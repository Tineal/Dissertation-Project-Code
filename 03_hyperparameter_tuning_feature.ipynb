{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 1\n",
    "\"\"\"\n",
    "def create_model(n, optimizer, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(n,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer = optimizer, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((728, 16), (182, 16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f-score regression\n",
    "x1_fregression = pd.read_csv('x1_fregression.csv')\n",
    "n = len(x1_fregression.columns)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1_fregression, y, test_size=0.2, random_state=42)\n",
    "X_train1.shape, X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((728, 16), (182, 16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mutual Info Regression\n",
    "x2_mutualinforegression = pd.read_csv('x2_mutualinforegression.csv')\n",
    "# n = len(x2_mutualinforegression.columns)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2_mutualinforegression, y, test_size=0.2, random_state=42)\n",
    "X_train2.shape, X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((728, 16), (182, 16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree-based Selection\n",
    "x3_treebased = pd.read_csv('x3_treebased.csv')\n",
    "# n = len(x3_treebased.columns)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(x3_treebased, y, test_size=0.2, random_state=42)\n",
    "X_train3.shape, X_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((728, 16), (182, 16))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "x3_pca = pd.read_csv('x4_pca.csv')\n",
    "# n = len(x3_pca.columns)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(x3_pca, y, test_size=0.2, random_state=42)\n",
    "X_train4.shape, X_test4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Method\n",
    "Testing feature selections: f_regression, mutual_info_regression, tree_base, PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 917.5565 - mae: 6.2414 - val_loss: 841.4586 - val_mae: 7.7177\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 841.45862, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 2/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 913.6404 - mae: 6.2013 - val_loss: 837.9047 - val_mae: 7.6726\n",
      "\n",
      "Epoch 00002: val_loss improved from 841.45862 to 837.90472, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 3/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 908.3355 - mae: 6.1703 - val_loss: 832.6071 - val_mae: 7.6320\n",
      "\n",
      "Epoch 00003: val_loss improved from 837.90472 to 832.60706, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 4/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 902.0119 - mae: 6.1387 - val_loss: 820.6979 - val_mae: 7.5714\n",
      "\n",
      "Epoch 00004: val_loss improved from 832.60706 to 820.69794, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 5/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 892.4922 - mae: 6.1147 - val_loss: 809.1981 - val_mae: 7.5223\n",
      "\n",
      "Epoch 00005: val_loss improved from 820.69794 to 809.19812, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 6/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 883.7751 - mae: 6.0999 - val_loss: 795.3036 - val_mae: 7.4687\n",
      "\n",
      "Epoch 00006: val_loss improved from 809.19812 to 795.30365, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 7/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 870.2573 - mae: 6.0743 - val_loss: 779.0466 - val_mae: 7.4096\n",
      "\n",
      "Epoch 00007: val_loss improved from 795.30365 to 779.04663, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 8/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 852.9127 - mae: 6.0545 - val_loss: 758.2486 - val_mae: 7.3324\n",
      "\n",
      "Epoch 00008: val_loss improved from 779.04663 to 758.24860, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 9/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 849.0271 - mae: 6.0576 - val_loss: 737.8613 - val_mae: 7.2608\n",
      "\n",
      "Epoch 00009: val_loss improved from 758.24860 to 737.86127, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 10/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 822.6439 - mae: 6.0276 - val_loss: 711.5747 - val_mae: 7.1778\n",
      "\n",
      "Epoch 00010: val_loss improved from 737.86127 to 711.57471, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 11/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 809.4338 - mae: 5.9605 - val_loss: 687.6543 - val_mae: 7.1148\n",
      "\n",
      "Epoch 00011: val_loss improved from 711.57471 to 687.65430, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 12/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 778.8953 - mae: 5.9588 - val_loss: 656.4655 - val_mae: 7.0181\n",
      "\n",
      "Epoch 00012: val_loss improved from 687.65430 to 656.46552, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 13/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 747.5077 - mae: 5.9148 - val_loss: 622.4709 - val_mae: 6.9048\n",
      "\n",
      "Epoch 00013: val_loss improved from 656.46552 to 622.47089, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 14/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 712.1022 - mae: 5.8693 - val_loss: 586.3331 - val_mae: 6.7701\n",
      "\n",
      "Epoch 00014: val_loss improved from 622.47089 to 586.33307, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 15/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 692.7908 - mae: 5.8410 - val_loss: 542.3506 - val_mae: 6.5836\n",
      "\n",
      "Epoch 00015: val_loss improved from 586.33307 to 542.35059, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 16/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 646.1580 - mae: 5.6884 - val_loss: 496.5023 - val_mae: 6.3575\n",
      "\n",
      "Epoch 00016: val_loss improved from 542.35059 to 496.50229, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 17/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 635.5440 - mae: 5.5887 - val_loss: 459.3241 - val_mae: 6.1157\n",
      "\n",
      "Epoch 00017: val_loss improved from 496.50229 to 459.32407, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 18/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 555.2595 - mae: 5.3551 - val_loss: 418.6978 - val_mae: 5.7978\n",
      "\n",
      "Epoch 00018: val_loss improved from 459.32407 to 418.69775, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 19/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 537.8693 - mae: 5.1983 - val_loss: 382.1156 - val_mae: 5.4710\n",
      "\n",
      "Epoch 00019: val_loss improved from 418.69775 to 382.11557, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 20/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 494.1634 - mae: 4.9470 - val_loss: 340.4897 - val_mae: 5.0536\n",
      "\n",
      "Epoch 00020: val_loss improved from 382.11557 to 340.48965, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 21/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 440.1142 - mae: 4.6701 - val_loss: 313.4210 - val_mae: 4.7049\n",
      "\n",
      "Epoch 00021: val_loss improved from 340.48965 to 313.42099, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 22/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 403.7171 - mae: 4.3674 - val_loss: 280.5005 - val_mae: 4.3907\n",
      "\n",
      "Epoch 00022: val_loss improved from 313.42099 to 280.50052, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 23/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 354.3304 - mae: 4.1954 - val_loss: 250.1443 - val_mae: 4.1414\n",
      "\n",
      "Epoch 00023: val_loss improved from 280.50052 to 250.14432, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 24/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 320.9413 - mae: 3.8508 - val_loss: 237.5042 - val_mae: 4.0467\n",
      "\n",
      "Epoch 00024: val_loss improved from 250.14432 to 237.50423, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 25/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 283.3238 - mae: 3.8949 - val_loss: 210.0588 - val_mae: 3.9360\n",
      "\n",
      "Epoch 00025: val_loss improved from 237.50423 to 210.05879, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 26/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 298.1313 - mae: 3.8301 - val_loss: 201.7084 - val_mae: 3.8374\n",
      "\n",
      "Epoch 00026: val_loss improved from 210.05879 to 201.70836, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 27/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 269.8990 - mae: 3.7822 - val_loss: 194.4758 - val_mae: 3.7913\n",
      "\n",
      "Epoch 00027: val_loss improved from 201.70836 to 194.47580, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 28/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 281.6069 - mae: 3.8794 - val_loss: 188.4715 - val_mae: 3.7684\n",
      "\n",
      "Epoch 00028: val_loss improved from 194.47580 to 188.47150, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 253.3027 - mae: 3.7299 - val_loss: 185.3913 - val_mae: 3.7424\n",
      "\n",
      "Epoch 00029: val_loss improved from 188.47150 to 185.39133, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 30/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 221.5494 - mae: 3.7155 - val_loss: 183.1050 - val_mae: 3.7066\n",
      "\n",
      "Epoch 00030: val_loss improved from 185.39133 to 183.10497, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 31/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 221.6688 - mae: 3.6568 - val_loss: 179.5691 - val_mae: 3.6528\n",
      "\n",
      "Epoch 00031: val_loss improved from 183.10497 to 179.56914, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 32/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 229.5561 - mae: 3.6550 - val_loss: 180.2337 - val_mae: 3.6814\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 179.56914\n",
      "Epoch 33/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 180.9020 - mae: 3.5647 - val_loss: 179.1468 - val_mae: 3.6673\n",
      "\n",
      "Epoch 00033: val_loss improved from 179.56914 to 179.14684, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 34/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 219.6746 - mae: 3.7052 - val_loss: 176.1909 - val_mae: 3.6208\n",
      "\n",
      "Epoch 00034: val_loss improved from 179.14684 to 176.19092, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 35/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 193.6766 - mae: 3.5699 - val_loss: 175.8283 - val_mae: 3.6196\n",
      "\n",
      "Epoch 00035: val_loss improved from 176.19092 to 175.82834, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 36/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 197.8897 - mae: 3.5734 - val_loss: 179.6958 - val_mae: 3.7385\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 175.82834\n",
      "Epoch 37/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 173.3634 - mae: 3.4369 - val_loss: 178.3671 - val_mae: 3.7476\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 175.82834\n",
      "Epoch 38/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 176.9434 - mae: 3.4045 - val_loss: 179.3350 - val_mae: 3.7904\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 175.82834\n",
      "Epoch 39/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 159.4994 - mae: 3.3946 - val_loss: 176.4572 - val_mae: 3.7792\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 175.82834\n",
      "Epoch 40/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 193.4660 - mae: 3.4992 - val_loss: 177.5934 - val_mae: 3.8239\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 175.82834\n",
      "Epoch 41/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 145.1265 - mae: 3.2339 - val_loss: 176.3566 - val_mae: 3.8226\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 175.82834\n",
      "Epoch 42/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 211.3465 - mae: 3.5240 - val_loss: 179.9046 - val_mae: 3.9072\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 175.82834\n",
      "Epoch 43/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 163.7159 - mae: 3.3659 - val_loss: 173.7974 - val_mae: 3.8202\n",
      "\n",
      "Epoch 00043: val_loss improved from 175.82834 to 173.79744, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 44/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 183.2248 - mae: 3.3571 - val_loss: 178.4286 - val_mae: 3.9172\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 173.79744\n",
      "Epoch 45/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 139.8448 - mae: 3.2584 - val_loss: 170.7332 - val_mae: 3.8086\n",
      "\n",
      "Epoch 00045: val_loss improved from 173.79744 to 170.73322, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 46/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 128.4043 - mae: 3.0291 - val_loss: 189.2208 - val_mae: 4.0775\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 170.73322\n",
      "Epoch 47/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 149.4168 - mae: 3.2930 - val_loss: 185.5950 - val_mae: 4.0401\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 170.73322\n",
      "Epoch 48/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 142.7153 - mae: 3.1853 - val_loss: 180.0537 - val_mae: 3.9787\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 170.73322\n",
      "Epoch 49/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 171.3820 - mae: 3.2277 - val_loss: 178.8508 - val_mae: 3.9740\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 170.73322\n",
      "Epoch 50/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 135.5062 - mae: 3.2179 - val_loss: 180.3707 - val_mae: 4.0044\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 170.73322\n",
      "Epoch 51/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 155.1187 - mae: 3.2254 - val_loss: 174.3287 - val_mae: 3.9364\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 170.73322\n",
      "Epoch 52/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 135.1781 - mae: 3.1201 - val_loss: 173.4467 - val_mae: 3.9321\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 170.73322\n",
      "Epoch 53/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 156.3121 - mae: 3.2928 - val_loss: 167.0076 - val_mae: 3.8510\n",
      "\n",
      "Epoch 00053: val_loss improved from 170.73322 to 167.00757, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 54/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 123.9185 - mae: 3.0390 - val_loss: 166.9982 - val_mae: 3.8511\n",
      "\n",
      "Epoch 00054: val_loss improved from 167.00757 to 166.99821, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 55/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 143.0879 - mae: 3.1256 - val_loss: 168.4677 - val_mae: 3.8734\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 166.99821\n",
      "Epoch 56/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 139.5625 - mae: 3.1200 - val_loss: 172.2019 - val_mae: 3.9184\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 166.99821\n",
      "Epoch 57/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 129.4228 - mae: 3.0249 - val_loss: 162.8909 - val_mae: 3.7977\n",
      "\n",
      "Epoch 00057: val_loss improved from 166.99821 to 162.89090, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 58/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 116.0668 - mae: 3.0956 - val_loss: 152.2536 - val_mae: 3.6462\n",
      "\n",
      "Epoch 00058: val_loss improved from 162.89090 to 152.25365, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 59/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 143.2479 - mae: 3.0978 - val_loss: 160.7454 - val_mae: 3.7648\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 152.25365\n",
      "Epoch 60/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 126.8019 - mae: 3.0318 - val_loss: 156.2041 - val_mae: 3.6994\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 152.25365\n",
      "Epoch 61/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 131.5596 - mae: 3.0366 - val_loss: 166.1366 - val_mae: 3.8161\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 152.25365\n",
      "Epoch 62/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 128.7662 - mae: 2.9678 - val_loss: 179.5100 - val_mae: 3.9602\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 152.25365\n",
      "Epoch 63/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 123.1967 - mae: 3.0181 - val_loss: 176.5196 - val_mae: 3.9149\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 152.25365\n",
      "Epoch 64/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 96.4524 - mae: 2.7805 - val_loss: 169.7787 - val_mae: 3.8362\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 152.25365\n",
      "Epoch 65/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 111.9686 - mae: 2.7924 - val_loss: 162.4223 - val_mae: 3.7372\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 152.25365\n",
      "Epoch 66/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 116.6680 - mae: 2.8970 - val_loss: 170.1735 - val_mae: 3.8100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 152.25365\n",
      "Epoch 67/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 106.4891 - mae: 2.7729 - val_loss: 182.4692 - val_mae: 3.9238\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 152.25365\n",
      "Epoch 68/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 110.1023 - mae: 2.7863 - val_loss: 179.1722 - val_mae: 3.8783\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 152.25365\n",
      "Epoch 69/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 118.7444 - mae: 2.9192 - val_loss: 176.5422 - val_mae: 3.8360\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 152.25365\n",
      "Epoch 70/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 93.5054 - mae: 2.6506 - val_loss: 170.7183 - val_mae: 3.7573\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 152.25365\n",
      "Epoch 71/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 119.9597 - mae: 2.7469 - val_loss: 167.5464 - val_mae: 3.7007\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 152.25365\n",
      "Epoch 72/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 105.7735 - mae: 2.7170 - val_loss: 155.5290 - val_mae: 3.5435\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 152.25365\n",
      "Epoch 73/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 98.8597 - mae: 2.6183 - val_loss: 173.1306 - val_mae: 3.7194\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 152.25365\n",
      "Epoch 74/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 99.1981 - mae: 2.6230 - val_loss: 190.2406 - val_mae: 3.8643\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 152.25365\n",
      "Epoch 75/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 100.4451 - mae: 2.7397 - val_loss: 178.7180 - val_mae: 3.7274\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 152.25365\n",
      "Epoch 76/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 91.8428 - mae: 2.5215 - val_loss: 179.6886 - val_mae: 3.7182\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 152.25365\n",
      "Epoch 77/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 69.7805 - mae: 2.4134 - val_loss: 179.0119 - val_mae: 3.6840\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 152.25365\n",
      "Epoch 78/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 114.5077 - mae: 2.6948 - val_loss: 183.4940 - val_mae: 3.7026\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 152.25365\n",
      "Epoch 79/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 69.4645 - mae: 2.4180 - val_loss: 184.0386 - val_mae: 3.6905\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 152.25365\n",
      "Epoch 80/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 95.3661 - mae: 2.6324 - val_loss: 201.4549 - val_mae: 3.8221\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 152.25365\n",
      "Epoch 81/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 91.0394 - mae: 2.4600 - val_loss: 185.2178 - val_mae: 3.6523\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 152.25365\n",
      "Epoch 82/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 68.1367 - mae: 2.4343 - val_loss: 184.1484 - val_mae: 3.6102\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 152.25365\n",
      "Epoch 83/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 94.6102 - mae: 2.5127 - val_loss: 187.2688 - val_mae: 3.6173\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 152.25365\n",
      "Epoch 84/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 60.8266 - mae: 2.2574 - val_loss: 200.5089 - val_mae: 3.7131\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 152.25365\n",
      "Epoch 85/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 94.6245 - mae: 2.5144 - val_loss: 208.9601 - val_mae: 3.7707\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 152.25365\n",
      "Epoch 86/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 116.3792 - mae: 2.6441 - val_loss: 227.0318 - val_mae: 3.8960\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 152.25365\n",
      "Epoch 87/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 106.7576 - mae: 2.5750 - val_loss: 225.4840 - val_mae: 3.8599\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 152.25365\n",
      "Epoch 88/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 62.6829 - mae: 2.3048 - val_loss: 208.2146 - val_mae: 3.6868\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 152.25365\n",
      "Epoch 89/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 71.4815 - mae: 2.3767 - val_loss: 217.6693 - val_mae: 3.7157\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 152.25365\n",
      "Epoch 90/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 74.2294 - mae: 2.3015 - val_loss: 216.6817 - val_mae: 3.6844\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 152.25365\n",
      "Epoch 91/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 63.1510 - mae: 2.3577 - val_loss: 218.1485 - val_mae: 3.6570\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 152.25365\n",
      "Epoch 92/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 60.4077 - mae: 2.2113 - val_loss: 213.7813 - val_mae: 3.5849\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 152.25365\n",
      "Epoch 93/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 62.4862 - mae: 2.2105 - val_loss: 198.2523 - val_mae: 3.4110\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 152.25365\n",
      "Epoch 94/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 59.0365 - mae: 2.2358 - val_loss: 209.3192 - val_mae: 3.4953\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 152.25365\n",
      "Epoch 95/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 57.4260 - mae: 2.2263 - val_loss: 204.3093 - val_mae: 3.4227\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 152.25365\n",
      "Epoch 96/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 83.3648 - mae: 2.4111 - val_loss: 246.0926 - val_mae: 3.7659\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 152.25365\n",
      "Epoch 97/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 49.7489 - mae: 2.1658 - val_loss: 247.4911 - val_mae: 3.7697\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 152.25365\n",
      "Epoch 98/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 60.6978 - mae: 2.2110 - val_loss: 282.6740 - val_mae: 4.0273\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 152.25365\n",
      "Epoch 99/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 54.8833 - mae: 2.2215 - val_loss: 260.7979 - val_mae: 3.8450\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 152.25365\n",
      "Epoch 100/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 54.0895 - mae: 2.1598 - val_loss: 227.0565 - val_mae: 3.5563\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 152.25365\n",
      "Epoch 101/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 62.1769 - mae: 2.2159 - val_loss: 226.3941 - val_mae: 3.5163\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 152.25365\n",
      "Epoch 102/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.8603 - mae: 2.0127 - val_loss: 239.6867 - val_mae: 3.6000\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 152.25365\n",
      "Epoch 103/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 57.1715 - mae: 2.1880 - val_loss: 211.6015 - val_mae: 3.4023\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 152.25365\n",
      "Epoch 104/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.2232 - mae: 1.9764 - val_loss: 244.1635 - val_mae: 3.6070\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 152.25365\n",
      "Epoch 105/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 56.8930 - mae: 2.2362 - val_loss: 260.9767 - val_mae: 3.6865\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 152.25365\n",
      "Epoch 106/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 74.2879 - mae: 2.4608 - val_loss: 260.4537 - val_mae: 3.6768\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 152.25365\n",
      "Epoch 107/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 58.0602 - mae: 2.2945 - val_loss: 291.6216 - val_mae: 3.8340\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 152.25365\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - ETA: 0s - loss: 46.5397 - mae: 1.92 - 0s 2ms/step - loss: 40.8165 - mae: 1.8816 - val_loss: 287.5176 - val_mae: 3.8070\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 152.25365\n",
      "Epoch 109/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 50.4365 - mae: 2.0746 - val_loss: 285.8589 - val_mae: 3.7613\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 152.25365\n",
      "Epoch 110/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.4905 - mae: 1.9782 - val_loss: 284.7458 - val_mae: 3.7614\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 152.25365\n",
      "Epoch 111/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 59.2480 - mae: 2.1999 - val_loss: 295.8031 - val_mae: 3.8315\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 152.25365\n",
      "Epoch 112/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 49.5290 - mae: 2.1065 - val_loss: 264.2427 - val_mae: 3.6264\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 152.25365\n",
      "Epoch 113/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 60.5555 - mae: 2.2094 - val_loss: 276.8189 - val_mae: 3.6928\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 152.25365\n",
      "Epoch 114/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.3620 - mae: 1.9870 - val_loss: 319.5136 - val_mae: 3.9278\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 152.25365\n",
      "Epoch 115/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 43.6432 - mae: 2.1018 - val_loss: 294.6162 - val_mae: 3.8095\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 152.25365\n",
      "Epoch 116/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 57.9769 - mae: 2.1384 - val_loss: 295.8049 - val_mae: 3.8204\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 152.25365\n",
      "Epoch 117/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 71.2285 - mae: 2.3113 - val_loss: 286.0341 - val_mae: 3.7342\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 152.25365\n",
      "Epoch 118/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51.2169 - mae: 2.1441 - val_loss: 248.5794 - val_mae: 3.5594\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 152.25365\n",
      "Epoch 119/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 49.3160 - mae: 2.2135 - val_loss: 252.9693 - val_mae: 3.5630\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 152.25365\n",
      "Epoch 120/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 64.0044 - mae: 2.2861 - val_loss: 283.3789 - val_mae: 3.6987\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 152.25365\n",
      "Epoch 121/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 35.6620 - mae: 1.9282 - val_loss: 276.5326 - val_mae: 3.6571\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 152.25365\n",
      "Epoch 122/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.8629 - mae: 2.0595 - val_loss: 291.6239 - val_mae: 3.7485\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 152.25365\n",
      "Epoch 123/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 55.9754 - mae: 2.1765 - val_loss: 322.4050 - val_mae: 3.8972\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 152.25365\n",
      "Epoch 124/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.5884 - mae: 1.9399 - val_loss: 256.4380 - val_mae: 3.5789\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 152.25365\n",
      "Epoch 125/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.6048 - mae: 2.0037 - val_loss: 293.3093 - val_mae: 3.7064\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 152.25365\n",
      "Epoch 126/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.2182 - mae: 2.0601 - val_loss: 318.7087 - val_mae: 3.8505\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 152.25365\n",
      "Epoch 127/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.7446 - mae: 2.0519 - val_loss: 287.4114 - val_mae: 3.6770\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 152.25365\n",
      "Epoch 128/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.2517 - mae: 2.0337 - val_loss: 306.5645 - val_mae: 3.7910\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 152.25365\n",
      "Epoch 129/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 42.4274 - mae: 2.0326 - val_loss: 367.6997 - val_mae: 4.1270\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 152.25365\n",
      "Epoch 130/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 46.4970 - mae: 2.1138 - val_loss: 323.8391 - val_mae: 3.8924\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 152.25365\n",
      "Epoch 131/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 53.0756 - mae: 2.0645 - val_loss: 302.0358 - val_mae: 3.7615\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 152.25365\n",
      "Epoch 132/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.9009 - mae: 1.9682 - val_loss: 330.1682 - val_mae: 3.9001\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 152.25365\n",
      "Epoch 133/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 59.7849 - mae: 2.2380 - val_loss: 334.9797 - val_mae: 3.9175\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 152.25365\n",
      "Epoch 134/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 44.1376 - mae: 2.0526 - val_loss: 303.6679 - val_mae: 3.7746\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 152.25365\n",
      "Epoch 135/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 55.2506 - mae: 2.1972 - val_loss: 329.0277 - val_mae: 3.8906\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 152.25365\n",
      "Epoch 136/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51.4666 - mae: 2.1933 - val_loss: 322.9012 - val_mae: 3.8911\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 152.25365\n",
      "Epoch 137/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 54.0707 - mae: 2.1749 - val_loss: 361.0824 - val_mae: 4.1011\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 152.25365\n",
      "Epoch 138/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 48.1421 - mae: 2.0897 - val_loss: 301.2909 - val_mae: 3.8264\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 152.25365\n",
      "Epoch 139/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 49.8588 - mae: 2.0924 - val_loss: 311.8643 - val_mae: 3.9084\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 152.25365\n",
      "Epoch 140/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.3768 - mae: 1.9998 - val_loss: 308.7224 - val_mae: 3.9032\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 152.25365\n",
      "Epoch 141/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.8001 - mae: 1.9588 - val_loss: 322.7656 - val_mae: 3.9705\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 152.25365\n",
      "Epoch 142/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 44.2871 - mae: 1.9635 - val_loss: 296.5769 - val_mae: 3.8275\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 152.25365\n",
      "Epoch 143/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.4562 - mae: 2.0303 - val_loss: 346.5377 - val_mae: 4.0695\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 152.25365\n",
      "Epoch 144/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 35.1062 - mae: 1.8714 - val_loss: 326.5456 - val_mae: 3.9446\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 152.25365\n",
      "Epoch 145/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 47.9438 - mae: 2.0539 - val_loss: 299.0602 - val_mae: 3.7646\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 152.25365\n",
      "Epoch 146/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.7807 - mae: 1.8675 - val_loss: 269.2001 - val_mae: 3.6363\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 152.25365\n",
      "Epoch 147/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 42.9149 - mae: 2.0403 - val_loss: 253.7858 - val_mae: 3.5913\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 152.25365\n",
      "Epoch 148/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 53.5367 - mae: 2.0955 - val_loss: 258.9742 - val_mae: 3.5819\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 152.25365\n",
      "Epoch 149/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 28.6045 - mae: 1.8619 - val_loss: 255.1942 - val_mae: 3.5976\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 152.25365\n",
      "Epoch 150/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.6947 - mae: 1.9977 - val_loss: 289.1069 - val_mae: 3.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00150: val_loss did not improve from 152.25365\n",
      "Epoch 151/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 52.6003 - mae: 2.1497 - val_loss: 355.8800 - val_mae: 4.0961\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 152.25365\n",
      "Epoch 152/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 31.5644 - mae: 1.9086 - val_loss: 350.2558 - val_mae: 4.0550\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 152.25365\n",
      "Epoch 153/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 54.3188 - mae: 2.1302 - val_loss: 341.0973 - val_mae: 3.9789\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 152.25365\n",
      "Epoch 154/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.8846 - mae: 1.9910 - val_loss: 305.8737 - val_mae: 3.7536\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 152.25365\n",
      "Epoch 155/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.2964 - mae: 2.0350 - val_loss: 286.3793 - val_mae: 3.6787\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 152.25365\n",
      "Epoch 156/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 28.1177 - mae: 1.7441 - val_loss: 308.9983 - val_mae: 3.7831\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 152.25365\n",
      "Epoch 157/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 50.7515 - mae: 2.0489 - val_loss: 308.0475 - val_mae: 3.8052\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 152.25365\n",
      "Epoch 158/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 42.4625 - mae: 2.0346 - val_loss: 264.5012 - val_mae: 3.6574\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 152.25365\n",
      "Epoch 159/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.5563 - mae: 2.0223 - val_loss: 315.7611 - val_mae: 3.8392\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 152.25365\n",
      "Epoch 160/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 45.9260 - mae: 1.9837 - val_loss: 336.8589 - val_mae: 3.9848\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 152.25365\n",
      "Epoch 161/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 34.0545 - mae: 1.8985 - val_loss: 297.9854 - val_mae: 3.7610\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 152.25365\n",
      "Epoch 162/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 45.2455 - mae: 2.0304 - val_loss: 330.7523 - val_mae: 3.9206\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 152.25365\n",
      "Epoch 163/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 33.5618 - mae: 1.9853 - val_loss: 317.7994 - val_mae: 3.8808\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 152.25365\n",
      "Epoch 164/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.1306 - mae: 1.9863 - val_loss: 306.0588 - val_mae: 3.8041\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 152.25365\n",
      "Epoch 165/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.4775 - mae: 1.9909 - val_loss: 300.2005 - val_mae: 3.8071\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 152.25365\n",
      "Epoch 166/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 52.0176 - mae: 2.0953 - val_loss: 264.7684 - val_mae: 3.6313\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 152.25365\n",
      "Epoch 167/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.9415 - mae: 2.0915 - val_loss: 302.9576 - val_mae: 3.7608\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 152.25365\n",
      "Epoch 168/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 29.8687 - mae: 1.8784 - val_loss: 295.8196 - val_mae: 3.7312\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 152.25365\n",
      "Epoch 169/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 56.2017 - mae: 2.1688 - val_loss: 297.6174 - val_mae: 3.7621\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 152.25365\n",
      "Epoch 170/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.8083 - mae: 1.9987 - val_loss: 312.3448 - val_mae: 3.8115\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 152.25365\n",
      "Epoch 171/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 57.3360 - mae: 2.1389 - val_loss: 266.3762 - val_mae: 3.6425\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 152.25365\n",
      "Epoch 172/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 45.7067 - mae: 2.0313 - val_loss: 310.9182 - val_mae: 3.7720\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 152.25365\n",
      "Epoch 173/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.1151 - mae: 1.9605 - val_loss: 366.3933 - val_mae: 4.0793\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 152.25365\n",
      "Epoch 174/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 53.0274 - mae: 2.0417 - val_loss: 348.3311 - val_mae: 3.9905\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 152.25365\n",
      "Epoch 175/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 26.6362 - mae: 1.7448 - val_loss: 335.7905 - val_mae: 3.9014\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 152.25365\n",
      "Epoch 176/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 41.0217 - mae: 1.9489 - val_loss: 281.2508 - val_mae: 3.6769\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 152.25365\n",
      "Epoch 177/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 42.2631 - mae: 2.1003 - val_loss: 282.6903 - val_mae: 3.6605\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 152.25365\n",
      "Epoch 178/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 31.0361 - mae: 1.8039 - val_loss: 330.5692 - val_mae: 3.8446\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 152.25365\n",
      "Epoch 179/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 27.1956 - mae: 1.7312 - val_loss: 344.0815 - val_mae: 3.8947\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 152.25365\n",
      "Epoch 180/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 47.4128 - mae: 2.1206 - val_loss: 341.8081 - val_mae: 3.8739\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 152.25365\n",
      "Epoch 181/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 34.1556 - mae: 1.8422 - val_loss: 317.3656 - val_mae: 3.7871\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 152.25365\n",
      "Epoch 182/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 44.4840 - mae: 2.0023 - val_loss: 368.3994 - val_mae: 3.9991\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 152.25365\n",
      "Epoch 183/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 31.6966 - mae: 1.8748 - val_loss: 333.3925 - val_mae: 3.8306\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 152.25365\n",
      "Epoch 184/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 46.6793 - mae: 1.9673 - val_loss: 275.0311 - val_mae: 3.6943\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 152.25365\n",
      "Epoch 185/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 47.1993 - mae: 1.9940 - val_loss: 324.1003 - val_mae: 3.8146\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 152.25365\n",
      "Epoch 186/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 56.3113 - mae: 2.2138 - val_loss: 358.5006 - val_mae: 3.9925\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 152.25365\n",
      "Epoch 187/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 31.9419 - mae: 1.8065 - val_loss: 350.4835 - val_mae: 3.9550\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 152.25365\n",
      "Epoch 188/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.2352 - mae: 1.9434 - val_loss: 352.7629 - val_mae: 3.9491\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 152.25365\n",
      "Epoch 189/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.1349 - mae: 1.9934 - val_loss: 356.1619 - val_mae: 3.9523\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 152.25365\n",
      "Epoch 190/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.0247 - mae: 1.9841 - val_loss: 350.8801 - val_mae: 3.9498\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 152.25365\n",
      "Epoch 191/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.3892 - mae: 1.9650 - val_loss: 317.0550 - val_mae: 3.7957\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 152.25365\n",
      "Epoch 192/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.2688 - mae: 1.8737 - val_loss: 303.7557 - val_mae: 3.7463\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 152.25365\n",
      "Epoch 193/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 44.7549 - mae: 2.0633 - val_loss: 319.8890 - val_mae: 3.7923\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 152.25365\n",
      "Epoch 194/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 53.2243 - mae: 2.0614 - val_loss: 336.1824 - val_mae: 3.8590\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 152.25365\n",
      "Epoch 195/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 27.1058 - mae: 1.7524 - val_loss: 309.2516 - val_mae: 3.7698\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 152.25365\n",
      "Epoch 196/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.1714 - mae: 2.0749 - val_loss: 275.0198 - val_mae: 3.6940\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 152.25365\n",
      "Epoch 197/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 43.4334 - mae: 2.0367 - val_loss: 350.2011 - val_mae: 3.9497\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 152.25365\n",
      "Epoch 198/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 44.3926 - mae: 1.9225 - val_loss: 339.0256 - val_mae: 3.8874\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 152.25365\n",
      "Epoch 199/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 30.7491 - mae: 1.8459 - val_loss: 299.3871 - val_mae: 3.6929\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 152.25365\n",
      "Epoch 200/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 52.8467 - mae: 2.1862 - val_loss: 336.5533 - val_mae: 3.9328\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 152.25365\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 2\n",
    "\"\"\"\n",
    "model_feature1 = create_model(n, Adam(learning_rate = 0.0001), 0.2)\n",
    "\n",
    "history_feature1 = model_feature1.fit(X_train1,\n",
    "                                      y_train1,\n",
    "                                      validation_split = 0.2,\n",
    "                                      epochs=200,\n",
    "                                      batch_size=5,\n",
    "                                      verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 205.9358 - mae: 2.5960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[205.93580627441406, 2.596035957336426]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 3\n",
    "\"\"\"\n",
    "plt.plot(history_feature1.history['mae'])\n",
    "plt.plot(history_feature1.history['val_mae'])\n",
    "plt.title('F Regression')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(top = 8)\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "score_feature1 = model_feature1.evaluate(X_test1, y_test1, verbose=1)\n",
    "score_feature1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "117/117 [==============================] - 1s 2ms/step - loss: 917.9519 - mae: 6.2369 - val_loss: 839.5366 - val_mae: 7.7147\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 839.53662, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 2/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 913.0252 - mae: 6.1849 - val_loss: 834.8492 - val_mae: 7.6670\n",
      "\n",
      "Epoch 00002: val_loss improved from 839.53662 to 834.84918, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 3/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 909.4551 - mae: 6.1511 - val_loss: 827.3199 - val_mae: 7.6136\n",
      "\n",
      "Epoch 00003: val_loss improved from 834.84918 to 827.31989, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 4/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 904.4914 - mae: 6.1369 - val_loss: 819.1259 - val_mae: 7.5683\n",
      "\n",
      "Epoch 00004: val_loss improved from 827.31989 to 819.12592, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 5/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 900.6249 - mae: 6.1152 - val_loss: 811.9974 - val_mae: 7.5334\n",
      "\n",
      "Epoch 00005: val_loss improved from 819.12592 to 811.99744, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 6/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 890.2221 - mae: 6.0812 - val_loss: 801.8973 - val_mae: 7.4897\n",
      "\n",
      "Epoch 00006: val_loss improved from 811.99744 to 801.89734, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 7/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 881.3209 - mae: 6.0619 - val_loss: 788.6978 - val_mae: 7.4374\n",
      "\n",
      "Epoch 00007: val_loss improved from 801.89734 to 788.69781, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 8/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 873.3589 - mae: 6.0605 - val_loss: 775.8466 - val_mae: 7.3871\n",
      "\n",
      "Epoch 00008: val_loss improved from 788.69781 to 775.84662, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 9/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 859.4706 - mae: 6.0381 - val_loss: 759.2645 - val_mae: 7.3331\n",
      "\n",
      "Epoch 00009: val_loss improved from 775.84662 to 759.26453, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 10/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 847.3593 - mae: 6.0264 - val_loss: 742.0428 - val_mae: 7.2758\n",
      "\n",
      "Epoch 00010: val_loss improved from 759.26453 to 742.04279, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 11/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 828.9432 - mae: 6.0093 - val_loss: 718.3663 - val_mae: 7.2001\n",
      "\n",
      "Epoch 00011: val_loss improved from 742.04279 to 718.36627, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 12/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 810.1043 - mae: 5.9749 - val_loss: 691.7710 - val_mae: 7.1159\n",
      "\n",
      "Epoch 00012: val_loss improved from 718.36627 to 691.77100, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 13/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 788.5073 - mae: 5.9531 - val_loss: 663.6837 - val_mae: 7.0316\n",
      "\n",
      "Epoch 00013: val_loss improved from 691.77100 to 663.68365, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 14/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 765.7829 - mae: 5.9473 - val_loss: 633.1700 - val_mae: 6.9406\n",
      "\n",
      "Epoch 00014: val_loss improved from 663.68365 to 633.16998, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 15/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 731.0461 - mae: 5.9096 - val_loss: 602.6057 - val_mae: 6.8491\n",
      "\n",
      "Epoch 00015: val_loss improved from 633.16998 to 602.60571, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 16/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 705.0899 - mae: 5.8693 - val_loss: 561.8351 - val_mae: 6.7113\n",
      "\n",
      "Epoch 00016: val_loss improved from 602.60571 to 561.83514, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 17/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 679.2601 - mae: 5.8072 - val_loss: 526.0972 - val_mae: 6.5779\n",
      "\n",
      "Epoch 00017: val_loss improved from 561.83514 to 526.09717, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 18/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 633.3831 - mae: 5.7966 - val_loss: 483.0683 - val_mae: 6.3756\n",
      "\n",
      "Epoch 00018: val_loss improved from 526.09717 to 483.06827, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 19/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590.9745 - mae: 5.5766 - val_loss: 443.1014 - val_mae: 6.1495\n",
      "\n",
      "Epoch 00019: val_loss improved from 483.06827 to 443.10144, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 20/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 554.8641 - mae: 5.4386 - val_loss: 407.3158 - val_mae: 5.9174\n",
      "\n",
      "Epoch 00020: val_loss improved from 443.10144 to 407.31580, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 21/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 526.0244 - mae: 5.3526 - val_loss: 371.5720 - val_mae: 5.6446\n",
      "\n",
      "Epoch 00021: val_loss improved from 407.31580 to 371.57196, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 22/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 479.7270 - mae: 5.1545 - val_loss: 337.9409 - val_mae: 5.3300\n",
      "\n",
      "Epoch 00022: val_loss improved from 371.57196 to 337.94095, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 23/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 447.2200 - mae: 4.9917 - val_loss: 308.4710 - val_mae: 5.0223\n",
      "\n",
      "Epoch 00023: val_loss improved from 337.94095 to 308.47098, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 24/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 451.5558 - mae: 4.8965 - val_loss: 278.6583 - val_mae: 4.7911\n",
      "\n",
      "Epoch 00024: val_loss improved from 308.47098 to 278.65826, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 25/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 403.4274 - mae: 4.7151 - val_loss: 254.0646 - val_mae: 4.5399\n",
      "\n",
      "Epoch 00025: val_loss improved from 278.65826 to 254.06464, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 26/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 354.3228 - mae: 4.3584 - val_loss: 236.5647 - val_mae: 4.3466\n",
      "\n",
      "Epoch 00026: val_loss improved from 254.06464 to 236.56470, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 27/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 316.2401 - mae: 4.2717 - val_loss: 214.3528 - val_mae: 4.2067\n",
      "\n",
      "Epoch 00027: val_loss improved from 236.56470 to 214.35280, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 28/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 293.3086 - mae: 4.0826 - val_loss: 201.3317 - val_mae: 4.0776\n",
      "\n",
      "Epoch 00028: val_loss improved from 214.35280 to 201.33170, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 277.7225 - mae: 4.1042 - val_loss: 189.3758 - val_mae: 3.9399\n",
      "\n",
      "Epoch 00029: val_loss improved from 201.33170 to 189.37579, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 30/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 253.8865 - mae: 3.9358 - val_loss: 182.7982 - val_mae: 3.8090\n",
      "\n",
      "Epoch 00030: val_loss improved from 189.37579 to 182.79823, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 31/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 243.6349 - mae: 3.8997 - val_loss: 179.2297 - val_mae: 3.7239\n",
      "\n",
      "Epoch 00031: val_loss improved from 182.79823 to 179.22966, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 32/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 210.4612 - mae: 3.6749 - val_loss: 175.6656 - val_mae: 3.6956\n",
      "\n",
      "Epoch 00032: val_loss improved from 179.22966 to 175.66557, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 33/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 244.1991 - mae: 3.8419 - val_loss: 174.1803 - val_mae: 3.6598\n",
      "\n",
      "Epoch 00033: val_loss improved from 175.66557 to 174.18033, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 34/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 217.3731 - mae: 3.7434 - val_loss: 172.2516 - val_mae: 3.5849\n",
      "\n",
      "Epoch 00034: val_loss improved from 174.18033 to 172.25160, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 35/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 238.2350 - mae: 3.7314 - val_loss: 174.7330 - val_mae: 3.6452\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 172.25160\n",
      "Epoch 36/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 223.4692 - mae: 3.7932 - val_loss: 175.3520 - val_mae: 3.6379\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 172.25160\n",
      "Epoch 37/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 192.1371 - mae: 3.6225 - val_loss: 175.9232 - val_mae: 3.6296\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 172.25160\n",
      "Epoch 38/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 181.1156 - mae: 3.4790 - val_loss: 179.0472 - val_mae: 3.7294\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 172.25160\n",
      "Epoch 39/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 186.5046 - mae: 3.5364 - val_loss: 181.0954 - val_mae: 3.7643\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 172.25160\n",
      "Epoch 40/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 180.5219 - mae: 3.6330 - val_loss: 181.6559 - val_mae: 3.7882\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 172.25160\n",
      "Epoch 41/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 204.4114 - mae: 3.6603 - val_loss: 185.3745 - val_mae: 3.8599\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 172.25160\n",
      "Epoch 42/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 191.9494 - mae: 3.6102 - val_loss: 188.1086 - val_mae: 3.9209\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 172.25160\n",
      "Epoch 43/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 202.7594 - mae: 3.6034 - val_loss: 189.7291 - val_mae: 3.9470\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 172.25160\n",
      "Epoch 44/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 172.1011 - mae: 3.5214 - val_loss: 184.2431 - val_mae: 3.8774\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 172.25160\n",
      "Epoch 45/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 153.6813 - mae: 3.4718 - val_loss: 189.7886 - val_mae: 3.9704\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 172.25160\n",
      "Epoch 46/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 172.1985 - mae: 3.4948 - val_loss: 192.3210 - val_mae: 4.0151\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 172.25160\n",
      "Epoch 47/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 148.4293 - mae: 3.3890 - val_loss: 192.6052 - val_mae: 4.0317\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 172.25160\n",
      "Epoch 48/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 174.4677 - mae: 3.4305 - val_loss: 193.1269 - val_mae: 4.0441\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 172.25160\n",
      "Epoch 49/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 163.4086 - mae: 3.4526 - val_loss: 191.7850 - val_mae: 4.0451\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 172.25160\n",
      "Epoch 50/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 150.3112 - mae: 3.2778 - val_loss: 190.3174 - val_mae: 4.0332\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 172.25160\n",
      "Epoch 51/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 160.1520 - mae: 3.3544 - val_loss: 201.7593 - val_mae: 4.1699\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 172.25160\n",
      "Epoch 52/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 159.0614 - mae: 3.3944 - val_loss: 198.3255 - val_mae: 4.1435\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 172.25160\n",
      "Epoch 53/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 187.7807 - mae: 3.4679 - val_loss: 201.1765 - val_mae: 4.1821\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 172.25160\n",
      "Epoch 54/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 183.6623 - mae: 3.4594 - val_loss: 204.9482 - val_mae: 4.2237\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 172.25160\n",
      "Epoch 55/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 144.3282 - mae: 3.2207 - val_loss: 200.9637 - val_mae: 4.1907\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 172.25160\n",
      "Epoch 56/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 174.8992 - mae: 3.4275 - val_loss: 202.2902 - val_mae: 4.2073\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 172.25160\n",
      "Epoch 57/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 150.2267 - mae: 3.3382 - val_loss: 195.5141 - val_mae: 4.1401\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 172.25160\n",
      "Epoch 58/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 149.0486 - mae: 3.2452 - val_loss: 198.1800 - val_mae: 4.1720\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 172.25160\n",
      "Epoch 59/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 122.8009 - mae: 3.1761 - val_loss: 199.8810 - val_mae: 4.1943\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 172.25160\n",
      "Epoch 60/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 167.4831 - mae: 3.3902 - val_loss: 198.0179 - val_mae: 4.1794\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 172.25160\n",
      "Epoch 61/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 153.1964 - mae: 3.3051 - val_loss: 185.9748 - val_mae: 4.0542\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 172.25160\n",
      "Epoch 62/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 131.1539 - mae: 3.1836 - val_loss: 180.7797 - val_mae: 3.9964\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 172.25160\n",
      "Epoch 63/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 139.7485 - mae: 3.1711 - val_loss: 178.2198 - val_mae: 3.9667\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 172.25160\n",
      "Epoch 64/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 168.0152 - mae: 3.2548 - val_loss: 177.8519 - val_mae: 3.9629\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 172.25160\n",
      "Epoch 65/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 132.5670 - mae: 3.1567 - val_loss: 180.9277 - val_mae: 4.0026\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 172.25160\n",
      "Epoch 66/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 124.1223 - mae: 3.0910 - val_loss: 179.7065 - val_mae: 3.9866\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 172.25160\n",
      "Epoch 67/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 150.1900 - mae: 3.2202 - val_loss: 179.8997 - val_mae: 3.9902\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 172.25160\n",
      "Epoch 68/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 130.0791 - mae: 3.1253 - val_loss: 186.3357 - val_mae: 4.0559\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 172.25160\n",
      "Epoch 69/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 126.5814 - mae: 3.0649 - val_loss: 175.3215 - val_mae: 3.9396\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 172.25160\n",
      "Epoch 70/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 109.3457 - mae: 2.9668 - val_loss: 203.7476 - val_mae: 4.2196\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 172.25160\n",
      "Epoch 71/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 154.1567 - mae: 3.1291 - val_loss: 192.2168 - val_mae: 4.1018\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 172.25160\n",
      "Epoch 72/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 145.1083 - mae: 3.0942 - val_loss: 191.2830 - val_mae: 4.0876\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 172.25160\n",
      "Epoch 73/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 98.5931 - mae: 2.9017 - val_loss: 192.6820 - val_mae: 4.1011\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 172.25160\n",
      "Epoch 74/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 133.9949 - mae: 3.0798 - val_loss: 196.8008 - val_mae: 4.1351\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 172.25160\n",
      "Epoch 75/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 131.5573 - mae: 3.0531 - val_loss: 183.7479 - val_mae: 4.0024\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 172.25160\n",
      "Epoch 76/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 104.1830 - mae: 2.8620 - val_loss: 186.2923 - val_mae: 4.0314\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 172.25160\n",
      "Epoch 77/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 119.9494 - mae: 2.9550 - val_loss: 166.5298 - val_mae: 3.8151\n",
      "\n",
      "Epoch 00077: val_loss improved from 172.25160 to 166.52979, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 78/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 136.5773 - mae: 3.0524 - val_loss: 167.2473 - val_mae: 3.8166\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 166.52979\n",
      "Epoch 79/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 100.7279 - mae: 2.8400 - val_loss: 168.3857 - val_mae: 3.8226\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 166.52979\n",
      "Epoch 80/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 107.5550 - mae: 2.8391 - val_loss: 172.2843 - val_mae: 3.8514\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 166.52979\n",
      "Epoch 81/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 96.4341 - mae: 2.7483 - val_loss: 174.1865 - val_mae: 3.8590\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 166.52979\n",
      "Epoch 82/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 129.0515 - mae: 2.9298 - val_loss: 183.9689 - val_mae: 3.9338\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 166.52979\n",
      "Epoch 83/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 112.6119 - mae: 2.8881 - val_loss: 167.5839 - val_mae: 3.7688\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 166.52979\n",
      "Epoch 84/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 110.6740 - mae: 2.7970 - val_loss: 169.0550 - val_mae: 3.7765\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 166.52979\n",
      "Epoch 85/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 129.8371 - mae: 2.8096 - val_loss: 190.0653 - val_mae: 3.9599\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 166.52979\n",
      "Epoch 86/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 100.5562 - mae: 2.7772 - val_loss: 178.0067 - val_mae: 3.8373\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 166.52979\n",
      "Epoch 87/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 79.6076 - mae: 2.6473 - val_loss: 179.1026 - val_mae: 3.8325\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 166.52979\n",
      "Epoch 88/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 112.7493 - mae: 2.8282 - val_loss: 181.2490 - val_mae: 3.8380\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 166.52979\n",
      "Epoch 89/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 106.9617 - mae: 2.7750 - val_loss: 179.3164 - val_mae: 3.8087\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 166.52979\n",
      "Epoch 90/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 90.9218 - mae: 2.6405 - val_loss: 180.6999 - val_mae: 3.8058\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 166.52979\n",
      "Epoch 91/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 89.0664 - mae: 2.5967 - val_loss: 175.7067 - val_mae: 3.7482\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 166.52979\n",
      "Epoch 92/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 105.3411 - mae: 2.7079 - val_loss: 181.7142 - val_mae: 3.7937\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 166.52979\n",
      "Epoch 93/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 101.2261 - mae: 2.6232 - val_loss: 171.0099 - val_mae: 3.6859\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 166.52979\n",
      "Epoch 94/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 88.2283 - mae: 2.5784 - val_loss: 188.5533 - val_mae: 3.8240\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 166.52979\n",
      "Epoch 95/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 96.3176 - mae: 2.5248 - val_loss: 196.9948 - val_mae: 3.8717\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 166.52979\n",
      "Epoch 96/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 73.5405 - mae: 2.4344 - val_loss: 197.4613 - val_mae: 3.8449\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 166.52979\n",
      "Epoch 97/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 87.1868 - mae: 2.5838 - val_loss: 184.7159 - val_mae: 3.7365\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 166.52979\n",
      "Epoch 98/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.3610 - mae: 2.3744 - val_loss: 186.5748 - val_mae: 3.7285\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 166.52979\n",
      "Epoch 99/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.4833 - mae: 2.4650 - val_loss: 171.7086 - val_mae: 3.5878\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 166.52979\n",
      "Epoch 100/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.3667 - mae: 2.3846 - val_loss: 186.9469 - val_mae: 3.6777\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 166.52979\n",
      "Epoch 101/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.0889 - mae: 2.4075 - val_loss: 194.4338 - val_mae: 3.7234\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 166.52979\n",
      "Epoch 102/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 75.8063 - mae: 2.4179 - val_loss: 177.2260 - val_mae: 3.5840\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 166.52979\n",
      "Epoch 103/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 57.6377 - mae: 2.2596 - val_loss: 180.9772 - val_mae: 3.5904\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 166.52979\n",
      "Epoch 104/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.2609 - mae: 2.3137 - val_loss: 213.8776 - val_mae: 3.8045\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 166.52979\n",
      "Epoch 105/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 58.2781 - mae: 2.2907 - val_loss: 193.4939 - val_mae: 3.6582\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 166.52979\n",
      "Epoch 106/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 72.4169 - mae: 2.3612 - val_loss: 198.0549 - val_mae: 3.6777\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 166.52979\n",
      "Epoch 107/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6272 - mae: 2.4177 - val_loss: 188.4577 - val_mae: 3.5989\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 166.52979\n",
      "Epoch 108/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 94.2605 - mae: 2.4572 - val_loss: 215.9304 - val_mae: 3.7638\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 166.52979\n",
      "Epoch 109/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 76.0382 - mae: 2.3049 - val_loss: 218.3849 - val_mae: 3.7690\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 166.52979\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 84.3874 - mae: 2.4483 - val_loss: 185.9137 - val_mae: 3.5230\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 166.52979\n",
      "Epoch 111/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 54.1517 - mae: 2.2077 - val_loss: 195.3241 - val_mae: 3.5499\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 166.52979\n",
      "Epoch 112/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 77.7814 - mae: 2.2939 - val_loss: 227.7188 - val_mae: 3.7387\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 166.52979\n",
      "Epoch 113/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.8510 - mae: 2.4444 - val_loss: 214.8880 - val_mae: 3.6388\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 166.52979\n",
      "Epoch 114/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.0571 - mae: 2.2353 - val_loss: 238.6081 - val_mae: 3.7874\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 166.52979\n",
      "Epoch 115/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 57.3340 - mae: 2.2948 - val_loss: 228.9545 - val_mae: 3.7254\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 166.52979\n",
      "Epoch 116/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.6891 - mae: 2.1114 - val_loss: 213.3308 - val_mae: 3.5878\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 166.52979\n",
      "Epoch 117/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 58.0680 - mae: 2.2345 - val_loss: 217.5190 - val_mae: 3.5881\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 166.52979\n",
      "Epoch 118/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.5561 - mae: 1.9687 - val_loss: 222.9035 - val_mae: 3.5788\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 166.52979\n",
      "Epoch 119/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 55.3695 - mae: 2.1572 - val_loss: 230.0791 - val_mae: 3.6099\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 166.52979\n",
      "Epoch 120/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 54.5933 - mae: 2.1648 - val_loss: 231.2955 - val_mae: 3.6210\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 166.52979\n",
      "Epoch 121/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.6175 - mae: 2.1445 - val_loss: 212.9034 - val_mae: 3.4659\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 166.52979\n",
      "Epoch 122/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 59.7491 - mae: 2.1843 - val_loss: 232.4969 - val_mae: 3.5999\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 166.52979\n",
      "Epoch 123/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 55.5427 - mae: 2.2174 - val_loss: 245.8702 - val_mae: 3.6796\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 166.52979\n",
      "Epoch 124/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.2409 - mae: 2.1028 - val_loss: 218.4476 - val_mae: 3.4651\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 166.52979\n",
      "Epoch 125/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 72.1089 - mae: 2.2826 - val_loss: 208.9239 - val_mae: 3.4013\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 166.52979\n",
      "Epoch 126/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.1912 - mae: 1.9285 - val_loss: 227.5458 - val_mae: 3.4788\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 166.52979\n",
      "Epoch 127/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 59.9053 - mae: 2.1895 - val_loss: 258.5768 - val_mae: 3.6358\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 166.52979\n",
      "Epoch 128/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 61.7758 - mae: 2.1437 - val_loss: 237.0146 - val_mae: 3.5271\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 166.52979\n",
      "Epoch 129/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 57.7017 - mae: 2.0319 - val_loss: 223.5543 - val_mae: 3.4234\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 166.52979\n",
      "Epoch 130/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 51.6016 - mae: 2.1414 - val_loss: 226.0549 - val_mae: 3.4230\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 166.52979\n",
      "Epoch 131/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.0763 - mae: 1.9961 - val_loss: 250.6733 - val_mae: 3.5746\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 166.52979\n",
      "Epoch 132/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 58.2144 - mae: 2.3055 - val_loss: 262.0169 - val_mae: 3.6603\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 166.52979\n",
      "Epoch 133/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.7007 - mae: 2.0589 - val_loss: 242.9666 - val_mae: 3.5544\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 166.52979\n",
      "Epoch 134/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 45.8236 - mae: 2.0718 - val_loss: 213.1615 - val_mae: 3.3421\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 166.52979\n",
      "Epoch 135/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.5575 - mae: 1.9782 - val_loss: 241.4370 - val_mae: 3.5240\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 166.52979\n",
      "Epoch 136/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51.0402 - mae: 2.0154 - val_loss: 293.1375 - val_mae: 3.7990\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 166.52979\n",
      "Epoch 137/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.2646 - mae: 2.1808 - val_loss: 285.5206 - val_mae: 3.7971\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 166.52979\n",
      "Epoch 138/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.8597 - mae: 1.8808 - val_loss: 291.7947 - val_mae: 3.8041\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 166.52979\n",
      "Epoch 139/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.2630 - mae: 2.0473 - val_loss: 276.5055 - val_mae: 3.6970\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 166.52979\n",
      "Epoch 140/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 45.8466 - mae: 2.1255 - val_loss: 249.7091 - val_mae: 3.5248\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 166.52979\n",
      "Epoch 141/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.9627 - mae: 1.9939 - val_loss: 261.8734 - val_mae: 3.5903\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 166.52979\n",
      "Epoch 142/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.2953 - mae: 2.0459 - val_loss: 281.9565 - val_mae: 3.7009\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 166.52979\n",
      "Epoch 143/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.9771 - mae: 1.9615 - val_loss: 247.1331 - val_mae: 3.4922\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 166.52979\n",
      "Epoch 144/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 33.8291 - mae: 1.8914 - val_loss: 292.7358 - val_mae: 3.7555\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 166.52979\n",
      "Epoch 145/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.8314 - mae: 1.9114 - val_loss: 268.1966 - val_mae: 3.6280\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 166.52979\n",
      "Epoch 146/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 32.4749 - mae: 1.7747 - val_loss: 264.9133 - val_mae: 3.6143\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 166.52979\n",
      "Epoch 147/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.9383 - mae: 1.9928 - val_loss: 241.4413 - val_mae: 3.4770\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 166.52979\n",
      "Epoch 148/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 50.4286 - mae: 2.0447 - val_loss: 267.9171 - val_mae: 3.6176\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 166.52979\n",
      "Epoch 149/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.2937 - mae: 1.9427 - val_loss: 260.0490 - val_mae: 3.5643\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 166.52979\n",
      "Epoch 150/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 42.7283 - mae: 2.0062 - val_loss: 274.7067 - val_mae: 3.6524\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 166.52979\n",
      "Epoch 151/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40.5773 - mae: 2.0211 - val_loss: 285.4021 - val_mae: 3.7107\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 166.52979\n",
      "Epoch 152/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.2770 - mae: 1.8831 - val_loss: 297.8767 - val_mae: 3.7736\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 166.52979\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 33.2127 - mae: 1.8703 - val_loss: 305.9335 - val_mae: 3.8238\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 166.52979\n",
      "Epoch 154/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 34.3801 - mae: 1.8705 - val_loss: 272.3516 - val_mae: 3.6231\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 166.52979\n",
      "Epoch 155/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 31.0594 - mae: 1.8676 - val_loss: 322.5259 - val_mae: 3.9001\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 166.52979\n",
      "Epoch 156/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.4656 - mae: 2.2934 - val_loss: 319.3082 - val_mae: 3.9066\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 166.52979\n",
      "Epoch 157/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 49.3959 - mae: 2.1713 - val_loss: 286.7514 - val_mae: 3.7309\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 166.52979\n",
      "Epoch 158/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 60.4247 - mae: 2.2287 - val_loss: 311.8389 - val_mae: 3.8652\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 166.52979\n",
      "Epoch 159/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.9841 - mae: 2.0070 - val_loss: 278.5294 - val_mae: 3.6799\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 166.52979\n",
      "Epoch 160/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.0733 - mae: 1.8262 - val_loss: 308.5172 - val_mae: 3.8554\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 166.52979\n",
      "Epoch 161/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.6099 - mae: 1.8732 - val_loss: 294.7885 - val_mae: 3.7635\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 166.52979\n",
      "Epoch 162/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.9331 - mae: 1.9362 - val_loss: 329.6165 - val_mae: 3.9698\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 166.52979\n",
      "Epoch 163/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 33.6201 - mae: 1.8927 - val_loss: 241.9392 - val_mae: 3.4690\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 166.52979\n",
      "Epoch 164/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 34.7823 - mae: 1.8766 - val_loss: 246.2152 - val_mae: 3.4719\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 166.52979\n",
      "Epoch 165/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 31.2979 - mae: 1.8081 - val_loss: 271.4663 - val_mae: 3.6131\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 166.52979\n",
      "Epoch 166/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.4155 - mae: 1.9549 - val_loss: 280.1924 - val_mae: 3.6671\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 166.52979\n",
      "Epoch 167/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 32.6022 - mae: 1.8473 - val_loss: 302.3264 - val_mae: 3.8030\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 166.52979\n",
      "Epoch 168/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 36.0161 - mae: 1.8138 - val_loss: 291.0865 - val_mae: 3.7289\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 166.52979\n",
      "Epoch 169/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 28.8214 - mae: 1.7460 - val_loss: 290.1051 - val_mae: 3.7248\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 166.52979\n",
      "Epoch 170/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.5231 - mae: 1.9345 - val_loss: 292.4485 - val_mae: 3.7309\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 166.52979\n",
      "Epoch 171/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.1208 - mae: 1.9414 - val_loss: 302.2798 - val_mae: 3.7967\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 166.52979\n",
      "Epoch 172/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 28.5660 - mae: 1.7635 - val_loss: 258.9066 - val_mae: 3.5456\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 166.52979\n",
      "Epoch 173/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 59.9446 - mae: 2.1646 - val_loss: 258.8031 - val_mae: 3.5370\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 166.52979\n",
      "Epoch 174/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.1440 - mae: 1.9769 - val_loss: 312.9618 - val_mae: 3.8506\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 166.52979\n",
      "Epoch 175/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.0125 - mae: 2.0151 - val_loss: 254.8453 - val_mae: 3.5341\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 166.52979\n",
      "Epoch 176/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.8814 - mae: 1.9331 - val_loss: 273.2653 - val_mae: 3.6371\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 166.52979\n",
      "Epoch 177/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 42.7468 - mae: 1.8494 - val_loss: 311.5341 - val_mae: 3.8439\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 166.52979\n",
      "Epoch 178/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.6428 - mae: 1.9492 - val_loss: 327.8674 - val_mae: 3.9346\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 166.52979\n",
      "Epoch 179/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 47.3219 - mae: 1.9815 - val_loss: 284.4902 - val_mae: 3.6913\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 166.52979\n",
      "Epoch 180/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 50.3580 - mae: 2.0073 - val_loss: 282.5679 - val_mae: 3.6688\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 166.52979\n",
      "Epoch 181/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 39.6016 - mae: 1.9388 - val_loss: 253.1330 - val_mae: 3.4834\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 166.52979\n",
      "Epoch 182/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.4101 - mae: 1.8550 - val_loss: 310.4375 - val_mae: 3.7987\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 166.52979\n",
      "Epoch 183/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.1002 - mae: 1.8847 - val_loss: 280.5115 - val_mae: 3.6154\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 166.52979\n",
      "Epoch 184/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.8108 - mae: 1.8688 - val_loss: 275.6283 - val_mae: 3.6034\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 166.52979\n",
      "Epoch 185/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 26.3717 - mae: 1.7213 - val_loss: 307.6891 - val_mae: 3.7922\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 166.52979\n",
      "Epoch 186/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.1342 - mae: 2.0774 - val_loss: 308.3434 - val_mae: 3.8129\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 166.52979\n",
      "Epoch 187/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.9034 - mae: 1.9915 - val_loss: 257.6635 - val_mae: 3.5317\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 166.52979\n",
      "Epoch 188/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.1828 - mae: 2.0320 - val_loss: 276.8349 - val_mae: 3.6317\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 166.52979\n",
      "Epoch 189/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 28.4814 - mae: 1.7060 - val_loss: 288.9970 - val_mae: 3.7076\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 166.52979\n",
      "Epoch 190/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.6596 - mae: 1.8906 - val_loss: 303.4608 - val_mae: 3.7979\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 166.52979\n",
      "Epoch 191/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 42.7732 - mae: 2.0252 - val_loss: 343.2682 - val_mae: 4.0167\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 166.52979\n",
      "Epoch 192/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.6813 - mae: 1.9197 - val_loss: 269.9977 - val_mae: 3.6307\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 166.52979\n",
      "Epoch 193/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 36.7196 - mae: 1.9014 - val_loss: 291.4750 - val_mae: 3.7326\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 166.52979\n",
      "Epoch 194/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.2261 - mae: 1.8402 - val_loss: 262.1584 - val_mae: 3.5636\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 166.52979\n",
      "Epoch 195/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.5651 - mae: 1.8987 - val_loss: 266.4356 - val_mae: 3.5974\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 166.52979\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 40.2147 - mae: 1.9473 - val_loss: 334.9751 - val_mae: 3.9894\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 166.52979\n",
      "Epoch 197/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.1909 - mae: 1.9000 - val_loss: 288.8389 - val_mae: 3.7626\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 166.52979\n",
      "Epoch 198/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.0639 - mae: 1.8130 - val_loss: 296.6412 - val_mae: 3.7957\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 166.52979\n",
      "Epoch 199/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.9490 - mae: 1.8619 - val_loss: 310.8045 - val_mae: 3.8681\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 166.52979\n",
      "Epoch 200/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.0493 - mae: 1.8268 - val_loss: 317.2328 - val_mae: 3.8833\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 166.52979\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 2\n",
    "\"\"\"\n",
    "model_feature2 = create_model(n, Adam(learning_rate = 0.0001), 0.2)\n",
    "\n",
    "history_feature2 = model_feature2.fit(X_train2,\n",
    "                                      y_train2,\n",
    "                                      validation_split = 0.2,\n",
    "                                      epochs=200,\n",
    "                                      batch_size=5,\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 226.3756 - mae: 2.5705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[226.37564086914062, 2.5704758167266846]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 3\n",
    "\"\"\"\n",
    "plt.plot(history_feature2.history['mae'])\n",
    "plt.plot(history_feature2.history['val_mae'])\n",
    "plt.title('Mutual Regression')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(top = 8)\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "score_feature2 = model_feature2.evaluate(X_test2, y_test2, verbose=1)\n",
    "score_feature2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tree_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "117/117 [==============================] - 1s 2ms/step - loss: 921.2223 - mae: 6.2617 - val_loss: 845.0234 - val_mae: 7.7728\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 845.02344, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 2/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 918.5587 - mae: 6.2307 - val_loss: 840.3612 - val_mae: 7.7277\n",
      "\n",
      "Epoch 00002: val_loss improved from 845.02344 to 840.36121, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 3/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 916.3776 - mae: 6.2081 - val_loss: 837.5096 - val_mae: 7.6976\n",
      "\n",
      "Epoch 00003: val_loss improved from 840.36121 to 837.50958, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 4/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 911.9596 - mae: 6.1813 - val_loss: 834.1262 - val_mae: 7.6659\n",
      "\n",
      "Epoch 00004: val_loss improved from 837.50958 to 834.12622, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 5/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 911.7795 - mae: 6.1707 - val_loss: 831.2338 - val_mae: 7.6423\n",
      "\n",
      "Epoch 00005: val_loss improved from 834.12622 to 831.23383, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 6/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 909.0038 - mae: 6.1593 - val_loss: 827.6882 - val_mae: 7.6175\n",
      "\n",
      "Epoch 00006: val_loss improved from 831.23383 to 827.68823, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 7/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 904.5145 - mae: 6.1461 - val_loss: 821.8589 - val_mae: 7.5883\n",
      "\n",
      "Epoch 00007: val_loss improved from 827.68823 to 821.85889, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 8/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 901.3378 - mae: 6.1409 - val_loss: 815.9872 - val_mae: 7.5638\n",
      "\n",
      "Epoch 00008: val_loss improved from 821.85889 to 815.98724, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 9/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 898.0191 - mae: 6.1470 - val_loss: 810.1804 - val_mae: 7.5445\n",
      "\n",
      "Epoch 00009: val_loss improved from 815.98724 to 810.18042, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 10/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 890.0530 - mae: 6.1332 - val_loss: 800.5289 - val_mae: 7.5109\n",
      "\n",
      "Epoch 00010: val_loss improved from 810.18042 to 800.52887, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 11/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 882.7920 - mae: 6.1252 - val_loss: 791.9409 - val_mae: 7.4839\n",
      "\n",
      "Epoch 00011: val_loss improved from 800.52887 to 791.94086, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 12/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 874.1400 - mae: 6.1211 - val_loss: 779.1411 - val_mae: 7.4425\n",
      "\n",
      "Epoch 00012: val_loss improved from 791.94086 to 779.14105, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 13/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 861.7715 - mae: 6.1028 - val_loss: 764.7316 - val_mae: 7.3914\n",
      "\n",
      "Epoch 00013: val_loss improved from 779.14105 to 764.73157, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 14/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 856.0505 - mae: 6.1058 - val_loss: 749.7185 - val_mae: 7.3408\n",
      "\n",
      "Epoch 00014: val_loss improved from 764.73157 to 749.71851, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 15/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 835.2577 - mae: 6.0805 - val_loss: 732.7485 - val_mae: 7.2795\n",
      "\n",
      "Epoch 00015: val_loss improved from 749.71851 to 732.74847, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 16/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 822.8781 - mae: 6.0838 - val_loss: 713.9327 - val_mae: 7.2138\n",
      "\n",
      "Epoch 00016: val_loss improved from 732.74847 to 713.93268, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 17/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 816.6375 - mae: 6.0789 - val_loss: 693.4349 - val_mae: 7.1394\n",
      "\n",
      "Epoch 00017: val_loss improved from 713.93268 to 693.43494, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 18/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 790.7320 - mae: 6.0361 - val_loss: 667.9690 - val_mae: 7.0472\n",
      "\n",
      "Epoch 00018: val_loss improved from 693.43494 to 667.96899, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 19/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 771.8023 - mae: 5.9995 - val_loss: 642.8979 - val_mae: 6.9542\n",
      "\n",
      "Epoch 00019: val_loss improved from 667.96899 to 642.89789, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 20/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 746.1510 - mae: 5.9613 - val_loss: 617.3062 - val_mae: 6.8408\n",
      "\n",
      "Epoch 00020: val_loss improved from 642.89789 to 617.30621, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 21/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 719.4792 - mae: 5.9076 - val_loss: 586.2101 - val_mae: 6.7078\n",
      "\n",
      "Epoch 00021: val_loss improved from 617.30621 to 586.21008, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 22/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 713.6012 - mae: 5.8319 - val_loss: 559.2240 - val_mae: 6.5719\n",
      "\n",
      "Epoch 00022: val_loss improved from 586.21008 to 559.22400, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 23/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 689.6928 - mae: 5.7711 - val_loss: 529.6997 - val_mae: 6.4194\n",
      "\n",
      "Epoch 00023: val_loss improved from 559.22400 to 529.69971, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 24/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 640.2956 - mae: 5.6086 - val_loss: 499.0508 - val_mae: 6.2072\n",
      "\n",
      "Epoch 00024: val_loss improved from 529.69971 to 499.05078, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 25/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 624.3628 - mae: 5.4862 - val_loss: 462.8586 - val_mae: 5.9290\n",
      "\n",
      "Epoch 00025: val_loss improved from 499.05078 to 462.85861, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 26/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 593.7254 - mae: 5.2505 - val_loss: 432.4500 - val_mae: 5.6526\n",
      "\n",
      "Epoch 00026: val_loss improved from 462.85861 to 432.45004, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 27/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 550.9103 - mae: 5.0393 - val_loss: 397.2432 - val_mae: 5.3240\n",
      "\n",
      "Epoch 00027: val_loss improved from 432.45004 to 397.24316, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 28/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 540.0129 - mae: 4.8429 - val_loss: 364.8738 - val_mae: 4.9673\n",
      "\n",
      "Epoch 00028: val_loss improved from 397.24316 to 364.87381, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 473.7675 - mae: 4.5442 - val_loss: 332.7268 - val_mae: 4.6522\n",
      "\n",
      "Epoch 00029: val_loss improved from 364.87381 to 332.72684, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 30/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 457.3177 - mae: 4.4254 - val_loss: 302.7549 - val_mae: 4.3875\n",
      "\n",
      "Epoch 00030: val_loss improved from 332.72684 to 302.75494, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 31/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 439.4250 - mae: 4.3028 - val_loss: 277.9428 - val_mae: 4.1274\n",
      "\n",
      "Epoch 00031: val_loss improved from 302.75494 to 277.94278, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 32/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 408.4540 - mae: 4.1678 - val_loss: 254.9670 - val_mae: 3.9299\n",
      "\n",
      "Epoch 00032: val_loss improved from 277.94278 to 254.96701, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 33/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 392.1566 - mae: 4.0397 - val_loss: 233.3957 - val_mae: 3.7314\n",
      "\n",
      "Epoch 00033: val_loss improved from 254.96701 to 233.39571, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 34/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 361.2639 - mae: 3.8824 - val_loss: 216.4149 - val_mae: 3.6185\n",
      "\n",
      "Epoch 00034: val_loss improved from 233.39571 to 216.41495, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 35/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 336.7289 - mae: 3.7616 - val_loss: 200.7753 - val_mae: 3.5320\n",
      "\n",
      "Epoch 00035: val_loss improved from 216.41495 to 200.77531, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 36/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 331.4291 - mae: 3.8284 - val_loss: 189.1271 - val_mae: 3.4435\n",
      "\n",
      "Epoch 00036: val_loss improved from 200.77531 to 189.12709, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 37/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 293.7052 - mae: 3.6754 - val_loss: 181.9359 - val_mae: 3.3771\n",
      "\n",
      "Epoch 00037: val_loss improved from 189.12709 to 181.93593, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 38/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 249.2599 - mae: 3.6231 - val_loss: 171.7800 - val_mae: 3.2834\n",
      "\n",
      "Epoch 00038: val_loss improved from 181.93593 to 171.78001, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 39/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 263.6515 - mae: 3.5743 - val_loss: 168.9855 - val_mae: 3.2375\n",
      "\n",
      "Epoch 00039: val_loss improved from 171.78001 to 168.98550, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 40/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 248.8092 - mae: 3.6301 - val_loss: 167.6373 - val_mae: 3.1888\n",
      "\n",
      "Epoch 00040: val_loss improved from 168.98550 to 167.63728, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 41/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 233.3152 - mae: 3.5508 - val_loss: 167.7531 - val_mae: 3.2154\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 167.63728\n",
      "Epoch 42/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 229.0169 - mae: 3.4981 - val_loss: 169.3712 - val_mae: 3.3360\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 167.63728\n",
      "Epoch 43/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 221.6417 - mae: 3.3887 - val_loss: 168.8126 - val_mae: 3.3599\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 167.63728\n",
      "Epoch 44/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 220.5636 - mae: 3.5602 - val_loss: 176.3334 - val_mae: 3.5307\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 167.63728\n",
      "Epoch 45/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 206.0709 - mae: 3.5241 - val_loss: 183.0755 - val_mae: 3.6649\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 167.63728\n",
      "Epoch 46/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 198.3629 - mae: 3.4874 - val_loss: 180.5250 - val_mae: 3.6457\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 167.63728\n",
      "Epoch 47/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 192.2821 - mae: 3.4704 - val_loss: 184.2805 - val_mae: 3.7260\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 167.63728\n",
      "Epoch 48/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 212.3765 - mae: 3.5876 - val_loss: 190.9204 - val_mae: 3.8328\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 167.63728\n",
      "Epoch 49/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 216.5813 - mae: 3.5355 - val_loss: 189.8704 - val_mae: 3.8346\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 167.63728\n",
      "Epoch 50/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 196.8545 - mae: 3.4499 - val_loss: 193.9619 - val_mae: 3.8988\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 167.63728\n",
      "Epoch 51/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 192.4207 - mae: 3.5444 - val_loss: 193.3591 - val_mae: 3.8981\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 167.63728\n",
      "Epoch 52/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 203.2976 - mae: 3.5377 - val_loss: 197.5517 - val_mae: 3.9590\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 167.63728\n",
      "Epoch 53/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 207.1263 - mae: 3.5544 - val_loss: 197.2234 - val_mae: 3.9648\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 167.63728\n",
      "Epoch 54/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 162.2489 - mae: 3.3188 - val_loss: 196.4373 - val_mae: 3.9712\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 167.63728\n",
      "Epoch 55/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 187.5820 - mae: 3.4265 - val_loss: 199.9704 - val_mae: 4.0149\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 167.63728\n",
      "Epoch 56/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 172.7195 - mae: 3.3640 - val_loss: 201.1362 - val_mae: 4.0298\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 167.63728\n",
      "Epoch 57/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 153.8394 - mae: 3.2520 - val_loss: 195.9632 - val_mae: 3.9898\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 167.63728\n",
      "Epoch 58/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 158.6635 - mae: 3.3360 - val_loss: 188.8062 - val_mae: 3.9212\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 167.63728\n",
      "Epoch 59/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 156.6173 - mae: 3.2507 - val_loss: 190.3078 - val_mae: 3.9511\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 167.63728\n",
      "Epoch 60/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 141.0836 - mae: 3.1689 - val_loss: 184.4743 - val_mae: 3.8943\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 167.63728\n",
      "Epoch 61/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 159.9956 - mae: 3.2391 - val_loss: 203.0040 - val_mae: 4.0829\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 167.63728\n",
      "Epoch 62/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 158.2710 - mae: 3.2678 - val_loss: 206.4077 - val_mae: 4.1150\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 167.63728\n",
      "Epoch 63/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 161.7463 - mae: 3.3150 - val_loss: 214.1691 - val_mae: 4.1874\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 167.63728\n",
      "Epoch 64/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 179.5661 - mae: 3.4179 - val_loss: 215.6558 - val_mae: 4.2037\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 167.63728\n",
      "Epoch 65/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 157.4079 - mae: 3.2490 - val_loss: 199.0905 - val_mae: 4.0548\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 167.63728\n",
      "Epoch 66/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 151.1539 - mae: 3.3000 - val_loss: 212.5782 - val_mae: 4.1809\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 167.63728\n",
      "Epoch 67/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 147.2178 - mae: 3.2508 - val_loss: 197.2745 - val_mae: 4.0429\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 167.63728\n",
      "Epoch 68/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 123.4623 - mae: 3.0083 - val_loss: 199.3216 - val_mae: 4.0655\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 167.63728\n",
      "Epoch 69/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 156.5489 - mae: 3.2003 - val_loss: 206.8961 - val_mae: 4.1362\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 167.63728\n",
      "Epoch 70/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 140.8170 - mae: 3.1635 - val_loss: 209.6433 - val_mae: 4.1616\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 167.63728\n",
      "Epoch 71/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 131.7789 - mae: 3.1093 - val_loss: 208.3810 - val_mae: 4.1549\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 167.63728\n",
      "Epoch 72/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 138.6161 - mae: 3.1866 - val_loss: 203.3117 - val_mae: 4.1068\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 167.63728\n",
      "Epoch 73/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 138.3518 - mae: 3.2034 - val_loss: 209.1688 - val_mae: 4.1601\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 167.63728\n",
      "Epoch 74/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 150.0538 - mae: 3.1629 - val_loss: 213.0668 - val_mae: 4.1915\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 167.63728\n",
      "Epoch 75/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 123.7515 - mae: 3.1320 - val_loss: 193.8777 - val_mae: 4.0127\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 167.63728\n",
      "Epoch 76/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 116.5698 - mae: 3.0239 - val_loss: 194.9271 - val_mae: 4.0174\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 167.63728\n",
      "Epoch 77/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 139.2719 - mae: 3.1196 - val_loss: 187.5739 - val_mae: 3.9463\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 167.63728\n",
      "Epoch 78/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 157.0711 - mae: 3.1943 - val_loss: 202.0003 - val_mae: 4.0781\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 167.63728\n",
      "Epoch 79/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 127.8202 - mae: 3.0354 - val_loss: 200.9295 - val_mae: 4.0656\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 167.63728\n",
      "Epoch 80/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 115.1456 - mae: 2.9498 - val_loss: 203.4477 - val_mae: 4.0861\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 167.63728\n",
      "Epoch 81/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 140.0861 - mae: 3.1176 - val_loss: 197.5828 - val_mae: 4.0281\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 167.63728\n",
      "Epoch 82/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 126.8994 - mae: 3.0173 - val_loss: 206.6633 - val_mae: 4.1065\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 167.63728\n",
      "Epoch 83/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 101.3165 - mae: 2.8647 - val_loss: 204.1107 - val_mae: 4.0767\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 167.63728\n",
      "Epoch 84/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 129.1798 - mae: 3.0094 - val_loss: 209.8145 - val_mae: 4.1238\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 167.63728\n",
      "Epoch 85/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 106.2561 - mae: 2.9503 - val_loss: 202.5531 - val_mae: 4.0417\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 167.63728\n",
      "Epoch 86/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 122.4364 - mae: 3.0029 - val_loss: 201.6640 - val_mae: 4.0246\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 167.63728\n",
      "Epoch 87/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 116.2041 - mae: 2.9365 - val_loss: 205.2554 - val_mae: 4.0554\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 167.63728\n",
      "Epoch 88/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 101.3619 - mae: 2.8229 - val_loss: 199.1565 - val_mae: 3.9883\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 167.63728\n",
      "Epoch 89/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 126.1233 - mae: 2.9755 - val_loss: 208.9290 - val_mae: 4.0818\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 167.63728\n",
      "Epoch 90/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 97.7297 - mae: 2.8351 - val_loss: 205.8067 - val_mae: 4.0370\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 167.63728\n",
      "Epoch 91/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 105.2739 - mae: 2.8488 - val_loss: 199.2983 - val_mae: 3.9698\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 167.63728\n",
      "Epoch 92/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 121.4274 - mae: 2.8725 - val_loss: 197.1556 - val_mae: 3.9459\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 167.63728\n",
      "Epoch 93/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 122.1905 - mae: 2.9292 - val_loss: 195.7402 - val_mae: 3.9306\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 167.63728\n",
      "Epoch 94/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 104.9272 - mae: 2.7514 - val_loss: 191.2047 - val_mae: 3.8749\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 167.63728\n",
      "Epoch 95/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 92.7344 - mae: 2.7425 - val_loss: 182.5417 - val_mae: 3.7798\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 167.63728\n",
      "Epoch 96/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 106.1106 - mae: 2.8614 - val_loss: 190.3177 - val_mae: 3.8504\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 167.63728\n",
      "Epoch 97/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 130.2300 - mae: 2.8870 - val_loss: 206.1645 - val_mae: 4.0056\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 167.63728\n",
      "Epoch 98/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 112.6722 - mae: 2.8706 - val_loss: 213.8822 - val_mae: 4.0629\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 167.63728\n",
      "Epoch 99/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 124.4935 - mae: 2.8682 - val_loss: 200.8281 - val_mae: 3.9326\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 167.63728\n",
      "Epoch 100/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 105.8460 - mae: 2.7569 - val_loss: 205.3626 - val_mae: 3.9723\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 167.63728\n",
      "Epoch 101/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 105.3671 - mae: 2.8025 - val_loss: 210.2126 - val_mae: 4.0105\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 167.63728\n",
      "Epoch 102/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 137.6165 - mae: 3.0426 - val_loss: 211.4030 - val_mae: 4.0122\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 167.63728\n",
      "Epoch 103/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 105.4660 - mae: 2.6962 - val_loss: 197.4501 - val_mae: 3.8675\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 167.63728\n",
      "Epoch 104/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 106.0038 - mae: 2.7440 - val_loss: 194.8918 - val_mae: 3.8251\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 167.63728\n",
      "Epoch 105/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 101.0116 - mae: 2.6972 - val_loss: 193.6183 - val_mae: 3.8001\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 167.63728\n",
      "Epoch 106/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 87.8647 - mae: 2.7026 - val_loss: 174.5833 - val_mae: 3.6163\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 167.63728\n",
      "Epoch 107/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 113.8204 - mae: 2.7816 - val_loss: 194.6980 - val_mae: 3.7782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00107: val_loss did not improve from 167.63728\n",
      "Epoch 108/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.3862 - mae: 2.6326 - val_loss: 182.0730 - val_mae: 3.6538\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 167.63728\n",
      "Epoch 109/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 111.0960 - mae: 2.6431 - val_loss: 199.6575 - val_mae: 3.7960\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 167.63728\n",
      "Epoch 110/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 91.3920 - mae: 2.6812 - val_loss: 210.7644 - val_mae: 3.8666\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 167.63728\n",
      "Epoch 111/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 90.7281 - mae: 2.6627 - val_loss: 202.1056 - val_mae: 3.8011\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 167.63728\n",
      "Epoch 112/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 103.3019 - mae: 2.6028 - val_loss: 219.3657 - val_mae: 3.9438\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 167.63728\n",
      "Epoch 113/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 110.2303 - mae: 2.7278 - val_loss: 200.2017 - val_mae: 3.7694\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 167.63728\n",
      "Epoch 114/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 98.9758 - mae: 2.6064 - val_loss: 203.4415 - val_mae: 3.7801\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 167.63728\n",
      "Epoch 115/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 120.0125 - mae: 2.7334 - val_loss: 214.8583 - val_mae: 3.8832\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 167.63728\n",
      "Epoch 116/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 81.9907 - mae: 2.5551 - val_loss: 206.8478 - val_mae: 3.7952\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 167.63728\n",
      "Epoch 117/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 88.6745 - mae: 2.5680 - val_loss: 211.0402 - val_mae: 3.8359\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 167.63728\n",
      "Epoch 118/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 95.8431 - mae: 2.5784 - val_loss: 202.8053 - val_mae: 3.7555\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 167.63728\n",
      "Epoch 119/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 92.9247 - mae: 2.5640 - val_loss: 209.0242 - val_mae: 3.7881\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 167.63728\n",
      "Epoch 120/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 112.4230 - mae: 2.7049 - val_loss: 196.5613 - val_mae: 3.6930\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 167.63728\n",
      "Epoch 121/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 113.5958 - mae: 2.6885 - val_loss: 201.6554 - val_mae: 3.7253\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 167.63728\n",
      "Epoch 122/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 82.1514 - mae: 2.4701 - val_loss: 226.2158 - val_mae: 3.8967\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 167.63728\n",
      "Epoch 123/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 109.7690 - mae: 2.7132 - val_loss: 223.8314 - val_mae: 3.8811\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 167.63728\n",
      "Epoch 124/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.5109 - mae: 2.4674 - val_loss: 234.6230 - val_mae: 3.9828\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 167.63728\n",
      "Epoch 125/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 116.0627 - mae: 2.6279 - val_loss: 245.6665 - val_mae: 4.0608\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 167.63728\n",
      "Epoch 126/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 108.9601 - mae: 2.6738 - val_loss: 208.1516 - val_mae: 3.7463\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 167.63728\n",
      "Epoch 127/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 99.6561 - mae: 2.5745 - val_loss: 209.2306 - val_mae: 3.7625\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 167.63728\n",
      "Epoch 128/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 125.6316 - mae: 2.7918 - val_loss: 197.4233 - val_mae: 3.6410\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 167.63728\n",
      "Epoch 129/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.4002 - mae: 2.4970 - val_loss: 185.9447 - val_mae: 3.5080\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 167.63728\n",
      "Epoch 130/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 95.9829 - mae: 2.6662 - val_loss: 189.5748 - val_mae: 3.5402\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 167.63728\n",
      "Epoch 131/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 93.6969 - mae: 2.5033 - val_loss: 213.7747 - val_mae: 3.7425\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 167.63728\n",
      "Epoch 132/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 73.3977 - mae: 2.4045 - val_loss: 206.7629 - val_mae: 3.6968\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 167.63728\n",
      "Epoch 133/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.5597 - mae: 2.5044 - val_loss: 192.4885 - val_mae: 3.5496\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 167.63728\n",
      "Epoch 134/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 81.8018 - mae: 2.4441 - val_loss: 204.8820 - val_mae: 3.6647\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 167.63728\n",
      "Epoch 135/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.2194 - mae: 2.6892 - val_loss: 212.4539 - val_mae: 3.7492\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 167.63728\n",
      "Epoch 136/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 93.4273 - mae: 2.5441 - val_loss: 197.2716 - val_mae: 3.6242\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 167.63728\n",
      "Epoch 137/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 103.3171 - mae: 2.6085 - val_loss: 213.0315 - val_mae: 3.7236\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 167.63728\n",
      "Epoch 138/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 82.1635 - mae: 2.4181 - val_loss: 203.4520 - val_mae: 3.6491\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 167.63728\n",
      "Epoch 139/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 83.8823 - mae: 2.4573 - val_loss: 213.7926 - val_mae: 3.7288\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 167.63728\n",
      "Epoch 140/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.6963 - mae: 2.6279 - val_loss: 224.4877 - val_mae: 3.8277\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 167.63728\n",
      "Epoch 141/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 92.1237 - mae: 2.4742 - val_loss: 215.4220 - val_mae: 3.7433\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 167.63728\n",
      "Epoch 142/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 103.1635 - mae: 2.6650 - val_loss: 201.8610 - val_mae: 3.6327\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 167.63728\n",
      "Epoch 143/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 83.3159 - mae: 2.5313 - val_loss: 204.9797 - val_mae: 3.6690\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 167.63728\n",
      "Epoch 144/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 86.6921 - mae: 2.4347 - val_loss: 232.7919 - val_mae: 3.8992\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 167.63728\n",
      "Epoch 145/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 98.1373 - mae: 2.4041 - val_loss: 215.2974 - val_mae: 3.7712\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 167.63728\n",
      "Epoch 146/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 90.8678 - mae: 2.5039 - val_loss: 218.9447 - val_mae: 3.7996\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 167.63728\n",
      "Epoch 147/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 75.5882 - mae: 2.3557 - val_loss: 217.3154 - val_mae: 3.7814\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 167.63728\n",
      "Epoch 148/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 97.1149 - mae: 2.5955 - val_loss: 198.8471 - val_mae: 3.6039\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 167.63728\n",
      "Epoch 149/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 88.9151 - mae: 2.4183 - val_loss: 199.6593 - val_mae: 3.6027\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 167.63728\n",
      "Epoch 150/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.9495 - mae: 2.6088 - val_loss: 207.9830 - val_mae: 3.6806\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 167.63728\n",
      "Epoch 151/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 86.2719 - mae: 2.4252 - val_loss: 214.5113 - val_mae: 3.7457\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 167.63728\n",
      "Epoch 152/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.2009 - mae: 2.3786 - val_loss: 216.6881 - val_mae: 3.7628\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 167.63728\n",
      "Epoch 153/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 92.9106 - mae: 2.3978 - val_loss: 210.9568 - val_mae: 3.7254\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 167.63728\n",
      "Epoch 154/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.0856 - mae: 2.4940 - val_loss: 209.4332 - val_mae: 3.7013\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 167.63728\n",
      "Epoch 155/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 91.3082 - mae: 2.5759 - val_loss: 223.4591 - val_mae: 3.8519\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 167.63728\n",
      "Epoch 156/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 105.5274 - mae: 2.6666 - val_loss: 217.3111 - val_mae: 3.7596\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 167.63728\n",
      "Epoch 157/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 111.0535 - mae: 2.5487 - val_loss: 221.1453 - val_mae: 3.7941\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 167.63728\n",
      "Epoch 158/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 112.1494 - mae: 2.7335 - val_loss: 239.4470 - val_mae: 3.9639\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 167.63728\n",
      "Epoch 159/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 109.6445 - mae: 2.5472 - val_loss: 219.6236 - val_mae: 3.7898\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 167.63728\n",
      "Epoch 160/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 89.8839 - mae: 2.4269 - val_loss: 207.5845 - val_mae: 3.6553\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 167.63728\n",
      "Epoch 161/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 89.3490 - mae: 2.4571 - val_loss: 240.0958 - val_mae: 3.9230\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 167.63728\n",
      "Epoch 162/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 111.2098 - mae: 2.6549 - val_loss: 256.7603 - val_mae: 4.0849\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 167.63728\n",
      "Epoch 163/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.5321 - mae: 2.5197 - val_loss: 268.0558 - val_mae: 4.1857\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 167.63728\n",
      "Epoch 164/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.8701 - mae: 2.5175 - val_loss: 256.8519 - val_mae: 4.0892\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 167.63728\n",
      "Epoch 165/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 86.0916 - mae: 2.4327 - val_loss: 243.8687 - val_mae: 3.9958\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 167.63728\n",
      "Epoch 166/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 112.0048 - mae: 2.5459 - val_loss: 242.8030 - val_mae: 3.9673\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 167.63728\n",
      "Epoch 167/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 73.1275 - mae: 2.4329 - val_loss: 220.5215 - val_mae: 3.7364\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 167.63728\n",
      "Epoch 168/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 75.8697 - mae: 2.3672 - val_loss: 218.2630 - val_mae: 3.7178\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 167.63728\n",
      "Epoch 169/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 76.4961 - mae: 2.4470 - val_loss: 222.1402 - val_mae: 3.7605\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 167.63728\n",
      "Epoch 170/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.3580 - mae: 2.4786 - val_loss: 242.8049 - val_mae: 3.9680\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 167.63728\n",
      "Epoch 171/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.7136 - mae: 2.5074 - val_loss: 224.0252 - val_mae: 3.7971\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 167.63728\n",
      "Epoch 172/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 94.0438 - mae: 2.5385 - val_loss: 218.2254 - val_mae: 3.7560\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 167.63728\n",
      "Epoch 173/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 92.2172 - mae: 2.5253 - val_loss: 206.2784 - val_mae: 3.6361\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 167.63728\n",
      "Epoch 174/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 93.4748 - mae: 2.5013 - val_loss: 222.6830 - val_mae: 3.7748\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 167.63728\n",
      "Epoch 175/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 85.9895 - mae: 2.4808 - val_loss: 216.5100 - val_mae: 3.6962\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 167.63728\n",
      "Epoch 176/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 85.4678 - mae: 2.3909 - val_loss: 223.8426 - val_mae: 3.7916\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 167.63728\n",
      "Epoch 177/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 90.9951 - mae: 2.4754 - val_loss: 226.2241 - val_mae: 3.8087\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 167.63728\n",
      "Epoch 178/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 71.0587 - mae: 2.3860 - val_loss: 226.7739 - val_mae: 3.8131\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 167.63728\n",
      "Epoch 179/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 92.9796 - mae: 2.4477 - val_loss: 221.5302 - val_mae: 3.7657\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 167.63728\n",
      "Epoch 180/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.8607 - mae: 2.3756 - val_loss: 236.3646 - val_mae: 3.9201\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 167.63728\n",
      "Epoch 181/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 92.8269 - mae: 2.4826 - val_loss: 228.5322 - val_mae: 3.8440\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 167.63728\n",
      "Epoch 182/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 92.0109 - mae: 2.5100 - val_loss: 224.7186 - val_mae: 3.8291\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 167.63728\n",
      "Epoch 183/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.4917 - mae: 2.3100 - val_loss: 220.8025 - val_mae: 3.7546\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 167.63728\n",
      "Epoch 184/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 75.5022 - mae: 2.3727 - val_loss: 233.1637 - val_mae: 3.9034\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 167.63728\n",
      "Epoch 185/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 119.7259 - mae: 2.6017 - val_loss: 252.0466 - val_mae: 4.0684\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 167.63728\n",
      "Epoch 186/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 79.9955 - mae: 2.4718 - val_loss: 223.2620 - val_mae: 3.7907\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 167.63728\n",
      "Epoch 187/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 76.1623 - mae: 2.3058 - val_loss: 218.2044 - val_mae: 3.7498\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 167.63728\n",
      "Epoch 188/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.7951 - mae: 2.3809 - val_loss: 222.9621 - val_mae: 3.7813\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 167.63728\n",
      "Epoch 189/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 108.7481 - mae: 2.5902 - val_loss: 208.8218 - val_mae: 3.6490\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 167.63728\n",
      "Epoch 190/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 76.4175 - mae: 2.3570 - val_loss: 222.9472 - val_mae: 3.7853\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 167.63728\n",
      "Epoch 191/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.0176 - mae: 2.2733 - val_loss: 225.5299 - val_mae: 3.7760\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 167.63728\n",
      "Epoch 192/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 79.9757 - mae: 2.3377 - val_loss: 210.0404 - val_mae: 3.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00192: val_loss did not improve from 167.63728\n",
      "Epoch 193/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 93.2846 - mae: 2.5821 - val_loss: 222.1268 - val_mae: 3.7613\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 167.63728\n",
      "Epoch 194/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.0774 - mae: 2.2376 - val_loss: 222.9203 - val_mae: 3.7505\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 167.63728\n",
      "Epoch 195/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 86.2681 - mae: 2.5215 - val_loss: 242.7959 - val_mae: 3.9401\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 167.63728\n",
      "Epoch 196/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 83.7229 - mae: 2.4124 - val_loss: 217.8090 - val_mae: 3.7499\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 167.63728\n",
      "Epoch 197/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 67.5920 - mae: 2.3741 - val_loss: 210.0418 - val_mae: 3.6488\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 167.63728\n",
      "Epoch 198/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.3589 - mae: 2.4529 - val_loss: 214.4415 - val_mae: 3.6730\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 167.63728\n",
      "Epoch 199/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 75.7321 - mae: 2.3832 - val_loss: 233.9454 - val_mae: 3.8590\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 167.63728\n",
      "Epoch 200/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 77.3730 - mae: 2.2817 - val_loss: 221.8028 - val_mae: 3.7534\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 167.63728\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 2\n",
    "\"\"\"\n",
    "model_feature3 = create_model(n, Adam(learning_rate = 0.0001), 0.2)\n",
    "\n",
    "history_feature3 = model_feature3.fit(X_train3,\n",
    "                                      y_train3,\n",
    "                                      validation_split = 0.2,\n",
    "                                      epochs=200,\n",
    "                                      batch_size=5,\n",
    "                                      verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 251.3824 - mae: 3.1760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[251.3824005126953, 3.1759533882141113]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 3\n",
    "\"\"\"\n",
    "plt.plot(history_feature3.history['mae'])\n",
    "plt.plot(history_feature3.history['val_mae'])\n",
    "plt.title('Tree Based')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(top = 8)\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "score_feature3 = model_feature3.evaluate(X_test3, y_test3, verbose=1)\n",
    "score_feature3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "117/117 [==============================] - 1s 2ms/step - loss: 921.3542 - mae: 6.2648 - val_loss: 846.1032 - val_mae: 7.7685\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 846.10321, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 2/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 921.0167 - mae: 6.2277 - val_loss: 844.8660 - val_mae: 7.7179\n",
      "\n",
      "Epoch 00002: val_loss improved from 846.10321 to 844.86603, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 3/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 915.2953 - mae: 6.1731 - val_loss: 838.8210 - val_mae: 7.6554\n",
      "\n",
      "Epoch 00003: val_loss improved from 844.86603 to 838.82098, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 4/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 908.1135 - mae: 6.1548 - val_loss: 831.4495 - val_mae: 7.6233\n",
      "\n",
      "Epoch 00004: val_loss improved from 838.82098 to 831.44952, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 5/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 901.7380 - mae: 6.1516 - val_loss: 822.8719 - val_mae: 7.5978\n",
      "\n",
      "Epoch 00005: val_loss improved from 831.44952 to 822.87189, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 6/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 892.9014 - mae: 6.1459 - val_loss: 814.7880 - val_mae: 7.5763\n",
      "\n",
      "Epoch 00006: val_loss improved from 822.87189 to 814.78796, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 7/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 879.9149 - mae: 6.1460 - val_loss: 804.8406 - val_mae: 7.5474\n",
      "\n",
      "Epoch 00007: val_loss improved from 814.78796 to 804.84058, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 8/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 871.1829 - mae: 6.1530 - val_loss: 793.4730 - val_mae: 7.5123\n",
      "\n",
      "Epoch 00008: val_loss improved from 804.84058 to 793.47296, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 9/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 859.7030 - mae: 6.1517 - val_loss: 780.7112 - val_mae: 7.4753\n",
      "\n",
      "Epoch 00009: val_loss improved from 793.47296 to 780.71118, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 10/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 847.6268 - mae: 6.1523 - val_loss: 767.5741 - val_mae: 7.4480\n",
      "\n",
      "Epoch 00010: val_loss improved from 780.71118 to 767.57410, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 11/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 843.1069 - mae: 6.1831 - val_loss: 753.2628 - val_mae: 7.4162\n",
      "\n",
      "Epoch 00011: val_loss improved from 767.57410 to 753.26282, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 12/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 829.2224 - mae: 6.1507 - val_loss: 737.0543 - val_mae: 7.3874\n",
      "\n",
      "Epoch 00012: val_loss improved from 753.26282 to 737.05426, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 13/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 815.2020 - mae: 6.1514 - val_loss: 719.4524 - val_mae: 7.3597\n",
      "\n",
      "Epoch 00013: val_loss improved from 737.05426 to 719.45239, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 14/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 787.1721 - mae: 6.1322 - val_loss: 703.8919 - val_mae: 7.3171\n",
      "\n",
      "Epoch 00014: val_loss improved from 719.45239 to 703.89191, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 15/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 773.7516 - mae: 6.1586 - val_loss: 681.2246 - val_mae: 7.2630\n",
      "\n",
      "Epoch 00015: val_loss improved from 703.89191 to 681.22461, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 16/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 746.0905 - mae: 6.1053 - val_loss: 659.7183 - val_mae: 7.1846\n",
      "\n",
      "Epoch 00016: val_loss improved from 681.22461 to 659.71826, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 17/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 733.4355 - mae: 6.0653 - val_loss: 635.7253 - val_mae: 7.0928\n",
      "\n",
      "Epoch 00017: val_loss improved from 659.71826 to 635.72528, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 18/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 708.9370 - mae: 6.0323 - val_loss: 611.9320 - val_mae: 6.9707\n",
      "\n",
      "Epoch 00018: val_loss improved from 635.72528 to 611.93201, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 19/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 668.0025 - mae: 5.8761 - val_loss: 586.1915 - val_mae: 6.8284\n",
      "\n",
      "Epoch 00019: val_loss improved from 611.93201 to 586.19147, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 20/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 644.0094 - mae: 5.7661 - val_loss: 556.7855 - val_mae: 6.6755\n",
      "\n",
      "Epoch 00020: val_loss improved from 586.19147 to 556.78546, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 21/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 619.3396 - mae: 5.6738 - val_loss: 529.9994 - val_mae: 6.4698\n",
      "\n",
      "Epoch 00021: val_loss improved from 556.78546 to 529.99939, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 22/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 600.5721 - mae: 5.5382 - val_loss: 504.2829 - val_mae: 6.2481\n",
      "\n",
      "Epoch 00022: val_loss improved from 529.99939 to 504.28287, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 23/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 561.9406 - mae: 5.3222 - val_loss: 470.8534 - val_mae: 5.9603\n",
      "\n",
      "Epoch 00023: val_loss improved from 504.28287 to 470.85342, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 24/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 550.6323 - mae: 5.2325 - val_loss: 441.5012 - val_mae: 5.6760\n",
      "\n",
      "Epoch 00024: val_loss improved from 470.85342 to 441.50122, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 25/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 496.7645 - mae: 4.9851 - val_loss: 411.3732 - val_mae: 5.4107\n",
      "\n",
      "Epoch 00025: val_loss improved from 441.50122 to 411.37320, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 26/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 483.5447 - mae: 4.8509 - val_loss: 383.9988 - val_mae: 5.1584\n",
      "\n",
      "Epoch 00026: val_loss improved from 411.37320 to 383.99881, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 27/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 436.5229 - mae: 4.5601 - val_loss: 355.7614 - val_mae: 4.8886\n",
      "\n",
      "Epoch 00027: val_loss improved from 383.99881 to 355.76138, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 28/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 427.6320 - mae: 4.5127 - val_loss: 330.6962 - val_mae: 4.6327\n",
      "\n",
      "Epoch 00028: val_loss improved from 355.76138 to 330.69617, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 390.5045 - mae: 4.2205 - val_loss: 311.9376 - val_mae: 4.4337\n",
      "\n",
      "Epoch 00029: val_loss improved from 330.69617 to 311.93759, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 30/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 357.4583 - mae: 4.1292 - val_loss: 282.2337 - val_mae: 4.2179\n",
      "\n",
      "Epoch 00030: val_loss improved from 311.93759 to 282.23370, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 31/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 343.1353 - mae: 4.0290 - val_loss: 261.9954 - val_mae: 4.0462\n",
      "\n",
      "Epoch 00031: val_loss improved from 282.23370 to 261.99536, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 32/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 343.6653 - mae: 3.9647 - val_loss: 242.7767 - val_mae: 3.9068\n",
      "\n",
      "Epoch 00032: val_loss improved from 261.99536 to 242.77675, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 33/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 343.7253 - mae: 3.8508 - val_loss: 228.8166 - val_mae: 3.7861\n",
      "\n",
      "Epoch 00033: val_loss improved from 242.77675 to 228.81659, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 34/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 307.5451 - mae: 3.6880 - val_loss: 210.3326 - val_mae: 3.6829\n",
      "\n",
      "Epoch 00034: val_loss improved from 228.81659 to 210.33257, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 35/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 308.4378 - mae: 3.7438 - val_loss: 194.0322 - val_mae: 3.5874\n",
      "\n",
      "Epoch 00035: val_loss improved from 210.33257 to 194.03220, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 36/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 261.1360 - mae: 3.5012 - val_loss: 188.1165 - val_mae: 3.5230\n",
      "\n",
      "Epoch 00036: val_loss improved from 194.03220 to 188.11646, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 37/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 274.6599 - mae: 3.5312 - val_loss: 169.7458 - val_mae: 3.4344\n",
      "\n",
      "Epoch 00037: val_loss improved from 188.11646 to 169.74577, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 38/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 245.9398 - mae: 3.5702 - val_loss: 161.2769 - val_mae: 3.3388\n",
      "\n",
      "Epoch 00038: val_loss improved from 169.74577 to 161.27687, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 39/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 221.3089 - mae: 3.3692 - val_loss: 151.3080 - val_mae: 3.2526\n",
      "\n",
      "Epoch 00039: val_loss improved from 161.27687 to 151.30797, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 40/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 212.2465 - mae: 3.3967 - val_loss: 143.8618 - val_mae: 3.1951\n",
      "\n",
      "Epoch 00040: val_loss improved from 151.30797 to 143.86182, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 41/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 228.5379 - mae: 3.3274 - val_loss: 138.8165 - val_mae: 3.1355\n",
      "\n",
      "Epoch 00041: val_loss improved from 143.86182 to 138.81648, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 42/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 224.2376 - mae: 3.2937 - val_loss: 133.2098 - val_mae: 3.0800\n",
      "\n",
      "Epoch 00042: val_loss improved from 138.81648 to 133.20981, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 43/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 194.0051 - mae: 3.2686 - val_loss: 128.8953 - val_mae: 3.0208\n",
      "\n",
      "Epoch 00043: val_loss improved from 133.20981 to 128.89526, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 44/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 173.4706 - mae: 3.2032 - val_loss: 125.9020 - val_mae: 2.9894\n",
      "\n",
      "Epoch 00044: val_loss improved from 128.89526 to 125.90199, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 45/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 192.6359 - mae: 3.2718 - val_loss: 124.5215 - val_mae: 3.0334\n",
      "\n",
      "Epoch 00045: val_loss improved from 125.90199 to 124.52145, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 46/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 187.9266 - mae: 3.3321 - val_loss: 120.5630 - val_mae: 3.0024\n",
      "\n",
      "Epoch 00046: val_loss improved from 124.52145 to 120.56297, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 47/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 209.2989 - mae: 3.3782 - val_loss: 118.6950 - val_mae: 3.0085\n",
      "\n",
      "Epoch 00047: val_loss improved from 120.56297 to 118.69503, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 48/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 189.0568 - mae: 3.1988 - val_loss: 118.1338 - val_mae: 3.0216\n",
      "\n",
      "Epoch 00048: val_loss improved from 118.69503 to 118.13384, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 49/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 190.0221 - mae: 3.1575 - val_loss: 118.3373 - val_mae: 3.0356\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 118.13384\n",
      "Epoch 50/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 165.8074 - mae: 3.1303 - val_loss: 116.5254 - val_mae: 3.0104\n",
      "\n",
      "Epoch 00050: val_loss improved from 118.13384 to 116.52535, saving model to validation_loss_m2\n",
      "INFO:tensorflow:Assets written to: validation_loss_m2\\assets\n",
      "Epoch 51/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 175.2424 - mae: 3.0514 - val_loss: 120.8915 - val_mae: 3.0921\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 116.52535\n",
      "Epoch 52/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 169.6716 - mae: 3.1138 - val_loss: 125.2411 - val_mae: 3.1806\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 116.52535\n",
      "Epoch 53/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 147.8564 - mae: 3.0360 - val_loss: 124.7428 - val_mae: 3.1838\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 116.52535\n",
      "Epoch 54/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 123.7583 - mae: 2.8777 - val_loss: 127.7630 - val_mae: 3.2322\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 116.52535\n",
      "Epoch 55/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 128.0588 - mae: 2.9568 - val_loss: 132.8949 - val_mae: 3.2989\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 116.52535\n",
      "Epoch 56/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 125.6435 - mae: 2.8834 - val_loss: 131.7643 - val_mae: 3.2850\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 116.52535\n",
      "Epoch 57/200\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 117.1266 - mae: 2.7778 - val_loss: 133.6484 - val_mae: 3.3003\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 116.52535\n",
      "Epoch 58/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 125.6883 - mae: 2.8421 - val_loss: 142.1966 - val_mae: 3.3914\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 116.52535\n",
      "Epoch 59/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 146.4799 - mae: 2.9074 - val_loss: 143.6974 - val_mae: 3.3893\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 116.52535\n",
      "Epoch 60/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 146.3333 - mae: 2.8855 - val_loss: 150.4254 - val_mae: 3.4324\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 116.52535\n",
      "Epoch 61/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 90.3982 - mae: 2.6575 - val_loss: 155.4284 - val_mae: 3.4673\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 116.52535\n",
      "Epoch 62/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 133.8145 - mae: 2.8487 - val_loss: 162.9200 - val_mae: 3.5131\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 116.52535\n",
      "Epoch 63/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 119.2135 - mae: 2.7538 - val_loss: 163.2467 - val_mae: 3.4939\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 116.52535\n",
      "Epoch 64/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 107.9855 - mae: 2.6466 - val_loss: 170.9905 - val_mae: 3.5324\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 116.52535\n",
      "Epoch 65/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 98.6764 - mae: 2.6897 - val_loss: 175.1230 - val_mae: 3.5481\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 116.52535\n",
      "Epoch 66/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 120.7848 - mae: 2.8404 - val_loss: 180.7735 - val_mae: 3.5735\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 116.52535\n",
      "Epoch 67/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 100.2072 - mae: 2.5689 - val_loss: 187.9589 - val_mae: 3.5939\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 116.52535\n",
      "Epoch 68/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 92.3661 - mae: 2.6132 - val_loss: 189.4339 - val_mae: 3.5756\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 116.52535\n",
      "Epoch 69/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 141.8559 - mae: 2.7370 - val_loss: 198.9226 - val_mae: 3.6030\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 116.52535\n",
      "Epoch 70/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 88.5540 - mae: 2.5778 - val_loss: 210.7640 - val_mae: 3.6559\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 116.52535\n",
      "Epoch 71/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 110.7322 - mae: 2.7577 - val_loss: 206.9516 - val_mae: 3.6022\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 116.52535\n",
      "Epoch 72/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.3976 - mae: 2.5907 - val_loss: 226.1169 - val_mae: 3.6861\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 116.52535\n",
      "Epoch 73/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 102.3183 - mae: 2.6197 - val_loss: 230.4722 - val_mae: 3.6797\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 116.52535\n",
      "Epoch 74/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 72.0886 - mae: 2.4669 - val_loss: 230.8881 - val_mae: 3.6533\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 116.52535\n",
      "Epoch 75/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.8926 - mae: 2.5869 - val_loss: 240.3707 - val_mae: 3.6732\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 116.52535\n",
      "Epoch 76/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.9634 - mae: 2.5155 - val_loss: 256.0559 - val_mae: 3.7404\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 116.52535\n",
      "Epoch 77/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 93.4283 - mae: 2.4906 - val_loss: 264.8297 - val_mae: 3.7636\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 116.52535\n",
      "Epoch 78/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 79.8248 - mae: 2.4811 - val_loss: 275.2798 - val_mae: 3.8081\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 116.52535\n",
      "Epoch 79/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 88.9235 - mae: 2.5432 - val_loss: 287.5137 - val_mae: 3.8501\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 116.52535\n",
      "Epoch 80/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 97.2557 - mae: 2.6209 - val_loss: 286.8900 - val_mae: 3.8105\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 116.52535\n",
      "Epoch 81/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.6070 - mae: 2.3863 - val_loss: 291.5107 - val_mae: 3.8183\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 116.52535\n",
      "Epoch 82/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 76.5213 - mae: 2.4408 - val_loss: 295.6609 - val_mae: 3.8135\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 116.52535\n",
      "Epoch 83/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.9146 - mae: 2.4259 - val_loss: 304.4979 - val_mae: 3.8251\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 116.52535\n",
      "Epoch 84/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 59.6588 - mae: 2.3000 - val_loss: 309.3008 - val_mae: 3.8303\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 116.52535\n",
      "Epoch 85/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 80.1464 - mae: 2.4978 - val_loss: 315.1391 - val_mae: 3.8277\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 116.52535\n",
      "Epoch 86/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.5080 - mae: 2.3827 - val_loss: 314.0377 - val_mae: 3.8070\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 116.52535\n",
      "Epoch 87/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 93.4454 - mae: 2.3883 - val_loss: 305.2973 - val_mae: 3.7157\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 116.52535\n",
      "Epoch 88/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.2872 - mae: 2.4586 - val_loss: 324.6467 - val_mae: 3.7741\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 116.52535\n",
      "Epoch 89/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 83.3049 - mae: 2.5098 - val_loss: 344.1722 - val_mae: 3.8384\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 116.52535\n",
      "Epoch 90/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 49.5430 - mae: 2.1770 - val_loss: 350.6746 - val_mae: 3.8489\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 116.52535\n",
      "Epoch 91/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.5315 - mae: 2.4334 - val_loss: 370.4621 - val_mae: 3.9152\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 116.52535\n",
      "Epoch 92/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 80.5457 - mae: 2.3959 - val_loss: 405.3931 - val_mae: 4.0423\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 116.52535\n",
      "Epoch 93/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.3323 - mae: 2.2625 - val_loss: 413.7817 - val_mae: 4.0630\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 116.52535\n",
      "Epoch 94/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.1089 - mae: 2.3774 - val_loss: 435.7352 - val_mae: 4.1366\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 116.52535\n",
      "Epoch 95/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 49.7247 - mae: 2.1930 - val_loss: 428.5741 - val_mae: 4.0958\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 116.52535\n",
      "Epoch 96/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 80.1441 - mae: 2.4495 - val_loss: 445.2067 - val_mae: 4.1402\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 116.52535\n",
      "Epoch 97/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.9023 - mae: 2.1921 - val_loss: 423.3765 - val_mae: 4.0164\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 116.52535\n",
      "Epoch 98/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 102.1141 - mae: 2.5026 - val_loss: 463.7407 - val_mae: 4.1652\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 116.52535\n",
      "Epoch 99/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.5611 - mae: 2.3282 - val_loss: 435.3928 - val_mae: 4.0116\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 116.52535\n",
      "Epoch 100/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.5589 - mae: 2.2266 - val_loss: 441.8742 - val_mae: 4.0160\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 116.52535\n",
      "Epoch 101/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 60.8304 - mae: 2.2854 - val_loss: 448.5444 - val_mae: 4.0155\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 116.52535\n",
      "Epoch 102/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.2344 - mae: 2.2143 - val_loss: 461.4043 - val_mae: 4.0516\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 116.52535\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 54.8086 - mae: 2.2704 - val_loss: 463.4113 - val_mae: 4.0310\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 116.52535\n",
      "Epoch 104/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.1635 - mae: 2.1661 - val_loss: 451.8815 - val_mae: 3.9680\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 116.52535\n",
      "Epoch 105/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.3596 - mae: 2.0383 - val_loss: 451.5980 - val_mae: 3.9426\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 116.52535\n",
      "Epoch 106/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.7095 - mae: 2.2737 - val_loss: 486.9174 - val_mae: 4.0604\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 116.52535\n",
      "Epoch 107/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.0131 - mae: 2.3862 - val_loss: 479.3762 - val_mae: 4.0174\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 116.52535\n",
      "Epoch 108/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.8299 - mae: 2.1941 - val_loss: 446.5978 - val_mae: 3.8798\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 116.52535\n",
      "Epoch 109/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 51.8473 - mae: 2.1228 - val_loss: 502.9235 - val_mae: 4.0869\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 116.52535\n",
      "Epoch 110/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.0182 - mae: 2.1271 - val_loss: 510.3351 - val_mae: 4.1079\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 116.52535\n",
      "Epoch 111/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.5934 - mae: 2.2996 - val_loss: 513.1483 - val_mae: 4.0871\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 116.52535\n",
      "Epoch 112/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 55.9472 - mae: 2.1685 - val_loss: 542.5685 - val_mae: 4.1763\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 116.52535\n",
      "Epoch 113/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 54.6817 - mae: 2.1746 - val_loss: 572.0623 - val_mae: 4.3087\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 116.52535\n",
      "Epoch 114/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.1171 - mae: 2.0913 - val_loss: 539.2310 - val_mae: 4.1624\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 116.52535\n",
      "Epoch 115/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.4256 - mae: 2.0758 - val_loss: 499.2090 - val_mae: 4.0461\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 116.52535\n",
      "Epoch 116/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.1906 - mae: 2.0598 - val_loss: 470.5439 - val_mae: 3.9547\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 116.52535\n",
      "Epoch 117/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 61.2997 - mae: 2.2464 - val_loss: 459.8250 - val_mae: 3.9072\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 116.52535\n",
      "Epoch 118/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.6563 - mae: 2.1216 - val_loss: 485.5936 - val_mae: 4.0002\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 116.52535\n",
      "Epoch 119/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6684 - mae: 2.3570 - val_loss: 485.4000 - val_mae: 3.9885\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 116.52535\n",
      "Epoch 120/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 59.4325 - mae: 2.2675 - val_loss: 491.3063 - val_mae: 3.9979\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 116.52535\n",
      "Epoch 121/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.9459 - mae: 2.0647 - val_loss: 554.5979 - val_mae: 4.2090\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 116.52535\n",
      "Epoch 122/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 49.6954 - mae: 2.1590 - val_loss: 539.8276 - val_mae: 4.1459\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 116.52535\n",
      "Epoch 123/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 42.6992 - mae: 2.0092 - val_loss: 530.4456 - val_mae: 4.1153\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 116.52535\n",
      "Epoch 124/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 50.5012 - mae: 2.1053 - val_loss: 542.1695 - val_mae: 4.1712\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 116.52535\n",
      "Epoch 125/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 57.6067 - mae: 2.1630 - val_loss: 541.5301 - val_mae: 4.1778\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 116.52535\n",
      "Epoch 126/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.0324 - mae: 1.9546 - val_loss: 556.3099 - val_mae: 4.2459\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 116.52535\n",
      "Epoch 127/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 46.0146 - mae: 2.0369 - val_loss: 566.5850 - val_mae: 4.3054\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 116.52535\n",
      "Epoch 128/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.0433 - mae: 2.1174 - val_loss: 594.8010 - val_mae: 4.4092\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 116.52535\n",
      "Epoch 129/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 53.6624 - mae: 2.0943 - val_loss: 552.1889 - val_mae: 4.2411\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 116.52535\n",
      "Epoch 130/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.8590 - mae: 2.0182 - val_loss: 545.9394 - val_mae: 4.1930\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 116.52535\n",
      "Epoch 131/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.1567 - mae: 1.9737 - val_loss: 594.2060 - val_mae: 4.3808\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 116.52535\n",
      "Epoch 132/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.2354 - mae: 2.0035 - val_loss: 614.6000 - val_mae: 4.4549\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 116.52535\n",
      "Epoch 133/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 55.4986 - mae: 2.2829 - val_loss: 614.2690 - val_mae: 4.4778\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 116.52535\n",
      "Epoch 134/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.2103 - mae: 2.0183 - val_loss: 547.0386 - val_mae: 4.2060\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 116.52535\n",
      "Epoch 135/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.6927 - mae: 2.1363 - val_loss: 569.1342 - val_mae: 4.2930\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 116.52535\n",
      "Epoch 136/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 42.7703 - mae: 2.0363 - val_loss: 578.5529 - val_mae: 4.3257\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 116.52535\n",
      "Epoch 137/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 30.7062 - mae: 1.7893 - val_loss: 586.1327 - val_mae: 4.3428\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 116.52535\n",
      "Epoch 138/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.5403 - mae: 1.9934 - val_loss: 574.1282 - val_mae: 4.2934\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 116.52535\n",
      "Epoch 139/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.0081 - mae: 2.0924 - val_loss: 578.9741 - val_mae: 4.3105\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 116.52535\n",
      "Epoch 140/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.8635 - mae: 1.9001 - val_loss: 629.9156 - val_mae: 4.4942\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 116.52535\n",
      "Epoch 141/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 51.4276 - mae: 2.1065 - val_loss: 609.8263 - val_mae: 4.4064\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 116.52535\n",
      "Epoch 142/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.9754 - mae: 2.1678 - val_loss: 590.1531 - val_mae: 4.3014\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 116.52535\n",
      "Epoch 143/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.7536 - mae: 1.8541 - val_loss: 551.2159 - val_mae: 4.1636\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 116.52535\n",
      "Epoch 144/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.4074 - mae: 1.9756 - val_loss: 589.7734 - val_mae: 4.2931\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 116.52535\n",
      "Epoch 145/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.8855 - mae: 2.0336 - val_loss: 597.2271 - val_mae: 4.3169\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 116.52535\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 43.7064 - mae: 1.9707 - val_loss: 604.6204 - val_mae: 4.3649\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 116.52535\n",
      "Epoch 147/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 60.4008 - mae: 2.1266 - val_loss: 590.1796 - val_mae: 4.3394\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 116.52535\n",
      "Epoch 148/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 34.5908 - mae: 1.9011 - val_loss: 585.2962 - val_mae: 4.3356\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 116.52535\n",
      "Epoch 149/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.3569 - mae: 2.1330 - val_loss: 584.3234 - val_mae: 4.3378\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 116.52535\n",
      "Epoch 150/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.9931 - mae: 1.9468 - val_loss: 620.5919 - val_mae: 4.4900\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 116.52535\n",
      "Epoch 151/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.2757 - mae: 1.8311 - val_loss: 595.9816 - val_mae: 4.3928\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 116.52535\n",
      "Epoch 152/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 55.6080 - mae: 2.1359 - val_loss: 544.2589 - val_mae: 4.2566\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 116.52535\n",
      "Epoch 153/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.2307 - mae: 1.9793 - val_loss: 590.1039 - val_mae: 4.4226\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 116.52535\n",
      "Epoch 154/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.3865 - mae: 2.1107 - val_loss: 591.4581 - val_mae: 4.4129\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 116.52535\n",
      "Epoch 155/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.1422 - mae: 1.9317 - val_loss: 613.3519 - val_mae: 4.4946\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 116.52535\n",
      "Epoch 156/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.2617 - mae: 1.9891 - val_loss: 598.2219 - val_mae: 4.4084\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 116.52535\n",
      "Epoch 157/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.8277 - mae: 2.0187 - val_loss: 591.6297 - val_mae: 4.3838\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 116.52535\n",
      "Epoch 158/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.3864 - mae: 1.9470 - val_loss: 576.0983 - val_mae: 4.3299\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 116.52535\n",
      "Epoch 159/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.0989 - mae: 2.0243 - val_loss: 540.9088 - val_mae: 4.2193\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 116.52535\n",
      "Epoch 160/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.7363 - mae: 1.9808 - val_loss: 557.1204 - val_mae: 4.3017\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 116.52535\n",
      "Epoch 161/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.6335 - mae: 1.9751 - val_loss: 580.4323 - val_mae: 4.3757\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 116.52535\n",
      "Epoch 162/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.1543 - mae: 1.9132 - val_loss: 597.9026 - val_mae: 4.4205\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 116.52535\n",
      "Epoch 163/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.5710 - mae: 1.9376 - val_loss: 579.4047 - val_mae: 4.3606\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 116.52535\n",
      "Epoch 164/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.5251 - mae: 1.9892 - val_loss: 507.8574 - val_mae: 4.1237\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 116.52535\n",
      "Epoch 165/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.9235 - mae: 1.8439 - val_loss: 528.2034 - val_mae: 4.2023\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 116.52535\n",
      "Epoch 166/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 50.2564 - mae: 2.1432 - val_loss: 534.7823 - val_mae: 4.2206\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 116.52535\n",
      "Epoch 167/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.3847 - mae: 1.8136 - val_loss: 559.8032 - val_mae: 4.2947\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 116.52535\n",
      "Epoch 168/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.7454 - mae: 1.8751 - val_loss: 564.2213 - val_mae: 4.3064\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 116.52535\n",
      "Epoch 169/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 36.1721 - mae: 1.9292 - val_loss: 537.1262 - val_mae: 4.2161\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 116.52535\n",
      "Epoch 170/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.7452 - mae: 1.8796 - val_loss: 506.5274 - val_mae: 4.1338\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 116.52535\n",
      "Epoch 171/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.7139 - mae: 1.9347 - val_loss: 521.3713 - val_mae: 4.1869\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 116.52535\n",
      "Epoch 172/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.7679 - mae: 2.1419 - val_loss: 581.0905 - val_mae: 4.3940\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 116.52535\n",
      "Epoch 173/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.7454 - mae: 2.1601 - val_loss: 591.6755 - val_mae: 4.4025\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 116.52535\n",
      "Epoch 174/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 45.9938 - mae: 1.9904 - val_loss: 553.8548 - val_mae: 4.3075\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 116.52535\n",
      "Epoch 175/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.0317 - mae: 2.0423 - val_loss: 535.0123 - val_mae: 4.2552\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 116.52535\n",
      "Epoch 176/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 31.4929 - mae: 1.8064 - val_loss: 539.8509 - val_mae: 4.2815\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 116.52535\n",
      "Epoch 177/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.5979 - mae: 1.8908 - val_loss: 560.5321 - val_mae: 4.3707\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 116.52535\n",
      "Epoch 178/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 42.7398 - mae: 2.0035 - val_loss: 552.7590 - val_mae: 4.3460\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 116.52535\n",
      "Epoch 179/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.7080 - mae: 1.7891 - val_loss: 610.3088 - val_mae: 4.5228\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 116.52535\n",
      "Epoch 180/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.4483 - mae: 1.9513 - val_loss: 568.9653 - val_mae: 4.3825\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 116.52535\n",
      "Epoch 181/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 39.4323 - mae: 1.9780 - val_loss: 502.5776 - val_mae: 4.1883\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 116.52535\n",
      "Epoch 182/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.4700 - mae: 1.9219 - val_loss: 519.0076 - val_mae: 4.2392\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 116.52535\n",
      "Epoch 183/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.4383 - mae: 1.9440 - val_loss: 528.0847 - val_mae: 4.2626\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 116.52535\n",
      "Epoch 184/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 36.5157 - mae: 1.8621 - val_loss: 552.3240 - val_mae: 4.3435\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 116.52535\n",
      "Epoch 185/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 33.8133 - mae: 1.8392 - val_loss: 524.8140 - val_mae: 4.2556\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 116.52535\n",
      "Epoch 186/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 37.0445 - mae: 1.8381 - val_loss: 507.7820 - val_mae: 4.2143\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 116.52535\n",
      "Epoch 187/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 41.7975 - mae: 1.9682 - val_loss: 482.4405 - val_mae: 4.1505\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 116.52535\n",
      "Epoch 188/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 33.4698 - mae: 1.8418 - val_loss: 499.1328 - val_mae: 4.1972\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 116.52535\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 32.7682 - mae: 1.7532 - val_loss: 467.7195 - val_mae: 4.0956\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 116.52535\n",
      "Epoch 190/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.3939 - mae: 2.0015 - val_loss: 510.4042 - val_mae: 4.2322\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 116.52535\n",
      "Epoch 191/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.8729 - mae: 1.8105 - val_loss: 489.0311 - val_mae: 4.1798\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 116.52535\n",
      "Epoch 192/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 30.2224 - mae: 1.7505 - val_loss: 509.1613 - val_mae: 4.2406\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 116.52535\n",
      "Epoch 193/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.6448 - mae: 2.0231 - val_loss: 545.5864 - val_mae: 4.3452\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 116.52535\n",
      "Epoch 194/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 38.2517 - mae: 1.9123 - val_loss: 562.3990 - val_mae: 4.4082\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 116.52535\n",
      "Epoch 195/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.7059 - mae: 1.9558 - val_loss: 578.0723 - val_mae: 4.4574\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 116.52535\n",
      "Epoch 196/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 40.8465 - mae: 1.8709 - val_loss: 554.8479 - val_mae: 4.3790\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 116.52535\n",
      "Epoch 197/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 33.9651 - mae: 1.8147 - val_loss: 552.7086 - val_mae: 4.3697\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 116.52535\n",
      "Epoch 198/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 35.4070 - mae: 1.8614 - val_loss: 535.9955 - val_mae: 4.3166\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 116.52535\n",
      "Epoch 199/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 34.0249 - mae: 1.7502 - val_loss: 519.5593 - val_mae: 4.2702\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 116.52535\n",
      "Epoch 200/200\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 38.6564 - mae: 1.8760 - val_loss: 513.9385 - val_mae: 4.2798\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 116.52535\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 2\n",
    "\"\"\"\n",
    "model_feature4 = create_model(n, Adam(learning_rate = 0.0001), 0.2)\n",
    "\n",
    "history_feature4 = model_feature4.fit(X_train4,\n",
    "                                      y_train4,\n",
    "                                      validation_split = 0.2,\n",
    "                                      epochs=200,\n",
    "                                      batch_size=5,\n",
    "                                      verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 384.6692 - mae: 3.1910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[384.6692199707031, 3.190950393676758]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 3\n",
    "\"\"\"\n",
    "plt.plot(history_feature4.history['mae'])\n",
    "plt.plot(history_feature4.history['val_mae'])\n",
    "plt.title('PCA')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(top = 8)\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "score_feature4 = model_feature4.evaluate(X_test4, y_test4, verbose=1)\n",
    "score_feature4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Regression 2.596035957336426\n",
      "Mutual Info Regression 2.5704758167266846\n",
      "Tree Based 3.1759533882141113\n",
      "PCA 3.190950393676758\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history_feature1.history['val_mae'])\n",
    "plt.plot(history_feature2.history['val_mae'])\n",
    "plt.plot(history_feature3.history['val_mae'])\n",
    "plt.plot(history_feature4.history['val_mae'])\n",
    "\n",
    "plt.title('Comparison of Feature Selection Method')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['F Regression', 'Mutual Info Regression', 'Tree Based', 'PCA'], loc='upper right')\n",
    "plt.ylim(top = 8)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('F Regression', score_feature1[1])\n",
    "print('Mutual Info Regression', score_feature2[1])\n",
    "print('Tree Based', score_feature3[1])\n",
    "print('PCA', score_feature4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "1. Keras Sequential model: https://keras.io/guides/sequential_model/\n",
    "2. Train model: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "3. Display model training history: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
