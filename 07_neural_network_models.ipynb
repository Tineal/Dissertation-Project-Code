{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 1\n",
    "\"\"\"\n",
    "def create_model(n, optimizer, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(n,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer = optimizer, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((728, 16), (182, 16), 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters: feature selection = Mutual Info Regression\n",
    "x2_mutualinforegression = pd.read_csv('x2_mutualinforegression.csv')\n",
    "n = len(x2_mutualinforegression.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x2_mutualinforegression, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    " best hyperparameters: batch = 1, optimizer=Adagrad, dropout rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 505.5097 - mae: 4.6849 - val_loss: 179.5778 - val_mae: 3.3551\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 267.9629 - mae: 3.3893 - val_loss: 250.7979 - val_mae: 4.5011\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 133.0178 - mae: 2.9800 - val_loss: 129.6745 - val_mae: 3.1245\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 254.0707 - mae: 3.3994 - val_loss: 125.1942 - val_mae: 3.1448\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 138.9173 - mae: 2.8784 - val_loss: 110.4811 - val_mae: 2.8972\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 169.2962 - mae: 2.9328 - val_loss: 389.6417 - val_mae: 4.5802\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 174.2552 - mae: 2.8520 - val_loss: 196.6535 - val_mae: 3.4585\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 69.3387 - mae: 2.2931 - val_loss: 313.5118 - val_mae: 3.9046\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 150.7474 - mae: 2.7351 - val_loss: 213.6663 - val_mae: 3.3059\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 82.2182 - mae: 2.3330 - val_loss: 134.1403 - val_mae: 2.7796\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 61.5571 - mae: 2.0899 - val_loss: 149.8007 - val_mae: 2.9529\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 52.8503 - mae: 2.0434 - val_loss: 514.5030 - val_mae: 4.7285\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 94.3337 - mae: 2.2684 - val_loss: 524.9178 - val_mae: 4.6911\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 71.4308 - mae: 2.2150 - val_loss: 251.0112 - val_mae: 3.3732\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 72.8171 - mae: 2.2357 - val_loss: 381.4551 - val_mae: 4.0151\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.8116 - mae: 1.9526 - val_loss: 188.2607 - val_mae: 3.2326\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.4246 - mae: 2.0807 - val_loss: 245.9088 - val_mae: 3.3725\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.1319 - mae: 1.9969 - val_loss: 356.7158 - val_mae: 3.9138\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 63.4517 - mae: 2.1207 - val_loss: 194.3753 - val_mae: 3.1202\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.7427 - mae: 1.9372 - val_loss: 272.2406 - val_mae: 3.4512\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.0745 - mae: 1.8511 - val_loss: 260.0764 - val_mae: 3.5771\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6722 - mae: 1.6910 - val_loss: 290.5459 - val_mae: 3.7446\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.4169 - mae: 1.7332 - val_loss: 281.4261 - val_mae: 3.7759\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 62.9003 - mae: 1.9879 - val_loss: 385.4689 - val_mae: 4.0825\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.7245 - mae: 1.9083 - val_loss: 241.8521 - val_mae: 3.4816\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.6224 - mae: 2.0169 - val_loss: 201.7065 - val_mae: 3.3775\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9568 - mae: 1.8284 - val_loss: 249.2555 - val_mae: 3.5928\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.2926 - mae: 1.8544 - val_loss: 108.1340 - val_mae: 2.7750\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.3283 - mae: 1.7162 - val_loss: 203.6256 - val_mae: 3.4336\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.0409 - mae: 1.7849 - val_loss: 293.6541 - val_mae: 3.7506\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.3102 - mae: 1.8025 - val_loss: 252.2179 - val_mae: 3.5849\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.3866 - mae: 1.5711 - val_loss: 136.8319 - val_mae: 2.9344\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.0655 - mae: 1.7435 - val_loss: 320.1867 - val_mae: 3.9585\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.9248 - mae: 1.6218 - val_loss: 153.3519 - val_mae: 3.0874\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.1163 - mae: 1.4765 - val_loss: 166.1527 - val_mae: 3.1764\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5546 - mae: 1.5176 - val_loss: 189.9855 - val_mae: 3.3400\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.2497 - mae: 1.6336 - val_loss: 195.3064 - val_mae: 3.3436\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.0346 - mae: 1.7379 - val_loss: 371.5219 - val_mae: 4.1699\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 62.2677 - mae: 1.8671 - val_loss: 169.5666 - val_mae: 3.1826\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.6346 - mae: 1.6926 - val_loss: 269.1412 - val_mae: 3.8131\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.7484 - mae: 1.5180 - val_loss: 214.7773 - val_mae: 3.5283\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.5980 - mae: 1.6731 - val_loss: 238.9974 - val_mae: 3.6014\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.9183 - mae: 1.6993 - val_loss: 197.7201 - val_mae: 3.3936\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.6659 - mae: 1.6639 - val_loss: 186.7823 - val_mae: 3.2867\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4276 - mae: 1.4720 - val_loss: 193.1230 - val_mae: 3.3816\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.9730 - mae: 1.5267 - val_loss: 153.0455 - val_mae: 3.1136\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 42.5394 - mae: 1.7087 - val_loss: 139.4690 - val_mae: 2.9909\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.8357 - mae: 1.4776 - val_loss: 232.6636 - val_mae: 3.5916\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 28.8727 - mae: 1.4491 - val_loss: 215.5690 - val_mae: 3.4923\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.8174 - mae: 1.7812 - val_loss: 270.9968 - val_mae: 3.7555\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 46.0065 - mae: 1.5808 - val_loss: 199.3954 - val_mae: 3.4813\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.5163 - mae: 1.7463 - val_loss: 178.5041 - val_mae: 3.3099\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 27.4603 - mae: 1.4582 - val_loss: 133.8169 - val_mae: 2.9333\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.7454 - mae: 1.5515 - val_loss: 229.1598 - val_mae: 3.5455\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.5606 - mae: 1.5254 - val_loss: 276.9050 - val_mae: 3.8348\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8172 - mae: 1.4619 - val_loss: 187.5488 - val_mae: 3.3437\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.0249 - mae: 1.3013 - val_loss: 174.0247 - val_mae: 3.3141\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4133 - mae: 1.3672 - val_loss: 186.7341 - val_mae: 3.3725\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.8621 - mae: 1.4456 - val_loss: 177.4193 - val_mae: 3.2893\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.1968 - mae: 1.3863 - val_loss: 132.7046 - val_mae: 2.9360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3903 - mae: 1.5092 - val_loss: 119.2371 - val_mae: 2.7968\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.1838 - mae: 1.5535 - val_loss: 193.8420 - val_mae: 3.3363\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.3594 - mae: 1.4414 - val_loss: 183.7724 - val_mae: 3.3035\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.5155 - mae: 1.7764 - val_loss: 125.0659 - val_mae: 2.8656\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.3746 - mae: 1.4449 - val_loss: 157.6395 - val_mae: 3.1511\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 33.8363 - mae: 1.4822 - val_loss: 188.5824 - val_mae: 3.3483\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.5349 - mae: 1.5694 - val_loss: 257.2067 - val_mae: 3.7520\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.7013 - mae: 1.4889 - val_loss: 134.8344 - val_mae: 2.9786\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.3808 - mae: 1.5432 - val_loss: 201.7518 - val_mae: 3.4074\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.1624 - mae: 1.5110 - val_loss: 176.7412 - val_mae: 3.2726\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.6941 - mae: 1.4709 - val_loss: 188.7157 - val_mae: 3.3050\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.4909 - mae: 1.4063 - val_loss: 168.3423 - val_mae: 3.1495\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2178 - mae: 1.5377 - val_loss: 118.8363 - val_mae: 2.7588\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.3112 - mae: 1.4923 - val_loss: 115.6398 - val_mae: 2.7303\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6449 - mae: 1.1933 - val_loss: 154.1021 - val_mae: 3.0510\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.2517 - mae: 1.5959 - val_loss: 132.8556 - val_mae: 2.9081\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7255 - mae: 1.5239 - val_loss: 179.0181 - val_mae: 3.2915\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2451 - mae: 1.4708 - val_loss: 147.8627 - val_mae: 3.0270\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.0916 - mae: 1.3519 - val_loss: 163.7643 - val_mae: 3.1699\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8418 - mae: 1.3130 - val_loss: 139.1409 - val_mae: 2.9722\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4059 - mae: 1.3699 - val_loss: 242.9259 - val_mae: 3.6317\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.0879 - mae: 1.4253 - val_loss: 158.2576 - val_mae: 3.1233\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5332 - mae: 1.3549 - val_loss: 128.8437 - val_mae: 2.8549\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 52.5798 - mae: 1.5708 - val_loss: 197.5948 - val_mae: 3.3485\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.9262 - mae: 1.4426 - val_loss: 192.8036 - val_mae: 3.3651\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5907 - mae: 1.3893 - val_loss: 159.3452 - val_mae: 3.1241\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.1598 - mae: 1.5018 - val_loss: 135.2014 - val_mae: 2.9081\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4171 - mae: 1.3071 - val_loss: 123.7172 - val_mae: 2.7846\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7471 - mae: 1.5162 - val_loss: 141.2462 - val_mae: 2.9651\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.3646 - mae: 1.2999 - val_loss: 160.6523 - val_mae: 3.1095\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6158 - mae: 1.2619 - val_loss: 157.5872 - val_mae: 3.0412\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 30.3605 - mae: 1.4677 - val_loss: 133.3357 - val_mae: 2.8629\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2348 - mae: 1.4537 - val_loss: 112.7250 - val_mae: 2.6716\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.5206 - mae: 1.2495 - val_loss: 154.9363 - val_mae: 3.0953\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.3095 - mae: 1.3951 - val_loss: 154.1703 - val_mae: 3.0328\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6143 - mae: 1.2548 - val_loss: 160.5637 - val_mae: 3.0913\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 27.0514 - mae: 1.4984 - val_loss: 167.1575 - val_mae: 3.1558\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.4335 - mae: 1.5598 - val_loss: 229.1843 - val_mae: 3.5257\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5043 - mae: 1.2366 - val_loss: 153.6716 - val_mae: 3.0733\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0896 - mae: 1.2860 - val_loss: 172.1963 - val_mae: 3.1972\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.5616 - mae: 1.2782 - val_loss: 178.6432 - val_mae: 3.2529\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.6604 - mae: 1.4567 - val_loss: 175.0704 - val_mae: 3.2111\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.9724 - mae: 1.2814 - val_loss: 145.7483 - val_mae: 2.9916\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8439 - mae: 1.2362 - val_loss: 155.0981 - val_mae: 3.0771\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5391 - mae: 1.4170 - val_loss: 144.1475 - val_mae: 2.9722\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9650 - mae: 1.2981 - val_loss: 124.1583 - val_mae: 2.7185\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.9455 - mae: 1.2696 - val_loss: 137.5387 - val_mae: 2.8608\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.1098 - mae: 1.5047 - val_loss: 179.7622 - val_mae: 3.2147\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1638 - mae: 1.2972 - val_loss: 176.8025 - val_mae: 3.2076\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.0477 - mae: 1.3554 - val_loss: 143.8104 - val_mae: 2.9297\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3142 - mae: 1.3787 - val_loss: 190.2100 - val_mae: 3.2624\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6943 - mae: 1.2300 - val_loss: 134.4236 - val_mae: 2.8832\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1364 - mae: 1.2604 - val_loss: 140.4994 - val_mae: 2.9604\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8006 - mae: 1.1946 - val_loss: 175.5801 - val_mae: 3.2115\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3144 - mae: 1.3825 - val_loss: 161.8367 - val_mae: 3.1122\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8688 - mae: 1.4334 - val_loss: 160.6927 - val_mae: 3.0834\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2242 - mae: 1.1345 - val_loss: 144.8477 - val_mae: 2.9641\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.8846 - mae: 1.2597 - val_loss: 201.6502 - val_mae: 3.3710\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.2506 - mae: 1.3761 - val_loss: 132.3074 - val_mae: 2.8190\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.9822 - mae: 1.4019 - val_loss: 156.8818 - val_mae: 3.0580\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3997 - mae: 1.2397 - val_loss: 152.0288 - val_mae: 3.0336\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.4690 - mae: 1.3295 - val_loss: 131.4999 - val_mae: 2.8348\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.1213 - mae: 1.4338 - val_loss: 146.1585 - val_mae: 2.9478\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.1358 - mae: 1.3469 - val_loss: 99.5054 - val_mae: 2.4787\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9122 - mae: 1.2937 - val_loss: 115.3204 - val_mae: 2.6669\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.0623 - mae: 1.4895 - val_loss: 107.9648 - val_mae: 2.5327\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.6023 - mae: 1.4698 - val_loss: 150.1055 - val_mae: 3.0034\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5923 - mae: 1.3005 - val_loss: 145.7829 - val_mae: 2.9441\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 13.1976 - mae: 1.1233 - val_loss: 164.4740 - val_mae: 3.1143\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.9095 - mae: 1.3807 - val_loss: 268.4976 - val_mae: 3.7226\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7601 - mae: 1.3055 - val_loss: 149.9628 - val_mae: 2.9967\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4649 - mae: 1.3330 - val_loss: 168.5097 - val_mae: 3.1845\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6714 - mae: 1.1946 - val_loss: 142.8089 - val_mae: 2.9503\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.7891 - mae: 1.3911 - val_loss: 165.6878 - val_mae: 3.1220\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.6544 - mae: 1.3756 - val_loss: 140.0181 - val_mae: 2.9257\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1583 - mae: 1.4358 - val_loss: 129.0368 - val_mae: 2.8106\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.2383 - mae: 1.4643 - val_loss: 224.7333 - val_mae: 3.4569\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.9834 - mae: 1.3291 - val_loss: 177.7079 - val_mae: 3.1661\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9622 - mae: 1.2676 - val_loss: 129.2277 - val_mae: 2.7243\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.7715 - mae: 1.3445 - val_loss: 166.1919 - val_mae: 3.0814\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.8670 - mae: 1.3397 - val_loss: 207.5928 - val_mae: 3.3295\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.8343 - mae: 1.4048 - val_loss: 148.3280 - val_mae: 2.9394\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5488 - mae: 1.2453 - val_loss: 150.7536 - val_mae: 2.9538\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9890 - mae: 1.2692 - val_loss: 136.6674 - val_mae: 2.8509\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2371 - mae: 1.2985 - val_loss: 192.9872 - val_mae: 3.2239\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7050 - mae: 1.3210 - val_loss: 165.0133 - val_mae: 3.0771\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9805 - mae: 1.2749 - val_loss: 136.6395 - val_mae: 2.8642\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9545 - mae: 1.2890 - val_loss: 152.8422 - val_mae: 2.9892\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3676 - mae: 1.2206 - val_loss: 183.1278 - val_mae: 3.2354\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.3405 - mae: 1.3905 - val_loss: 129.7077 - val_mae: 2.7858\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7129 - mae: 1.3518 - val_loss: 135.7458 - val_mae: 2.8082\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6530 - mae: 1.1701 - val_loss: 124.2580 - val_mae: 2.7055\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9704 - mae: 1.2589 - val_loss: 169.8356 - val_mae: 3.0819\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.1327 - mae: 1.3905 - val_loss: 151.1065 - val_mae: 2.9337\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3020 - mae: 1.1760 - val_loss: 157.2750 - val_mae: 2.9538\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5091 - mae: 1.1869 - val_loss: 154.3751 - val_mae: 2.9682\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5511 - mae: 1.1231 - val_loss: 140.7502 - val_mae: 2.8524\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0160 - mae: 1.1859 - val_loss: 142.5439 - val_mae: 2.9110\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.6314 - mae: 1.0883 - val_loss: 145.3396 - val_mae: 2.9127\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0797 - mae: 1.3822 - val_loss: 154.1116 - val_mae: 2.9717\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1314 - mae: 1.1083 - val_loss: 117.1043 - val_mae: 2.5819\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7290 - mae: 1.1026 - val_loss: 155.8534 - val_mae: 2.9810\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5001 - mae: 1.2278 - val_loss: 160.4600 - val_mae: 3.0221\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.9858 - mae: 1.3128 - val_loss: 222.0088 - val_mae: 3.4407\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1524 - mae: 1.3061 - val_loss: 141.5919 - val_mae: 2.8141\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3861 - mae: 1.2520 - val_loss: 158.8529 - val_mae: 2.9944\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.8806 - mae: 1.0572 - val_loss: 164.9079 - val_mae: 3.0514\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0902 - mae: 1.1520 - val_loss: 159.2485 - val_mae: 3.0606\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4272 - mae: 1.1939 - val_loss: 151.5796 - val_mae: 2.9311\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.4481 - mae: 1.2344 - val_loss: 186.0703 - val_mae: 3.2161\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.1583 - mae: 1.1380 - val_loss: 170.8677 - val_mae: 3.0755\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.8326 - mae: 1.1170 - val_loss: 180.7487 - val_mae: 3.1512\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.0491 - mae: 1.2065 - val_loss: 165.3604 - val_mae: 3.0375\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.8907 - mae: 1.3474 - val_loss: 163.5800 - val_mae: 3.0425\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6922 - mae: 1.2095 - val_loss: 172.0987 - val_mae: 3.1293\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.1449 - mae: 1.1786 - val_loss: 163.8995 - val_mae: 3.0442\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.6446 - mae: 1.1460 - val_loss: 180.5208 - val_mae: 3.1549\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2663 - mae: 1.1615 - val_loss: 168.7847 - val_mae: 3.0701\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 2ms/step - loss: 26.8115 - mae: 1.3180 - val_loss: 195.2027 - val_mae: 3.2658\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6094 - mae: 1.3163 - val_loss: 161.5038 - val_mae: 3.0487\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0536 - mae: 1.1914 - val_loss: 131.3034 - val_mae: 2.7434\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3553 - mae: 1.2164 - val_loss: 161.6848 - val_mae: 3.0013\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.4781 - mae: 1.2289 - val_loss: 162.4529 - val_mae: 3.0323\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2532 - mae: 1.2091 - val_loss: 147.5036 - val_mae: 2.8682\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0616 - mae: 1.1253 - val_loss: 154.0606 - val_mae: 2.9628\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.9497 - mae: 0.9932 - val_loss: 155.8535 - val_mae: 2.9528\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4760 - mae: 1.2382 - val_loss: 120.8533 - val_mae: 2.4998\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1429 - mae: 1.1111 - val_loss: 129.4203 - val_mae: 2.6743\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6110 - mae: 1.0393 - val_loss: 135.9653 - val_mae: 2.7284\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.5421 - mae: 1.1491 - val_loss: 136.7605 - val_mae: 2.7466\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.3581 - mae: 1.1778 - val_loss: 123.2436 - val_mae: 2.5279\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.5185 - mae: 1.0922 - val_loss: 165.1564 - val_mae: 3.0148\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.9510 - mae: 1.2621 - val_loss: 185.7731 - val_mae: 3.1552\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.1884 - mae: 1.1735 - val_loss: 165.5041 - val_mae: 3.0240\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 7.2790 - mae: 0.9284 - val_loss: 175.0791 - val_mae: 3.0650\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.2118 - mae: 1.2813 - val_loss: 118.1006 - val_mae: 2.4080\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.3908 - mae: 1.1896 - val_loss: 159.8635 - val_mae: 2.9875\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.9677 - mae: 1.2994 - val_loss: 135.6985 - val_mae: 2.7203\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2254 - mae: 1.2271 - val_loss: 173.3407 - val_mae: 3.1011\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.5236 - mae: 1.2294 - val_loss: 121.9754 - val_mae: 2.6195\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 2\n",
    "\"\"\"\n",
    "# best hyperparameters: batch = 1, optimizer=Adagrad, dropout rate=0.2\n",
    "optimizer = Adagrad(learning_rate = 0.05)\n",
    "dropout_rate = 0.2\n",
    "batch_size = 1\n",
    "\n",
    "model = create_model(n, optimizer, dropout_rate)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=200,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABlvklEQVR4nO2dd3hcxdWH39Gq995lyb1XuWJsbGx6h4ReAziQQOBLSEiHNNJpgdAChNBM791g2Rjcu9xlybaK1XuXVvP9MfdukXbVV5LleZ9Hz67u3nJ2dvc35545c0ZIKdFoNBrN8MNrsA3QaDQajWfQAq/RaDTDFC3wGo1GM0zRAq/RaDTDFC3wGo1GM0zRAq/RaDTDFC3wJxFCiE+EEDf0974nI0KIG4UQ6wbhuvcLIV4a6Ov2F0KIJ4UQvxlsO04WtMAPcYQQtQ5/bUKIBof/r+nJuaSU50gpX+jvfQcLQ+xahBA1xt9BIcRjQoiEwbZtsBBChAohHhZCHDO+I1nG/9Eevm63Ojwp5W1Syj940haNHS3wQxwpZbD5BxwDLnDY9rK5nxDCe/CsHFRek1KGAJHAJUA8sPVkFHkhhC/wJTAZOBsIBU4ByoC5g2gaAEIIy2DbcLKhBf4ERQixRAiRJ4S4VwhRCDwvhIgQQnwohCgRQlQYz5MdjskQQtxiPL9RCLFOCPEPY98cIcQ5vdx3pBBireFFrxJCPN5ZGEEIcavhWZYLId4XQiQ6vCaFELcJIQ4Z13pcCCG6ag8pZYuUcg9wBVAC/MThnOcLIXYIISqFEN8KIaYZ238uhHiznW2PCCEeNZ6HCSGeFUIcF0LkCyH+6E6khBCnCCE2CyGqjMdT2rXln4UQm4zX3xNCRDq8Pt+wq1IIsVMIsaRd264x2vYLoDNP/HpgBHCJlHKvlLJNSlkspfyDlPJj43wTDXsqhRB7hBAXtrPzFof/nbxyd5+NEGIi8CSwwLhrqDT2/68Q4gkhxMdCiDpgqbHtj119NsZr9xrtXiOEOCCEWNbJe9e4QAv8iU08ynNNBVagPs/njf9HAA3AY50cPw84gBKNvwHPdiKmne37CrAJiALuB65zd0EhxOnAn4HLgQTgKLCy3W7nA3OA6cZ+Z3XyHpyQUlqB94BFxvVmAc8B3zfsewp4XwjhB7wKnCuECDX2tRjXe8U43QtAKzAGmAmcCdgE0OE9RQIfAY8a13gQ+EgIEeWw2/XA94BE45xmJ5JkHPtH1Gd5D/CWECLGOO4VYCuq3f8AdDYushz4VEpZ6+pFIYQP8AHwORAL3Am8LIQY38k529Phs5FS7gNuA9Ybd5bhDvtfDfwJCAGcQjidfTaGTXcAc4w7tLOAIz2wU4MW+BOdNuA+KWWTlLJBSlkmpXxLSlkvpaxB/bBO6+T4o1LKZwxRfAEluHE92VcIMQL1g/+tlLJZSrkOeL+Ta14DPCel3CalbAJ+gfL80hz2+YuUslJKeQxYDczooh3aU4ASS4BbgaeklBullFZjXKEJmC+lPApsAy429j0dqJdSbhBCxAHnAHdLKeuklMXAQ8CVLq53HnBISvmilLJVSvkqsB+4wGGfF6WUmVLKOuA3wOVGh3It8LGU8mPD4/4C2ILqeMy2/Y3xGa9FCbQ7ooDjnbw+HwhGtW+zlPIr4EPgqk6OaU9PP5v3pJTfGO+tsd1rbj8bwAr4AZOEED5SyiNSysM9sFODFvgTnRLHH40QIlAI8ZQQ4qgQohpYC4S7CysAheYTKWW98TS4h/smAuUO2wByO7E5EeW1m+eqRcWIk1xdC6jvxCZ3JAHlxvNU4CdGCKDSCB+kGHaA8pBNgbsau/eeCvgAxx2Oewrl+Xb6ngyOtntPue1e80F55anAd9vZdyqqA00EKoxOwfFYd5QZx7kjEciVUrZ1YmdX9PSz6ey74PazkVJmAXej7giLhRArhUMoT9M9tMCf2LQvBfoTYDwwT0oZCiw2tncZw+4Dx4FIIUSgw7aUTvYvQP2wARBCBKE8z/z+MEYI4YXynL82NuUCf5JShjv8BRpeNsAbwBKhxiouwS7wuShvMtrhuFAp5eSu3pPBiHbvKaXday1AqXGdF9vZFySl/AuqbSOMNnI81h2rgLPa7d/ezhSjjVzZWQc4fo7xnVyrPe7K0nZWrrbTz0ZK+YqU8lRU20rgrz2wR4MW+OFGCCruXmnEhe/z9AWNMMcW4H4hhK8QYgHOoYn2vALcJISYYcTBHwA2SimP9MUOIYSPMdj3KkqYHjReega4TQgxzxgQDBJCnCeECDHsLwEyUGMXOUY8GSnlcVSs+p9CpR56CSFGCyFchbw+BsYJIa4WQngLIa4AJqHCHybXCiEmGR3h74E3jXDXS8AFQoizhBAWIYS/UAPoyQ5t+zujbU+l87Z9ESWabwkhJhg2RwkhfimEOBfYiBLxnxnttcQ4nzkGsgO41LgTHAPc3GXD2ykCkoXK5Okubj8bIcR4IcTpxnekEfW9tvbg3Bq0wA83HgYCUJ7hBuDTAbruNcACVIjgj8BrKO+3A1LKL1Ex6LdQHupoXMe1u8sVQohaoBIV+y8D0qWUBcb1tqBivY8BFUAWcGO7c7yCGqB8pd326wFfYK9x7Ju4CIFIKctQg48/Ma7/M+B8KWWpw24vAv9FhTj8gR8Zx+YCFwG/RGX/5AI/xf7bvBo1wF2O6rD/564hjDGN5aj4/xdANWrwOxrViTYDF6LGFkqBfwPXSyn3G6d4CGhGifULwMt0n6+APUChEKK0q50Nezv7bPyAvxh2FqJCY7/sgT0aQOgFPzT9jRDiNWC/lNLjdxAnAkKIDOAlKeV/BtsWzcmF9uA1fUYIMccIX3gJIc5GeaTvDrJZGs1Jj0cFXgjxf0JNpsgUQrwqhPD35PU0g0Y8Ko5di8rvvl1KuX1QLdJoNJ4L0RgTONYBk6SUDUKI11H5vv/1yAU1Go1G44SnQzTeQIBQdVICUWlaGo1GoxkAPFagSkqZL4T4B6pAVgPwuZTy8/b7CSFWoKbZExAQkJ6S0lkKtXva2trw8hp6Qwrarp4zVG3TdvUMbVfP6Y1tBw8eLJVSxrh8UUrpkT8gApU6FYOatfcucG1nx6Snp8vesnr16l4f60m0XT1nqNqm7eoZ2q6e0xvbgC3SjaZ6shtbjpo4UiKlbAHeRpUu1Wg0Gs0A4EmBPwbMN2bFCWAZsM+D19NoNBqNAx4TeCnlRtTMv23AbuNaT3vqehqNRqNxxqOrAEk1k1HPZtRoTkKEEOTk5NDY2L5K8OASFhbGvn1DM5jQmW3+/v4kJyfj4+PT7fOdrMu8aTQaDxMUFERISAhpaWm4X0dm4KmpqSEkJGSwzXCJO9uklJSVlZGXl8fIkSO7fb6hmSuk0WhOeCwWC1FRUUNK3E9UhBBERUX1+G5IC7xGo/EYWtz7j960pRZ4jUajGaZogddoNMOSyspK/v3vf/f4uHPPPZfKysr+N2gQ0AKv0WiGJe4E3mrtfGGojz/+mPDwcA9ZNbDoLBqNRjMs+fnPf87hw4eZMWMGPj4+BAcHk5CQwLZt29i/fz8XX3wxubm5NDY2ctddd7FixQoA0tLS2LJlC7W1tZxzzjmceuqpfPvttyQlJfHee+8REBAwyO+s+2iB12g0Hud3H+xhb0F1v55zUmIo913gag10xV/+8hcyMzPZsWMHGRkZnHfeeWRmZhIdHQ3Ac889R2RkJA0NDcyZM4fLLruMqKgop3McOnSIV199lWeeeYbLL7+ct956i2uvvbZf34cn0SEajUZzUjB37lynHPJHH32U6dOnM3/+fHJzczl06FCHY0aOHMmMGTMASE9P58iRIwNkbf+gPXiNRuNxOvO0B4qgoCDb84yMDFatWsX69esJDAxkyZIlLnPM/fz8bM8tFgsNDQ0DYmt/oT14jUYzLAkJCaGmpsbla1VVVURERBAYGMj+/fvZsGHDAFs3MGgPXqPRDEuioqJYuHAhU6ZMISAggLi4ONtrZ599Nk8++STTpk1j/PjxzJ8/fxAt9Rxa4DUazbDllVdecbndz8+PTz75xOVrZpw9OjqazMxM2/Z77rmn3+3zNDpEo9FoNMMULfAajUYzTNECr9FoNMMULfAajUYzTNECr9FoNMMULfAajUYzTNECr9FoNEBwcDAABQUFfOc733G5z5IlS9iyZUun53n44Yepr6+3/T+Y5Ye1wGs0Go0DiYmJvPnmm70+vr3AD2b5YY8JvBBivBBih8NftRDibk9dT6PRaBy59957nerB33///fzud7/jggsuYNasWUydOpX33nuvw3FHjhxhypQpADQ0NHDllVcybdo0rrjiCqdaNLfffjuzZ89m8uTJ3HfffYAqYFZQUMDSpUtZunQpoMoPl5aWAvDggw8yZcoUpkyZwsMPP2y73sSJE7n11luZO3cuZ555Zr/VvPHYTFYp5QFgBoAQwgLkA+946noajWYI88nPoXB3/54zfiqc8xe3L1955ZXcfffd/OAHPwDg9ddf59NPP+WWW24hKSmJ0tJS5s+fz4UXXuh2vdMnnniCwMBAdu3axa5du5g1a5bttT/96U9ERkZitVpZtmwZu3bt4kc/+hEPPvggq1evtpUlNtm6dSvPP/88GzduRErJvHnzOO2004iIiLCVJX7wwQe5+eab+60s8UCFaJYBh6WURwfoehqN5iRn5syZFBcXU1BQwM6dO4mIiCAhIYHf/e53TJs2jeXLl5Ofn09RUZHbc6xdu9YmtNOmTWPatGm2115//XVmzZrFzJkz2bNnD3v37u3UnnXr1nHJJZcQFBREcHAwl156KV9//TXgubLEA1WL5krgVVcvCCFWACsA4uLiyMjI6NUFamtre32sJ9F29Zyhapu2q2eEhobaqzme+ivPXMRNtUiTCy64gJdeeoni4mIuvvhinn32WUpLS8nIyMDHx4cpU6ZQWlpqKyVcU1NDbW0tbW1t1NTU0NraSkNDg+19tLW1UVdXx+7du/nb3/5GRkYGERER3HbbbVRWVlJTU4OUktraWlupYfP/hoYGmpqabOdqamqisbGR2tpafHx8qKmpwWq10traSl1dnctKmI2NjT37rKWUHv0DfIFSIK6rfdPT02VvWb16da+P9STarp4zVG3TdvWMbdu2DbYJMjMzUy5YsECOHTtWFhQUyIcffliuWLFCSinlV199JQGZk5MjpZQyKChISillTk6OnDx5spRSyn/+85/y5ptvllJKuXv3bmmxWOTmzZvljh075LRp06TVapWFhYUyNjZWPv/881JKKadMmSKzs7NtNqSmpsqSkhK5detWOXXqVFlXVydra2vl5MmT5bZt25yuV11dLf/+97/L++67z+X72bt3b4dtwBbpRlMHwoM/B9gmpXR/H6TRaDQeYPLkydTU1JCUlERCQgLXXHMN5557LrNnz2bGjBlMmDCh0+Nvv/12brrpJqZNm8aMGTOYO3cuANOnT2fmzJlMnjyZUaNGsXDhQtsxK1as4JxzziEhIYHVq1fbts+aNYsbb7zRdo5bbrmFmTNnenaVKHfK319/wErgpu7sqz34gWOo2iXl0LVN29UzhoIH74rq6urBNsEtXdnWUw/eo4OsQohA4AzgbU9eR6PRaDQd8WiIRkpZD0R1uaNGo9Fo+h09k1Wj0XgMFUHQ9Ae9aUst8BqNxiNYrVbKysq0yPcDUkrKysrw9/fv0XF6TVaNRuMRzFzukpKSwTbFicbGxh4L5UDRmW3+/v4kJyf36Hxa4DUajUeQUjJy5MjBNqMDGRkZzJw5c7DNcEl/26ZDNBqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM8ajACyHChRBvCiH2CyH2CSEWePJ6Go1Go7Hj6SX7HgE+lVJ+RwjhCwR6+HoajUajMfCYwAshQoHFwI0AUspmoNlT19NoNBqNM0JK6ZkTCzEDeBrYC0wHtgJ3SSnr2u23AlgBEBcXl75y5cpeXa+2tpbg4OC+mOwRtF09Z6japu3qGdquntMb25YuXbpVSjnb5YtSSo/8AbOBVmCe8f8jwB86OyY9PV32ltWrV/f6WE+i7eo5Q9U2bVfP0Hb1nN7YBmyRbjTVk4OseUCelHKj8f+bwCwPXk+j0Wg0DnhM4KWUhUCuEGK8sWkZKlyj0Wg0mgHA01k0dwIvGxk02cBNHr6eRqPRaAw8KvBSyh2oWLxGo9FoBhg9k1Wj0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKVrgNRqNZpiiBV6j0WiGKd6ePLkQ4ghQA1iBVinlbE9eT6PRaDR2PCrwBkullKUDcB2NRqPROKBDNBqNRjNMEVJKz51ciBygApDAU1LKp13sswJYARAXF5e+cuXKXl2rtraW4ODgPljrGbRdPWeo2qbt6hnarp7TG9uWLl261W34W0rpsT8g0XiMBXYCizvbPz09XfaW1atX9/pYT6Lt6jlD1TZtV8/QdvWc3tgGbJFuNNWjIRopZYHxWAy8A8z15PU0Go1GY8djAi+ECBJChJjPgTOBTE9dT6PRaDTOeDKLJg54RwhhXucVKeWnHryeRqPRaBzwmMBLKbOB6Z46v0aj0Wg6R6dJajQazTBFCzyAlLD3fagvH2xLNBqNpt8YFgJfUNlAbXMf8vkrj8Hr18ETC+Ho+v4zTKPRaAaRYSHwS/+Rwcc5Lb0/QXOdeqwtgvd+0D9GaTQazSAzLAQ+0NdCk7UPHry1ST2GJUN9Wf8YpdFoNINMtwVeCJEqhFhuPA8wc9yHAgE+FpqtfThBa7NxonBoaegPkzQajWbQ6ZbACyFuBd4EnjI2JQPvesimHuPva6HZnQdfvB8emQ61Je5P0NponCgcrM1gbe13GzUajWag6a4H/0NgIVANIKU8hKovMyQI8LHQ5M6DL94LFUegPNv9CaymBx+hHlu1F6/RaE58uivwTVLKZvMfIYQ3qkLkkCDAx0JIayl8+y+V8uiIKd4tde5P0GrE4APCjX21wGs0mhOf7gr8GiHEL4EAIcQZwBvAB54zq2cE+Fo4pWUDfP7rjoOkZviluTOBdwjRALTU97uNGo1GM9B0V+B/DpQAu4HvAx8Dv/aUUT3F38eCb5sh0u3F2fTOOxP49iEa7cFrNJphQLdq0Ugp24BnjL8hR4CPBR+bwLcT55548LYQjfbgNRrNiU+3BF4IMRb4MzAJ8De3SylHeciuHhHgY8FPNoLAhcAb3nmnAm/sYwvRaA9eo9Gc+HQ3RPM88ATQCiwF/ge86CmjekqArwU/aYRieuPBW/Ugq0ajGX50V+ADpJRfotZwPSqlvB843XNm9Qx/Hwt+GELePsXRFPjuZNHoQVaNRjOM6G49+EYhhBdwSAhxB5DPEMuDD3DrwXdjkLW1CYQF/EJcn0Oj0WhOQLrrwd8NBAI/AtKBa4HrPWRTjwn0tRAg3Ai8GX5p7sQrtzaBtx/4BLo+h0aj0ZyAdNeDl6iYeyrgY2x7BpjmCaN6ir+vhSDcZdGYAl/r/gStTWDxBZ8A1+fQaDSaE5DuCvzLwE9RefBtnjOndwT4WAjAEHIz5m7SrTTJJvD2d/Dgh1gMvrpAzdI94w9g8eQyuhqNZjjR3RBNiZTyfSlljjHIelRKedSjlvWAAB8LgbYQjZuJTp2JdmsTePuCxUfF4oeaB3/oc9jwbyg/PNiWaDSaE4juuoP3CSH+A3wJpqsMUsq3PWJVDwnw9XII0fTCg7c2gcUPhFBefF8EXkp1nv6ksUo9NnUSZtJoNJp2dFfgbwImoOLvZohGAl0KvBDCAmwB8qWU5/fGyK7w9/ayh2g6ePDmRKfOYvDNKkQDKg7flxDNa9eqkgcXPdb7c7THFPjmmv47p0ajGfZ0V+CnSymn9vIadwH7gNBeHt8lgRYrPsKoF+w2Bt9ZiKZRhWjAEPheevBSwpGvIbKfJ/hqD16j0fSC7sbgNwghJvX05EKIZOA84D89PbYn2OLv0PtiYxY/9dwnUJ1j0zPw71N6ZkhtkRLjutKeHdcVNg9eC7xGo+k+3fXgTwVuEELkoGLwApBSyq7SJB8Gfga4Xd5PCLECWAEQFxdHRkZGN02yU1tRxDjjeVHeUfY5nGNuTQWBAC11ZKz+CkTHPm1meTFWSwC7MjKY1dhKS1E+zRWfkFC8hzVffYn0snTLjojyHUwHrDVFfL16NQhBbW1tt95TSPUh6gOTsHoHdnhtan42UcDBzK0UVMR3y5au6K5dg8FQtU3b1TO0XT2nv23rrsCf3dMTCyHOB4qllFuFEEvc7SelfBp4GmD27NlyyRK3u7qlLGcX7FTP4yJDiHM8x3YLGBGXJQvngW9QxxPs94PQeJYsWQI5sYAAP18ohNPmz4TAyO4ZsmEf7AJLWzNLTpkDfsFkZGTQ5XuytsADl8PSX8Cp/9fx9cMPQDmMG5HAuEVdnKubdMuuQWKo2qbt6hnarp7T37Z1K0TjmBrZgzTJhcCFQogjwErgdCHES3201yW2OjTgJgZvZLVU5cFbt0JDhfM+1mY1kxXsg6zmwiGO+z69BLY8596Qkv3253WdrAHbnqYalcnjbt1YHaLRaDS9oLsx+B4jpfyFlDJZSpkGXAl8JaW81hPX8jdqwUuE65msZpXIQ5/D7tchd1PHfSyOAt8A9UYc3Sau9VCwHY7vcm9I8X57CKgncfgmIzumqcr1643Vxuta4DUaTffxmMAPJN5WJeoN3mGuywUHGCGWkgPqsb13bU50Avsgq+nBN1YaxxQ7/98eKaFkHyRMd32NzjAHgE0hb48ti8bDaZLVBfDFb8Ha6tnraDSaAWFABF5KmeGpHHjAFrqo8w53FngpVfglsAuBtzY558E31dhFtaFSPdYUqcdGN162mUGTdqr6v74HHrwZemlyIfDWFnup4+YaKNwN/xgPVfndP3932f0GfPOIc6hJo9GcsAwLD97Mca+1hDnXgzdTJAOj1GOpKfDtxNcpRBMIDeX210yPvdYQeFPwHbG2wMan1PO0xcY1OvHgra3OefmmZ+7Kg3fc1lSrQkS1hZC7wf35O6M0y32ef9Fe9VhzvHfndqShQt8JaDSDzPAQeCP3vVq0C9HY1lo1PHjT++40RBPg/Jp5TG0nHvzKa2DdgzDxAhi9FHxDOo/Bf/k7ePJUaDMmBXfmwTuGhJpr7XcGRXvcn98dTTXw5EJY/7jr14uNc/ZV4Fub4ZEZsPX5vp1H03vqy6Eyd7Ct0Awyw0PgDYGs9Ap1rkVj8+DbpTk6im9bG7S1OIdoHDE99lo3Mfjq43DoM5XeeMVLqmBZUFTnHnzeZlU47Ph2w/5OYvBmh2LxVQJd1weBL8xUnV7+1o6vWVuh5KD9PfWFqlzVThVH+nYeTe/57Few8qrBtkIzyAwTga/HihfVBDvPZDU9+A4C7yC+5oIgFodBVkfah2gaq1Rs3+Tgp+px6uX2bUExnXvw5ljA/o/VY1NnHrwh8KGJar96I3zUK4E3MoAKd3d8rfywvS1qCnp+bkcqj6lHV+EszcBQecwz4zSaE4phIvB1NOJHfZuP8sbN2K/VKDQW4CDwXt7O4mt6+Y558CZ+oQ4hGsODb2t1Lntw4BMIT4XYifZtnQl8Xak9xn/AEHiziFhro704mokp+mEpaj8zRFOV23MBPb7Tdqx3S7uUS7PD8PaHmsKenbc9lcYUCXcZR72lcDdkDokCpkOf+lLV/m1DbvkGzQAyPAS+pY4m4U9dm7HYlDnQaovBR9j3jZ2oPHjTCzc7AW+HQVaTyFEOIZoi+3ZbbnwdZGfA+HOdSwQHRdvvEqRUnYC1Rf1vZqiMWQ7Fe6E8xzm/vb0Xb/Pgk9R+daXgZbzP7NXw0U86TtxqT85aZevxneAbDEBwbY7zPkV7VC38lHkqXbIvmB68u4yj3rL+cfjg7v4953ClrgRkm+u7Qs1Jw/AQ+OZ6GoU/tW1GmMWMw5veuW+QXbgTZigv3xQfsxOwtPPg/cKUJ24L0RTbxNF2bNYqFdYYf46zPYHRyoOSkvDKTHj1SrUv2MMzp/xIPWavdp6h2l4UHUM00qpm46bMVdveuwM2/wf2f+S+berK4IUL4eOfqs5l8iWAC4Ev3gtRYyAire+DrBWGB9/fIZr6MjUZrLPCcRpos9pDeV11/pphzTAR+DqahR81rUZpHTMOb4q3t5+9Bk3iDPVohlDMkIhtkNXoCAIj1QxYM+ZeWwTRY9Vrpuhv+x+EJEDqQmd7gmJUKKexkrCqPc7XKz0IPkHGMULl1zsKlisPXnip64BKkYyfCv7hRscg4Mg37tumthCQsONlZdOY5RAc50Lg90HcJNWR1JXY7zh6g82Dr+z9OVxhTj7rawipK6oLIH+bZ6/hSerLUcs1oAX+JGd4CHxLHc3CnxqrGaJp58Fb/JRw+4VBxEi1zQyh2DoBw/s3hT4oGvzDlBfaUKG8/mijZmVjlQqtZH0Js27ouE5qUIxxjVLCqvbajwHlwUePVccEhBteqcMM1faZNI1VaizA36GcfmA0jDsbJl4IE86Do+vct037sYCE6RA3haA6B4GXUolmWDKEGNUq+yKinhpkNQXeMVzmCVb/CV65vOv9hiqOk+y0wJ/UDA+Bb66jxcuP6g4evMMAqm+wEjCb+BoCb3XoBMDBg49SXnJjlV3sTIFvqIRtL6i4+6zrO9oTbFyjZD9hVUZIxlHgYybYr1Ffqjxx8/quPHj/MHt4CFQa5qVPwRUvqpmzlcfc5zyb73PC+RA+QoVg4qcSVJdrn2zVXKfGLYJiICRRbettmKalQd01ePurQeH+nOxkhh36YyJWZ5QeUu3W2SIxQxnHLLHuCHzRHt0RDFOGicDX0+LlT5XVFHjTgze9c3+IHgNJM+0CX98+RNMuBh8YpTxsabUvdu3owe9+E8aeCWFJHe1JmQ/B8fDJz7EYhdBorFLeeU0BxBjnCYw2PPhaCDVCMK48eP8w8HMQ+MBo+3MzPHTUTZjG9OAveBTu3K46pVGn4SVb1eCrY1sERtvt6K2IVuWpx7jJdvv7A2uLvfPzdIim3Li7qT5B0wzreujBP38uZPzVc/b0B1ueh89/PdhWnHAMD4FvqaPV4k+jVGGWqpoqHll1iLYWhxj8d1+AC/5lL1tgi8E77APOAu8fpp6XGhOAzBh8Va76S5nn2h4ffzj1bqg2xM43WAmdKRgRafZr1JcrDz7U6Cg6ePDVhgfvsGZKkIPAx01Wrx8xwjRtVmevua5ExfADIuyhpNSFtFr87Tn8dWX285qx/t5OdjIHWOONtWAaK+HNm1WH2BfqHcpHeFLgm2rtheXMzupEw0ngKzvft7lefUZmCu1QZc/bsOuNwbbihGN4CHxzHVYvfxpRIr3lUAEPrTpIcYXhPXr7Kc/Vy0vF2v3DHEI0hgffIUQTqUI0oMoAgxqA9A2BvC3qf9Ojd8WsGyAohgb/eIgcqQTejCGbHnhgpNrWXGsXVrcevIPAm50UgJcFRi1RmTTNdfD2CnjBoa5bXYm6npfDR+3tR0XETDj4mYq/m20RGK3O7eWj7jTa2tSMyK//6f59tsfMgU8wBL66ADLfhDV/c54g1lPMtgNnga8rVd7d+sf7dn6TCoexib6mi/YUKeHDH8OxjX07T30pIMA7oGsP3mzX4j39036eojJX2TqUbRyCDBOBr8fi608japC1ukaJZF29EUM1B05NgmIcBlnbTXQKjoXTfw1TLrPXkT/wCUSOVoOdAeFwfIfabnr0rvANhCte4sD4O+yxfJvAGxOvAqPsIZqAcNW5mB78kXWqnkvJPnW8uxANwPwfqslT7/9IiWnuJntNnvoye1jKgbKo2UrEC3fZQzRB0aojDE1U4v/h3bD+MfjyD/ZOzWTfh/DpL509a4DybDUr2BxnMCdQlR5wXSKhu5htJ7zs4SNrKzw2W9n52S/7R5DLHQV+gEM0daWw5VnY/0Efz1OivmOBUd0QeId1D9q3X9aXULCjb7b0B21t6m7KMb1Z0y2Gh8DfsoqjiefbQjS1tSqvvL7OSD80xdskKMa+elJ7gRcCFv9UDUiaHnxzDUy/Ur3mH6bCOsJiz8hxx4j5VEZMVcc4CXyU/dHarMTZN8h55uyW59T2uStg/u32QVbhZe94bNeZB2mLlLiDGjcoNrJ36kqcQzoGZVGzAaEWQTE7O3O/M/+gMlW2vQAzr1V3Fx/e7Rz62fpf2PA4PD4Xyg7btx/9FpLS7bOHHcsifPOwWlEr861Om82/4bh9voCJ2XaRo+1ZNLVFSsAmX6r+z2/XCfWG8mz16Bs88CEaM/vInDXdW+pK1Xc8IKL7HjzYvzOgPOV3vq8yigab2kIl7uBsr6ZLhofAx08hMCyGBiNEU1+n0g7rGwyBt7gQeDPO2r4WjSNmDB5g2uXO2yLS7KmVXdFe4AMcPHgT3xCVCtlUrQZ+D32h0iDP+SvET7ELfECECsu0Z/E96nHhXerRFFY3At/iGw7hKSr8VFeqbufNuQKTLoI7t6lxi/MfgTN+r8535Gv7CWoLIXq8Ov+hL9S2hkp1dzPyNHsnVGTYkboQ9n2gVtRa+49Om2vcwSfgze85bzTLO8RNtodozMfJF6uwUl/uEEwqctTnEjXG2YOvPIYwRaan5G3tfK6C7RpGeKs/BD4wWn0GXQq8wx2YY32jqjz12Q6FgnGOGWI9WSmtuxz8HPa82//nHQIMD4EHArwFfgEqft5oCHtTQ73ytNvnqYfE2xfwsHnw7cI4YBepEafYB0ZNr76z+Ht7bAJfroTax7iWo8D7BRsefLUS0qZqldpo4uWljm0fnjEZtQTu2ArL7lfnMZcWNL05V0SMVILmKowTGKmE0+JtX8SkLMv+em2xmlHrHaAGnEFl8sg2GLnYYfxin7rrOP9hWHCHqrpZvNdeudIFgfUF6jjH0s9m5xg7SbVNc529KFp4qpr81R+Tk8pzVLuEJduLdR38DB6ZwaxtP+teCd6mWucaMJ/9Aj6+p+vj+suDry9VnXpPPHjfEGcPvsCodFpxtGM9m4ojal2B9hz+CtY93Fur3VPl0OadefBtbb1b1vLzX8En9w7L+P6wEXiAmAjlXbc1qdh7c1Oja+EOjlNT3lsaHATehTfuF6pEdtFP7NtMDz56TPcN8w9TYR4zNmri5MEH2z34/R+p2a6jTnM+j2+wS2/cRvQY1RHET1Wx9dYmdT53x0SOVD/WuhKVW++OkHhljxmKabOqY0LiDSE0Qhk5a5XgJ89WnZi3vwpBhSSq1NCz/gRzv6/23fee62u1NuPXVKrCTEUOglNfrkQofIT6v6bQ7sGHJKiwUMF2ZVtfKM9RNYhCk1RMOm8LvH49RI8joKEQnjur81m+xzbCn5PggUT4yghvlB5U5zUFpL4cHpykxnYcMQW+rq8efImzwLc0dhwrse1batQgmuPc3gVGZ2lt6jix7MP/g5cu7SiI6x+HjL/0v1Ca7QKdr5S25Vl4aHLPJthVF6jPp7ZwaNyt9DPDSuATI0Jolt74C5UZ09rc0DH+DkrgQX1xrZ148ELAlS/D2OX2baZX31MPHtQXyFHUHcXejMHXlcD+D2HMso616YNi1ABoV8RPU7fb5g/TrQefpjyi8hz3dwag2iFylH0+QH2Z8tSD4zoK/Ij59jY3vfjwFPu5QhPUPIE9bgS+KhdhTrMv3KlS477+p7pmYKTzTNvqAiVOQTFK4Jtr7SmtvaG1SaW2Ro40yjNXqRo+AZFw44ccHHe7Ctt0tvC6GSYKT1FjInVlSmRbG+yfR+5GdZ7Pf+M8rmET+NLeTxCztqrrOcbgP/81PL3EtfCa7Ro3WQ2Em51X/jb7AvLtha/0kAon5W22b5NSHdPa0P+TpiqP2UOUnYVojq1XKZ9731X2uOvUQN2JVRdAjkPY8VgvV0lzRVtbx8SEQWBYCXxyRAAN+HKlZTWb/O8gqKnItXDbRKLIuZxBdzDFOqqTDBp3x5RntxN4xxCNEYOvPKaEYO6tHc9z+Qtw5h+7vl7CNDWb10y3cyfe5iBx+WH3nYBJ1Ci7B296zsGxdoGvL1e3+CMX2Y8xO8OwZOdzTbxAxeZdDWI6ZrEUbIdV96tJONUFqr3MdNKa48qOkHh115I8W23vy49q+4uq44qdaLe5YBvMvQWCoqkMn6K2HVvv/hzlh1VJjKnfVe/FXNQF7EJphj/KDql1cE1snqrs2Zq+jjgO5AdEqMHJPe8oQa48pkKAZtqvuX9glHJYrM1Gtkqbyp4xJ9GZYwOgfi/m5+Y4t6HyqH2cpL8Hp6tyIWq0yjLrLERj3oHsfE2tmvbgROcEgENfQP42RJtVpRI/f45arCcgQv1Gj33bfzbveg3+s0xlIg0iw07gc2Q8Akks5UxvzUS6Cr3YPPhC9YX18nbOE++M8FTVacSM775hpsDXlznXpvcPUx4oKA/Fz6g3M+F8FcduT9Roe+fUGeYko/0fqkd34h3pkAXUWYgGVPZK5VHlIZox4uA4Vae+ttAe/06YYT/G9ODDUnDCzJF3/PGZmHnoUWNV7ffqPHWXdWy9EiLzDqbymIrBm4IfOVq1Z96mjud85zaVz9+e3E32Kp/HNsInP4cxZ6jBbXPimZcPzFTlKJr9ItXn39l6uGWHVWcYNwWQsNfhTsXsvAq2qzTS+GkqvXPb/1RoqfKYOj/0Pg5vDgybHjzYO4u8zarDfGapvQxDfblqV7NDq85XjkhTlRpsRzh78JXH1PvyCVQdh3mn4Tj+0T69VErnldZ6SmWu+g4FRrv34Fub1N2bf7gS6nUPq2y3Df9Wr5ceglevglcuJ77wC/WeKo6ojK6Ri9VdZX968DtfUY/bXnC/j7VVpRp7cGlFjwm8EMJfCLFJCLFTCLFHCPE7T13LJDkikEuaf8+ilsdow4tQUU+bK8/c0YO3Nrv28t0x9bvwox0dV4nqDMdsHEevXQj7/37B6kvsHaDSFPtC7CQlePveV/+7i8GbA8fQeYgGVOfS1qpE3gw1mCEagCwjkyZuiv0Ydx68KWKOwtFYrQbIKo5g9fJVZSCaa1XsX1jUtQOj1F1O2AgoyrR78KA66JR5HScJlWfDzldVPv/2l51fW3U/vHKF2r7yamXnZc+oLCWzBMWki+y1hQBGLFBCkPkWPHGqfRaw7XqHVdvHG+2w7wMjQ8sQSimVwCfOgsv+o7J13r8Tvvy9Cm+YdyK1xaoDap8u2hXZqw075zuvg+DlrQT+wMfq7i7XaKf6UkPgjU64Ks8+zyNlnupQHT8ns5Oa/T01VmCWyMjfqt6jeQ5Htj6vvGlXS1J2hZTKgw8foZwQxzubssOw4xXY+75qJ2mFRT9Wr4WnqNLY219WndinP1efQ10p4w4+pdp90sVq35GLVXuVHuyfLJ2qPBX68Q9Xq7YV7FDftfbvv3iPSjXurNx3H/GkB98EnC6lnA7MAM4WQsz34PVIjgxA4kVoaDg1oWoQtFW48OADo5Vo1BapXt5ViqQ7LN72ei3dxZ3AO/7vGwRzboG7d6l4d1/w8lLnkkb2gzsP3j/MfkfRVYgmcrR6LM92EPhYu3gf/FS1a3Csw/nD1aM5MGoSmqQEx/HW//Xr4LVroeIIjf6x9rLOEy+ApFnqudmpJkxTcfDq485jEiMWqDiyo+juNnLuE2epxVEcJ/NUHlMdx3s/UOJwzRt2UQxLgaW/VpPeHBkxT42TvHenCjNtcFjA3AxfRI1Wx/uHqXh05Gj1nitylHdbV6LeU8x4uPlzNYfB9DST56jHqmPwwgVqnsHbK7o/eHzgU0icqTo+871EjlJivet1+ySxnDXq0QzRmHcsVXlGtpRQYZvwVHv5CbDfYc25WcXozdTZgu3qM/Py6ejB529T4RtzBbOeUF+mOqTwEc4e/P6P1SS3d29Xg+DmgPW4c+DCx+DKV2Dxz1Sn+dgcdad2+q9gzs0I2tR6DOf8FaZfpYR+hCFN5riClCrUs+W5ntu863VAwiVPqRDZM0th3UMd7xDMzrKvS2R2gscEXirMnCUf48+jeUhJ4WpQMjkigMaY6QA04UK8vbyUEJkhGlcDsf2Jk8C38/xtAh+iOg9HgewLM65Wt9EWX+cyB+0xwzSdZeeAEi1QXlNtkbLXN8gu8BVH1ECd48pW7jx4i7faZnqGUkL+duV95m2mISABUk9Rnc7s79nDVWbbxU9VItRU5RyyGrFAPZohFClV3v2IU+CSJ9WP3ay/Y21VYj/5Uhi1FK581XlmshBw2k+dw1iO12htgKTZsPFp+6BixRHVqUaOVsebdzPRY+wZS2b8PXGm/TrzbrOXzEgyPPisL5XzkTxXxXM7mVHq01wFr10HR9crgRpnLEBjCvyopWoQuqEcm3Bnr1GxdjNE4xuoOvuqPPUZhyWrTKiItI4evE+QGr9JmK4mtrVZlX1Js5Xz096DN4/vYoJbBxqr1exsUOMiQdHK3rwt8OZNKhx4o+H9fvOIuhOPHAWzrlPfkbhJsOSXMHopLPutmjS4/H4Ojr1N/T5C4tX3Iija/lkV7VHzUP53IbyzQjkF7e/SumLf++pzG3+2anszJGyOHxRmqu+m2S59XeS+E7y73qX3CCEswFZgDPC4lLJDkQ0hxApgBUBcXBwZGRm9ulZtbS1bN3xDiC/4Nldz1CeSOKC8tpltLs6ZLgNpPrqPFp8QwlokG3t53e7Y9fWW3ZhDj3tyCimps19rcp2VGGDtxm2uw0l9YHTcMsIr97J1zRqXdmVkZDCxJYg4YOv+o9QUZHTYz4aUnGoJoHD3WnybKwm2hLApIwMvaxPmaEFuSxiHHdoxtaiaNATrduVg9XZOtZsuQ7Ec3c22jAx8m8o5pcmYwVtbRE3gDDK3Z8Gc/0B2A+HVYcwADuaWUpCRQVSpYKrhK+zLr6LIuKZoa2GR8CF/3escLgwiuCab2aUHOTBuGcczC5jvF0vNhtfYUzsKv8ZiFkgrB1oSOD7iBshpgpxO3r/ZZnvamOcfR0nMKRTFncac/LvJfv3XHEv9LlGlG5kKbD1aSU1FBmNaw0kGjtb54dvsR2R5JoXr3yVFWFh3oIy2LON6MoD5frH4NxXz9YESFlj8EQe/wAJsibuK2XmbyP7yeY6l1iDaWpDmko0GQcU7IOt92vZ/jBeSLTXR1GZkYGltYHrIGLKs4/GtKmcKUB0ylvKgmaQefYONn73BfGklq6CCvIwM0i3hNOfswqelBqslgp0ZGaRWSdJqjrPt/Wdo8otm/KHN+PnGsGXNGkZ7pZB07BN2vfc4M1rq2FsbTKIMhmN72JGRYfuOzT++H3+gLetLNn2ykrCqvURU7KIkZgFl0Q4F+2Qbow8/R5NfDHkpFzFh30PEFa0la8wt5B+VjC5rILGmiIp3fk6IVwBb0u6m5UgrUyNnEVW+lZrg0Wz9uv3aCPMgah5Yga9VOKk2bBEFX3eceDbfL5qqzDUUlAcyM2cthXGnE1/0Ffs+eITa4NHElHxLbXAq5ZGzaevkrn9hcRbFsadyKCMDkXwHloRGTv3mGrJ2b6I838rczT8kc/IviCzfRiJQeWwvO4zvsNlm/YVHBV5KaQVmCCHCgXeEEFOklJnt9nkaeBpg9uzZcsmSJb26VkZGBkuWLOHF0ZXEhfoRXB4JLzxFs08Q6xvi+OHSMYT6O/wwCsaqW8kgCxBNb6/bHbsWLV4M6wQgmTxnsXOmSc27ULaJxaef6ez99geLFwOSJS5mvprtRds6KF5L+qKzICK18/MdHEeyf4P61gSOtLfZNlXbJyX9bFJmLrHvXzsZjl/KorFndDxX9Uw48LE6R/YaWI/yDFvqaA1Ncf48rAshtIpxc25lXGgCVI2BzAcAmDhnKRNHO+x7ZDYp1jxSliyB1d+C8GL8RT9lfFAU1JyD/553WLJooYpvb4Dxc5cxfozD8Z1ga7PT9jFCeDFCCMj/L6PkUUYtWQLf7oZMSF/+XXW3EXoM8j8iddZy9V37ahWpZWshZS6Ll53lfPLIP8De91i0/FzYm6hCYSGJzL7ge5D7DKNEHqOiy+DdH8DdmU7jAgdfVqEPLyEgOJHZ53/P/l1afg6zQI1X7P07oXOvJDRlHvz3NeaHqk53zLR5jJm+BI5PUF5lQwmMu1i9152FcORV0rfdo8Z2RDOkTFGvxdXCa+8zI/9F8Atl0sX3wIf5kLuBJUuWqPY6dQFklML48/A68BHzN96GupEXxDcehkt+osY8Wptg7d8g7wOIn8qYJQ/BnnthwrmMvfKfjAXw3g557xJdtRtmXsfCMy9S7zGuBl67lpAxC7r1O7Z9ju3Jm4F/TRFx8SqwEX/N4/Cf5UyUWZCfYa+4uey3znNjHGlpgIwakibMJmmxcQ0p4VsLYxLCITUeNsOU8AZoUHdt4ZZ6mz1ubeslHhV4EyllpRAiAzgbyOxi9z4xIyVcXTNoGs3Sm+wKK0+tyaauqZU/XjzVvmNwrIqJlWa5XrSjP/HyUoODjVUdY/CTLlKhjv4Wd/O6XTHhPJVhYMZgOyN5Lmx/SYVeRjgMp4Qlq7iyWQPeJDgGXIk7qM6krkQNrJq56/Nvh6//QaN/nPO+Fh/1ozIJTVLhhIZyexaNyYgF8O2j6vY+a5UKG5gZQmOWqayGvC322ZHtxwe6g2OHmTRLxfnb2lRoIyDCHkoatUTd+qeeYq+TU18G17oonTz9SvUH6pa+PNs+9jByMWx9QcXPWxtVeMpB4P2aytSYxvc+A6Tr71JIPHx/jSovgVQZW2Z82WyfsGRjneFm+zjQ2DNh3u3qmI1Pqm3mGsRmuKr0IMy51UgUSII9x+2zXytz1bETL1Dt4uUNM69THd7r16kB8G0v2GPfvsEq5i+lGiMZvcz+HswwYmuj8/dq3NlqKcpJF3Z83z0hZoIaHM3fqj6D0EQYfy5sfka9fsGjqjaPWa/IFeYYh+P30kymqC+z130q3GUfz6g+rt6vBzTAk1k0MYbnjhAiAFgO7O/0oP68vrcfH/ssZ6vXVM6cFMdLG46x5YjDxIfgeDUporUBxp3peYPMOHz7GPzopWqG52CROFPl17cv5+CK6Veq9qo5bo8rghIG4WWvINkdzAyeymMqA8I3RGVALLuPiogZnR8rhIqxQscB7wnnq4HTDf9Wg3tjHCapjTxN2Xn4S7vAtx8f6CkJM9RYQEWOPYPGJHwE3P6N6szMiXGLfqxi151hDnibGTUjF6t2LzF+Pu0GMf2aSpWgJKfbj3FF/FQ1Y9vbTzk1psAEOgi8ORZgjrkERsI5f4GzHrC/B3P+RFCU/TOfc7N6DE1SA4vmbFzzGpEj4aLH4IKHlZ0TzlPfgffvVJ/TonvgosdVob+mauV0tNQ731WamV4WX3v5DFAOwLVvwbh2d0U9JWaCSsk9+Jk93XfCeeoxbqrqmMKSO69aasbT238vA6OUQ2K2S8EO1fn5BqvPtr/XLzbwZBZNArBaCLEL2Ax8IaX80IPX60D81f/m0tt+x0NXzCA2xI8nMhzyrkMMgfIJgtRTXZ+gPzEFPiCy8/2GMknpdgFzHAyedDHMvtleY6c7hKepx4ojKvMlZpy6k1n0407jmzbSFqkSCObcAZuNs9SPc+3fAdlxFnLSbFUzpTJXCWn72cI9xRwsPbZeDRS3v4sxiZ8KN6+CJb/o+pxm52kOuKYuVB2TKcTtBMavqax7M5wdmfd9+0xV87yOd3GOHRWou5bT7lXPYyfat8+6QVUcNbeZHaZZx8fMFGlfedXLomoTIeGCR2DZb9R5oowSIGaWj+MdlunBpy60F8brT8z30FRlz+JKOxWmXQHnP6TuiEOT7O/NFTYPvt3nYS7uY3rwDeUqc8vMmvLQQKvHQjRSyl3ATE+dvzvMH2UPh0xLDiOvwqF4VbCRfTFqSc+Eqbf4hysx6m4FyqGIECqtbPUf7e0HMPU76q8n2Dz4o6rw2OjTe3b8qf9niFS721ohVIro+3eoH1VCu6/gmGVGvZS2vnvvoETB4qcqZDbXwJRL3e+bMqd754warRwPU2QCwmHh3aqTeP9HrgU+qQe1kUAJ58QL1bR+mwdvTkgTznMkTKZcplI7Hec6LPiB8z5mJ/H+HUxv9oJxp6hsLlfZYXNuUeEVx1IW5nVtAu/gwZsZU+7Cfn3FcfKieZdl8YFLn7ZvD01SDoK7kIr52XTw4CONmjclzttTF6rssZoClfXTzwyrmaydER3sR2lts32DOZGlr7d13cU/rGeTo4YqM69RXmtyN8XKHYGR6vY0b4tKVzXXqe0uFm81ruGKKZepO6WxZ3Uchxi9DDAmG7WfYdsbLD5qUlNFjgqTpC3q+piumH0z3LHZOb11+X2q8whNcM6bltLw4LsxhtKec/4K3/2v3Rs2fxNmimR7zNBYZ7HiCGOmd2UuEZWZaswmIs31MUI4i7t5PNhrxDh68OEj4Pr3VMfgCfxC7N8JxxnZjoQlqQl47RcesbYq0a85rjrn9neWthh8sTEOYrRH6inq8UTz4Ica0cF+lNc1YW2TfLCzgIbmSK664uWBE/hFPxkeixWEJsKKjL6fRwg1+cZcpCS6B6UfusI3EL6/1nn+gUnSLHv55t4MsLoicaYamJv6Hde1+nuKt6/rxdxBtb+jB99YiaWtqechGlAe8eRL7P8Hx6sJgH2ZaOcfpjqnwGiq/7WI0JqsrhfGccQvxC6GgdHOK5mBuuP2JLET1SCuu/Y0O9LqfHVnVXFUzULe/5G6o6wuUJ1w+w7NDNHUFqvxiLZWNQ5kDqT3dpH7LjhpPPiYED/aJJTXNfP8t0d45uscmHi+8sAGgqRZnru1PFG54iU1WzQpXdWW70/CU1x7+OYattA/HjyoOiYImHZl/5yvM8wyxibm8/bZRL3B4q3CQo4ZUr0hfAT4BnI01WiP9pPFusIM03SVtusJlt8Plz3r/i7FcYyhKl8VLTv4mRL7g58Z5TNcfBaBUSrmXp6txhJSF6jxGp8A9ZqH1v89qTx4gNLaJo5XNlDZ0EJbm8TLywPpiZru4RuoZoue9tOBve7oZaoIWPvwQG+ZcpnqwKNGd71vXwlNtJdKXvt3ezZJb0I0rrj1q36r514WNVuVehh/Xs8ODE9Vd0T9dYfVE9wNkpvYPPg8+Or3UF8BN7yvMrO++qMKDTpmbpmY4xwt9RAUq7KFzIylkESPefAnjcDHhCiBL6hsoLhGlQguqW0iLnQABlg1Q4vJl6gBL1cVO3uDl9fAiDsogZdW+OZRlcdu5o/3JkTjjv7KxzbXN+4ppgcfPggefFcEx6nso0NfqGUsz3tQde4tRnXOhnLXtaoc578ExyrnBrUCHaEJHvPgT5oQTXSwyl7JzLdXdMurqB8sczSDiX+omnvQWY2eoYrpQe5+XT0W7kYiuldG+kTBDM0MRoimKyzeKgRj1jQaf656TJylJnFBxxRJcE6waF/YL0QLfJ8xPfhdeZW2bbnlDW721miGKGZ812Ed3Wbf8IEbSxoIzAlVPVlUZyAJTVJptvHT7N66b6A986YrD769wC+8C657xyOmnjQCH+znjZ+3Fzvz7OlN2oPXnHA4xtrP/CNYfGnyi3K//4nIiAWq7ELaAExA7A22FOuznbebg9MuPfhOBD5qtH0RnH7mpInBCyGICfGzTXYK9ffWHrzmxCMwUk2skm2qvktlLkW5RbiZEXBiIkTfM3k8SaibOTSTLlaxeVdzOnyDVIkFa3P/lQTvBieNwIPKpMmraCAyyJcRkYHkVWoPXnOCYU4OCklQonHaT8nPyGCIBjOGJxPOVyGyxFnO21PmwB0ulowEe8Gx2qIBLVdy0gk8QGK4PymRgezMrRxcgzSa3nDpM64ncWkGhtQF6q+nBEapxVG6u/5zP3DSxODBPtCaEBZAckQABZUNWNs8usiURtP/DFTOvaZ/CYxyrsI6AJxUHnyMkSqZFB5ASkQgrW2SoupGEsP7WFFQo9FouuL036jSwAPIySXwNg/en+QIJeq55fVa4DUajefpbjXRfuSkCtHYY/ABjI5VRYwOFNUMpkkajUbjMU4qgZ+SFEZSeADTk8NJDPMnOtiPnbn2vPjV+4v544d7aW5tG0QrNRqNpn84qUI0KZGBfPNz+8ISM1LC2Okws/Xptdmszy4jt6KepPBA2qTk/gu7KD6k0Wg0Q5STSuDbMz05nC/3F1Pd2EKgj4UduZWkRgXy2Z4i2z53Lx9LeOAJvAqTRqM5aTm5BT4lHCkhM6+K0AAfGlqs/OTM8SSG+XO0rJ6fvLGT/YU1Tkv/aTQazYnCSS3w05LVZJEdeZUE+aqmSE+NUGmUkaqU5/7j1U4C39hiZX9hDTNSwgfcXo1Go+kJJ9Uga3vCA31Jiwpkx7FKth6tID7Un8QwVR8+NsSPyCBf9hfW0NYmqWlsAeDRLw9xyb+/IbdclznQaDRDG48JvBAiRQixWgixTwixRwhxl6eu1RdOGRPNF/uKWLWviPS0CISx2IEQggnxIewrrOGJNYdZ8OevyC6pZeXmXKSENQdLujizRqPRDC6e9OBbgZ9IKScC84EfCiEmefB6veI3501i6fhY6putpI+IcHptQnwoBwtreHH9UWqbWrnqmQ2U1zXja/FibTcEvqqhhdpmXQpBo9EMDh6LwUspjwPHjec1Qoh9QBKw11PX7A0Bvhaeui6dTzILOXOSc52ICQkhNLRYaWixcsroKL49XEZaVCALRkfxwc7jtFjb8LE495HZJbV4e3mREhnAjc9vorqqkfPPHMh3pNFoNAoh+2mB3U4vIkQasBaYIqWsbvfaCmAFQFxcXPrKlSt7dY3a2lqCg4P7aKkzR6qs3L++kTA/wd8WB/Dkzibmxnvj4wWP7WjiF3P9GR9pcTrmt980UNsiuWaiL//artZ+ffT0QEJ9h9bi3p5or/5iqNqm7eoZ2q6e0xvbli5dulVKOdvli1JKj/4BwcBW4NKu9k1PT5e9ZfXq1b0+1h0Nza1yym8/lQ99ccBpe1VDsxz1i4/kHz/c47S9vqlVjvz5hzL13g/lmF9+JMf96mOZeu+H8r0d+f1uW1/xRHv1F0PVNm1Xz9B29Zze2AZskW401aNZNEIIH+At4GUp5duevJYn8PexkPHTJdx5uvNyCqH+Ppw9JZ4XNxx1WvZv7/Fq2iSMjwuhxSq5e/k4Ar3haz0gq9FoBgFPZtEI4Flgn5TyQU9dx9NEBfth8eoYXvnluRMB+NNH+2zbMvNVXZsnr0vnH9+dzk0L05gUZWFdVilZxTUc6mNhs8dXZ/H+Ts+svq7RaIYfnvTgFwLXAacLIXYYf+d68HoDSlJ4AD9cMoZPMgvZX6iGFXblVREd7EdaVCDfSU/G38fClGgLx6saWf7gWq56ZgMt1t4VMjte1cA/Pz/AI6sO9ufb0Gg0wxiPCbyUcp2UUkgpp0kpZxh/H3vqeoPBlXNHIAR8mlkIKA9+alKoLZceYEashalJYZwzJZ7S2mbWHCihsr6Zp9ce5tr/bGRHN5cNfH1zHm0SDpfUcays95Osqupb9CpWGs1Jwkk9k7WvxIT4MTs1gs/2FNHQbOVQcQ1Tk5zXygz38+KDO0/l0atmEhXky8rNx7j+uU088PF+vjlcyrvb87u8jrVN8vqWXMYYNey/2l/UxRGuaWq1suhvX/HcuhxAlV1o6wexfyLjMFc8tb7P59FoNP2LFvg+ctbkePYdr+aVTcdok6rmvCt8LF5cOCORVfuK2ZVXxRPXzGJuWiTbj1XQ2GLllD9/yYsbjro8du3BEvIrG7h7+VhGRQfx1YHeDdoeLaunurGVVfuKaG2TLPl7Bk+sOdyrczmyLquETUfKaWi29vlcGo2m/9AC30fOmhwPwB8+3EtqVCDzR7uvPPnd9BS8BNx4ShrnTE1gVmoEewqqyThQTEFVI09mHO4QPpFS8vjqLBLC/DlzUjxLJ8SyIbuM+uZWAEprm/j7Z/t5eNVBGlucBfbfGVlc9fQG2//ZJbUAbD9WSWaplcLqRjbllPe5DbJL6pASckrr+nwujUbTf5zU1ST7g5TIQJaOj6FNwsNXzCDU38ftvpMSQ1n7s6UkGWvAzkwJp7VN8uiXWQDkVzawen8xyx1m1K7PLmPL0Qp+f9FkfL29OH1CLM+uy+GbrDJGxwRx4WPfUN/cSpuED3cd55Vb5xEbogqmvbk1j+ySOkprm4gO9uNwiRLgZmsbbx5sBuBAYd8ye+qbWzle1QhAdmktkxJD+3Q+jUbTf2gPvh94/qa5vPC9uUQEdb0wSHJEoG0QdqZR+2bv8WpOnxBLfKg/L6w/4rT/v77MIjbEj8tnpwAwJy2SYD9vvtpfzFvb8mhosfLJXYt5/qY5ZBXX8v4OlUaZW15PtiHo249VAnC4pJbwQB8sXoK8WokQUFjdSGV9c6/fu3kNgMPF2oPXaIYSWuAHkZgQP1IilTd/5qQ4rpo7gq8PldomT2XmV7E+u4xbFo3E30eVRPD19uLUMdGs3l/MJ7sLWTAqivHxISwdH8uomCDWZZUCztUutx+rAFQGzqSEUNs4wblTEwDY3wcvPtsIy1i8BNmltb0+D0BdUyt/+3S/LtCm0fQTWuAHmVmGF790QiyXzkoC4IOdxwF4bl0Ogb4WrpgzwumY0yfEUljdSHZpHedMjbdtP3VMNBuzy2lubWPNwRKSIwKYlhzGtmMVSCnJLqlldEwwi8dGYxHwgyWjARWmOVpWR3FNY7ftLqhs4HBJLdkltQgB6SMiOGzE+BtbrNzxyjZbtk93M3W+PVzGvzMO82xmk1nmolOsbZKbnt/Eqr29yypyx+68Kj7cpSeUaU58dAx+kPn+4tHMSYskLlTFzWeNCOe9HflcNiuJD3YVcM28VMICnOP6SybEAOAl7IO8oAT+f+uPsj67jG+zSrl4ZhI+Fi9e35JLUXUTNY2tjIoJ4oo5KcQ25TMpIZTwQB++ySrl758doMXaxg2npPGzs8bjbXHf9397uJTbXtyKl5dgTlokiWEBTEoM5fUtuUgpeXZdDh/uOs63h8t45vrZ3PHKNkZGB/HHi6cwKsZeSOnX7+7G28uLX503ER+Ll20Rle3FVl7eeIxr56d22nYHCmtYfaCEsrpmp3ELEyklueUNjIgK7OJTsJNTWse1z26kxdrGeVMTnOY0aDQnGtqDH2QmJYY6CdlFM5LYX1jDlc9soE2qjJv2xIb4Mzs1glPHxhAd7GfbPn90FF4C7nhlG3XNVs6flsjMEeHUN1v5JFPdFYyKCSbQ15uUEC+EEIyPC+HzvUU0tFhZPimOp9dm88DH+93am1Vcyw3PbSLYz5vK+ha+2FvEqJggRscEUd9sZXtuJY99lUV6agTVDS1858lvaWyxsju/inMe+Zo3t+YBKqPnpQ3H+O+3R7jlhS20WtvIq2ggwJj9e//7e/h8T2Gnbbf5iMoA2pVXZSsTsfVoBbe/tJXm1jbe21HAkn+s5kg3s3saW6zc/MJmqhpaqG+22gaPe8LhkloufvwbSmqaenxsb8jMr2JXSSutvZwhrRneaIEfYpw7NQGLl6Ckuomnr0snLTrI5X7P3zSHJ66Z5bQt1N+H6Snh1DS2cv8Fk1gwOsoWAnrsK5WpMzrG+XwT4kMAuGpuCo9fPYubFqbx3Dc5vLfDeQKWmYL5v/VHEAjeu+NUZo0IN84ZzGjDM7/p+c20ScnDV8zg/84YR0SgLy/ePI8vf3was0ZEcM8bO3noi4O8viUPi5fgttNGs+ZgCZuPVJBXUU9KZAA/nOHH5KQw7nhlu024XbH5SDnRwb74+3jx6qZjAPz10/18klnItmMVrD1YQpuEDdlltmOeWnOYH7y8lTe35nUIA+3IrSS7pI5r56uQmBlyMqlukny5r/Nw0Bd7i9iRW8nqA8Wd7tdf/OjV7Ty4tYnT/p5BQWVDj48vqGzgDx/utXWWmuGFFvghRkyIHy/dPI+PfrSIZRM7hh1MQvx9CPLrGGG774LJPHb1TG5cOBJQaZx/uXQqbVISHuhDYliA0/6njY8hNSqQu5aNA+BX505kSlIoT2TYJ0B9vqeQafd/znPrcnh7Wz7nT0sgJsSPFYtHAarTGBMbjBDg7+PFf2+aS0pkID9cOobNv1rOlKQwYkP9efHmuVw2K5lHvjzE/9YfYen4GG5amAbAwaIacisaSI4IJMBb8MJNc/Dz9uLptdlO9lrbJK9tPkZRdSObj5SzYHQ0501N5J3t+by2+Zgtr/+brFI2Gs83H1GDzG1tkn9nHOaLvUXc88bODiK8K68SgOvmK5uyip0F/r3Dzdz8whYnIc2vbLCt1wv2Ae2N2d0TzPK6Zu5a2XlHZpJVXMM9b+ykqkFdr6CygezSOubFW8ivbOC9HT0bN3hvRz5L/5HBs+ty+Msn7u/aNCcuWuCHIAtGR/UobuzIjJRwzp+W6LTtyrkjWPuzpXz8o0V4tauMefqEONb8dCkxISrU423x4mIjTHS0rI6q+hZ+9W4mrW1t/P7DvdQ2tXLdAhVSOnNSPP/47nQumplEbKg/b3x/AZ/etZgFDpO9HCtxelu8eODSKUxPUWGjK+aMIDbEj7AAHw4U1SgPPkJ1QOGBvlw+J4WPdx+nqFqFSqSU3P/+Hu59azdXPbOBouom5qZF8H9njCXU34d739pNiL83E+JDeGd7PvmVDVi8hM073V9YQ1VDC3+4aAp+3l58k1VGY4uVBz8/QEVdMztzq0iOCGBcXDCh/t5OHryUkl0l6i7G7BisbZKLH/+Gn725y7bPNiMldWOO/a6hubWN5taOIZSy2iaufmYD7+0o4KPdx51e+/ZwKbe8sMUpTPWnj/bx5tY8HvpCFZz7xsiYOn+0L5MSQp1KWDS2WKl26HhMcsvreWnDUT7cVcA9b+xkenI431s4kq1HKzrcsYC6+zn3ka9tn0F3+GxPIfku7iZWHyh2Kq/tiqr6Fpd2a3qHFviThBB/HxLDA7reEfvA7Wd7CvndB3sor2vm1VvnMykhlDlpEcxICQfAy0vwnfRk2+Su2WmRXc4F8PO28Mz16fz50qmcPiHWNg6w5Ug5NY2tJEfYO7brF6RilZKXjBIOj36ZxYsbjrJobLQt/37OyEiSIwJ5+dZ5JIUHcNtpo1k+MY68CiUwF89I4lh5PUXVjbZQzaJxMcwaEcGG7DI+3n2cR7/K4oX1R9iZV8n0lHCEEIyJDXby4HNK6yhpUCGd1ftVCuquvEpKapr4bE8hueX1FFQ1UlLTxKjoIPIqGjhSWsfDqw4y74FV3PDcpg5t8bdPD5BdWkdUkC8HHVJV/7f+CFc/s5FV+4psdzC786pYfaCE2BA/XtxwlAOFNXx7uIyoIF+SggXLJsay9WiFbU7Db97N5KyH1lJV7yyWD606yK/fzeSOV7aTEhnIM9fP5rbTRuEl4C1jfASgtqmV3PJ6fvjyNvYer+aDbpapPlBYw/df3Mq5j3zNzpJW2/bjVQ3c/N/NPPTFoU6Pv/3lrfz4tR3dulZ3kVL2KENsOKEFXtOBlMhAJiWE8thXWby9PZ8fLh3DvFFRfHDnqbx487w+Z5bEhvhz1dwRNu9+bFwwB4tqjWvbO6HUqCDOmBjHExmHufPV7Ty06iCXzUrmf9+by3XzU0kKD2BcrBpDGB0TzNc/W8oPl47hlDHqDiLU39sWT99ypIKNOWWkRAaQFB7A/FFR7D1ebav/88rGY+RVNDA9Ocx2vsMOk7gyjPo/S8bH8E1WKY0tVtYcLEEIEELw4oaj7DC8dzN0dd1zG3l41SHCAnxYn11myxICJToZB4s5Y1Icp4yJ5oCxVoC1TfLUmmzSUyO4fcloth6roKSmiUe/OkSovzdv3X4KIf7e3LVyO+uySlkwOgovIVg6IZY2aZ//sOlIOcerGvnVu7t56IuD/P2z/Ugp+TarjEVjo3ngkqm8dPM8wgJ9iA3157RxMby1LY/GFisrNx1j2v2fsehvq2lssZIcEcBn7Qa8axpb+GT38Q71h1YZYxSxIX48vr3JVlLjzS2qGmpnsf62NsmO3Eq2Hq3oMD7S1GqlqLqxV8Xx3t2Rzyl//srtegyFVY18ua+IzUfK+6X43lBCC7zGJWdPiae6sZVFY6O5a5la0criJWwTrvqT8cZAL+DkwQP84/LpLJsYywc7Czh9Qix/uWwqQgh+f9FkMn66xCnkZD6fNSICfx8v5o6MZGpSGIG+Fj7cVcDGnHLmj1TiP39UJFKqWb5pUYEUG1kv05PDARgTG0xJTRPHyupZvb+YTzMLiQ8S3LAgjYYWK5tyyllzsITpyeGcPSWelZuO8c72fPy8vbh4ZhKh/t7kljdw79kTePHmeQB84JBbf6i4lqLqJhaNiWZ8XDB5FQ3UNrXy1f5i8isbuOXUkVwwLREp4c+f7OOLvUXcsmgUKZGB/OuqmWSX1FFS08TCMdE2u6OCfPlqfzFVDS0cLasnKTyAD3cd55EvD/H46sNkHCihsLqRs6fEc/W8EU53dN87dSRF1U3c+ep2fv/hXmaNiOCuZWN56ZZ5fDc9hS1HKyiuaaSmsYW/frqfBX/+ittf3sbV/9nAztxK3tiSS3VjC1/uK2JqUhi/vWASzW1qLKKtTfL61ly8BLa7KVfkVzZQ32ylor6FQod9pJR8/8WtzHvgSybf95ktE6u7rNyUS2ubdHvcna9u4+YXtvDdJ9fzdjequ/aWuqZW2/jJx7uP88iqQ92a79EXdB68xiVXzEmhsLqRe84c73JFq/5kXJyjwAdQ6vBaqL8PT16bzqaccqanhONj5OcLIfCxuLbL38fCv6+ZRUpEIN4WL244Jc02aDxvlBL46Snh+Hl70dTaxj8vn87Vz6jcd3OWr1ma+fx/fU11o/JCz0r1ZsHoKAJ9LTzw8T4OFtVw5+ljOWdqPBuzy1i1r4jZqRH4+1hYsXgUjS1t3HbaKIQQzBoRzvs7ChgRGUirVVJaqzqUU8dGs7dALRhzqKiGF749QkKYP2dMisPiJUiJDODtbfkkhPlz6yJ1Z7BobAxPXDuLx1dnsWxiLHu3ZmPxEpw2Poav9hfbBot/f9FkDhXXMiYmmBUvbuHX72YCcMro6A5ttmhsDHcvH8vDqw4R7OfNI1fNtNVMCvT15qFVB/nl25nsyK2gtLaZC6Ynkj4inAc+2c9Fj38DwNvb8tmeW8ldy8YyJy0SXy91R+Hn7UVueQPfWziS577JYVNOORdMT+xgg+OM6r0F1SQYCQGfZhaScaCEK+ekkF1ax8/e3EmAj4XzpiW4/Pwdya9sYGNOOT4WwTvb8/npWeOdXi+samTzkQpuPCWNdVmlvLj+CN9JT+7yvF1RUdfMU2uzueP0MQQbyRD3vLGTA0U1vPODhfzynd1U1reQFBHQL9dzhxZ4jUviQv154JKpA3ItU+BD/Lw7TOoCJeamMHeX0yfYM5DuPXsC4+NCeG1zLkvHq0li/j4W5o+KoqSmifTUSC6dlczh4lpbZpKZ9imBJ66ZRZsEivbj72Phsatn8sOXt9MmVRbShPhQVt+zhBc3HLXdAdzRbh3fC6Yn8rsP9nLHK9sBtSLYqJggkiMCbRVEP8ksZF1WKfecOc420eysSfH8Z10O9549gQBf+93Tsolxtiyrvea2CXG8vS2f/61XYaeZIyJs+ywcE83Xh0pJDPMnzc0AvnmnNi05zCbuAOPighkVHcSqfUUsHBPFs2dNYLoxDjN3ZBSZBVUUVjXyoDH4u3xiHP4+FiZEWcg4UMyegiqignz58ZnjWLn5GJuPuBb4gw4hlH3Hq1k2MY6GZit/+HAvExNC+ePFU2i2tnHNfzbyy3d2c9bkOKcJea9tPsa3h8v4+3em4+uttpvrLfz0rPHGGgxlTtf81Jgfcu38VNKiArn/g73syqukodnKN4fLaGq1csnMJCbE24vordpbxNNfZ/PizXPx83Z9R/vG1lyeXHMYieQX56jlPfcUVHOsvJ7rnt1IZX0Lo6KDuO+9TL49XIq/j8Ujvzct8JpBJzLIl+hgP6KDfT02c/TimUlcPDPJadujV87Eatwi/+niKU6vqdTRsZw1Od5WITMj4wCgOo/Xv7+AtYdKmGEIeoi/Dz9YMsbt9S+akcSagyWcMSmOlZty2Z1fxQ1GNlJKRCD+Pl48/00OvhYvrpxrL02xYvEoUqODuNCFILZn0bhovL0EX+wtIik8gEiHAe/LZiXz9aFSFoyOdtvGQgjuXj7O5fZnb5xDfXMrkxOd1zuYlBjKpMRQpJQcKKphX0E1k432mhpt4eV99Rwpq+eBS6YS7OfNrBERfHu4jM/2FDIlSXUkOaV1BPt5c6CwhuSIACxegr3H1V3NezvyKahq5B+XT8fb4oW3xYubFo7kR69uJ7Ogmhkp4TS3tnH/B3t4ZaOaC5GeGsH1C9Jotbbx5tY85qRFcMMpafw74zC//2APV422ssSw/5PMQsbFBTMmNpjYUD/++ukBrnp6A3XNVryECks+tSabP1w0mesWpAHw0e7jbMop59PMQi6a4fydamyx4u9jYdU+lWn13LocrpqjwmF5FfUIoSbmzUmL4KErZvD9F7eyMbuchDD/Lj/f3qAFXjMkuGRmIoG+A/t1DAu03y20Tx8VQvB/Z3QUO5OpyWFMTXa9uIsrIoN8+e9NcwFYPDaGO1/dbutwvLwEY2ND2J1fxaUzE51mJ8eG+nNdFyUbTEL9fZiTFsn67DKmJDmXbT5rcjwLRkVxWXqSm6M7Z6SbCXcmQgj+deVMmq1ttg5karTybicmhHLFHFUNde7ISB784iDff3ErqVGB/PWyadz0/GbSooNotbYxPi4EX28vW9jq5Y3HmBAfwgKHO7hTjDTcb7JKSY4I4LYXt7LlaAW3nTaabUcrePTLLL6TnsxbW/PIKa3j3rMn4Odt4dErZ/KzN3fxpw2N5MjdpKdGsOlIOXcad1uh/j7cuDCNL/YWceuikZwzNYFWq+RHr27nL5/s54xJ8cSH+bPTCIG9svGYTeCzimv4/Yf72JhdxnM3zmHr0Qoun53MR7uO8/Cqg9y5bCxtEm5dNJKVm3K5a9k4kiMC+ehHi3r1eXQXLfCaIcGvzps02CYMGCmRgbz7w4VO28bFKYG/3kVpip5w+oRY1meXdVg6MsDXwqsr5vfp3F3h5SXw97KHLOICBT8/ZwJLxsfYxnFuWJBGfKg/vt5e/PTNnVz59Ab8fbzYZ3jsZ0yKI8DHwieZhXybVcru/Cr+cNFkp7uO6GA/JsSH8E1WKTtyK9mdX8W/rprJBdMT2Xq0nMueWM8tL2xh3/FqFoyK4qzJKky1eFwMq35yGj9+7kte3XSMlzceIzHMn+86xMDvPXsC9549wel9/emSKZzx0Fr++NFeHrh0KtkldcSG+LExp5ys4loSw/25/KkNWNsk/j4Wvv/iVqxtkqvmjqDFKvkmq9QWkjp7SsKAfte1wGs0Q4Br5o9gRGSgbY5Bbzl7SjxPrc1m0diY/jGsDwihSlE4Ehbow+WGN9/c2sbfPjvA09en88u3d7O/sIbx8SG2Qckbn99MoK+lQ2gN1JjCf789grVN8tOzxtsEND01kl+fN5En1xymprGV35w/yalzCPbz5uqJftz7nYXUNrYyNSmsw91be1KjglixaBSPrc6yZS394twJ/OzNXTy+OoupSWGU1zXz1u0LyC6p46dv7iI62JfpyeFMS67kne35tlnVXd0J9TceE3ghxHPA+UCxlHJKV/trNCczs0ZE2OoG9YWUyEC2/Hp5P1jkeS6fk8J3ZycjhPL0b39pG7NGRBAX6s+vz5tITmkd6akRhLhYJW3hmCieXZdDbIifrdyFyS2LRnH9gjRKa5vcTu4b7VDVtDtcM38E/87I4u+fqXGYpeNjuf200Tz6VRaf7ylkblok6amRzEyJ4LM9RUxKDMXLSzDNGKN5f0cBof7eRAS6X/HNE3jSg/8v8BjwPw9eQ6PRnMCY3vWS8bFk/u4sWyjnFiMl1B3zRkYxIjKQH58xzuXYja+3V7dnbneHhLAAFo+LIeNACWlRgYQH+nLnsrGsPaTCRLctUfZ6eQn+c8Ns23GTE0Px9hIUVjcyPTlswMtPe0zgpZRrhRBpnjq/RqMZXvRkvkWQnzdrf7bUg9Z05IrZKWQcKLF55T4WL56+Lp01B0tYOj7W5TH+PhbGx4ewp6DabWVYTyI8OZPKEPgPOwvRCCFWACsA4uLi0leuXNmra9XW1hIc3LPbroFA29Vzhqpt2q6eMdzsam2T/GNLI2ek+pAe133f+L+ZTWTktXLRaB8uGdt5rabe2LZ06dKtUsrZLl+UUnrsD0gDMru7f3p6uuwtq1ev7vWxnkTb1XOGqm3arp6h7VKs3HRUpt77oXxnW16X+/bGNmCLdKOpuhaNRqPReJAl42OZPyqS+T2cjd0f6DRJjUaj8SBxof6sXLFgUK7tMQ9eCPEqsB4YL4TIE0Lc7KlraTQajaYjnsyiucpT59ZoNBpN1+gYvEaj0QxTtMBrNBrNMMWjefA9RQhRAhzt5eHR4LRWxFBB29Vzhqpt2q6eoe3qOb2xLVVK6bL40JAS+L4ghNgi3SX7DyLarp4zVG3TdvUMbVfP6W/bdIhGo9Fohila4DUajWaYMpwE/unBNsAN2q6eM1Rt03b1DG1Xz+lX24ZNDF6j0Wg0zgwnD16j0Wg0DmiB12g0mmHKCS/wQoizhRAHhBBZQoifD6IdKUKI1UKIfUKIPUKIu4zt9wsh8oUQO4y/cwfJviNCiN2GDVuMbZFCiC+EEIeMx76vGdczm8Y7tMsOIUS1EOLuwWgzIcRzQohiIUSmwza37SOE+IXxnTsghDhrEGz7uxBivxBilxDiHSFEuLE9TQjR4NB2Tw6wXW4/u4FqMzd2veZg0xEhxA5j+0C2lzuN8Nz3zF0d4RPhD7AAh4FRgC+wE5g0SLYkALOM5yHAQWAScD9wzxBoqyNAdLttfwN+bjz/OfDXQf4sC4HUwWgzYDEwC4f1C9y1j/G57gT8gJHGd9AywLadCXgbz//qYFsaPViDwQN2ufzsBrLNXNnV7vV/Ar8dhPZypxEe+56d6B78XCBLSpktpWwGVgIXDYYhUsrjUsptxvMaYB/QcTn4ocVFwAvG8xeAiwfPFJYBh6WUvZ3J3CeklGuB8nab3bXPRcBKKWWTlDIHyEJ9FwfMNinl51LKVuPfDUCyp67fE7s6YcDarDO7hFoU9XLgVU9cuzM60QiPfc9OdIFPAnId/s9jCIiqsVThTGCjsekO41b6uYEOgzgggc+FEFuNZRIB4qSUx0F9+QDXC0sODFfi/KMbCm3mrn2G2vfue8AnDv+PFEJsF0KsEUIsGgR7XH12Q6XNFgFFUspDDtsGvL3aaYTHvmcnusC7WqV3UPM+hRDBwFvA3VLKauAJYDQwAziOuj0cDBZKKWcB5wA/FEIsHiQ7OiCE8AUuBN4wNg2VNnPHkPneCSF+BbQCLxubjgMjpJQzgR8DrwghQgfQJHef3VBps6twdiQGvL1caITbXV1s61GbnegCnwekOPyfDBQMki0IIXxQH9zLUsq3AaSURVJKq5SyDXgGD97Kd4aUssB4LAbeMewoEkIkGLYnAMWDYRuq09kmpSwybBwSbYb79hkS3zshxA3A+cA10gjaGrfzZcbzrai47biBsqmTz27Q20wI4Q1cCrxmbhvo9nKlEXjwe3aiC/xmYKwQYqThBV4JvD8YhhixvWeBfVLKBx22JzjsdgmQ2f7YAbAtSAgRYj5HDdBlotrqBmO3G4D3Bto2Ayevaii0mYG79nkfuFII4SeEGAmMBTYNpGFCiLOBe4ELpZT1DttjhBAW4/kow7bsAbTL3Wc36G0GLAf2SynzzA0D2V7uNAJPfs8GYvTYwyPT56JGow8DvxpEO05F3T7tAnYYf+cCLwK7je3vAwmDYNso1Gj8TmCP2U5AFPAlcMh4jBwE2wKBMiDMYduAtxmqgzkOtKA8p5s7ax/gV8Z37gBwziDYloWKz5rftSeNfS8zPuOdwDbgggG2y+1nN1Bt5souY/t/gdva7TuQ7eVOIzz2PdOlCjQajWaYcqKHaDQajUbjBi3wGo1GM0zRAq/RaDTDFC3wGo1GM0zRAq/RaDTDFC3wGk0/IIRYIoT4cLDt0Ggc0QKv0Wg0wxQt8JqTCiHEtUKITUbt76eEEBYhRK0Q4p9CiG1CiC+FEDHGvjOEEBuEveZ6hLF9jBBilRBip3HMaOP0wUKIN4Wq0/6yMXNRoxk0tMBrThqEEBOBK1CF12YAVuAaIAhVC2cWsAa4zzjkf8C9UsppqNmZ5vaXgcellNOBU1CzJkFVB7wbVcd7FLDQw29Jo+kU78E2QKMZQJYB6cBmw7kOQBV2asNegOol4G0hRBgQLqVcY2x/AXjDqOmTJKV8B0BK2QhgnG+TNOqcGCsGpQHrPP6uNBo3aIHXnEwI4AUp5S+cNgrxm3b7dVa/o7OwS5PDcyv696UZZHSIRnMy8SXwHSFELNjWwkxF/Q6+Y+xzNbBOSlkFVDgsAHEdsEaq+t15QoiLjXP4CSECB/JNaDTdRXsYmpMGKeVeIcSvUStbeaGqDf4QqAMmCyG2AlWoOD2o0q1PGgKeDdxkbL8OeEoI8XvjHN8dwLeh0XQbXU1Sc9IjhKiVUgYPth0aTX+jQzQajUYzTNEevEaj0QxTtAev0Wg0wxQt8BqNRjNM0QKv0Wg0wxQt8BqNRjNM0QKv0Wg0w5T/Bynd+KiPI/3aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 58.3794 - mae: 2.1292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[58.37940979003906, 2.129176378250122]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resource 3\n",
    "\"\"\"\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Training on Developed Countries')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.ylim(top = 8)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "score1 = model.evaluate(X_test, y_test, verbose=1)\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction scaling\n",
    "We're scaling prediction data with mean and standard deviation values of trained data, so that prediction values range would match the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_prediction(n, columns, X):\n",
    "    X_scaled = X\n",
    "    counter = -1\n",
    "    \n",
    "    for col in range(0, n):\n",
    "        counter += 1 # for each column\n",
    "        col_mean = x_original[columns[counter]].mean()\n",
    "        col_std = x_original[columns[counter]].std()\n",
    "        for row in range(0, len(X)):\n",
    "            X_scaled.loc[row][col] = (X.loc[row][col] - col_mean) / col_std\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original = pd.read_csv('x_original.csv')\n",
    "x_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Developing Countries Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 39)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Resource 4\n",
    "\"\"\"\n",
    "developing = pd.read_csv('developing_banks_dropped.csv')\n",
    "developing = developing.fillna(developing.median())\n",
    "developing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_developing = developing['marketCap']\n",
    "best_feature_names = pd.read_csv('best_feature_names2.csv')['0'].to_list()\n",
    "X_developing = developing[best_feature_names]\n",
    "\n",
    "columns_developing = list(X_developing.columns)\n",
    "X_scaled_developing = scale_prediction(n, columns_developing, X_developing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_developing = model.predict(X_scaled_developing)\n",
    "\n",
    "developing['prediction'] = pd.DataFrame(predict_developing)\n",
    "developing['marketCap'] = developing['marketCap'] / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortName</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDFC BANK</td>\n",
       "      <td>119.246483</td>\n",
       "      <td>82.248817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICICI BANK</td>\n",
       "      <td>67.968793</td>\n",
       "      <td>45.202789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATE BK OF INDIA</td>\n",
       "      <td>55.169843</td>\n",
       "      <td>42.277294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KOTAK MAHINDRA BAN</td>\n",
       "      <td>54.205208</td>\n",
       "      <td>21.268042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXIS BANK</td>\n",
       "      <td>33.720593</td>\n",
       "      <td>20.644005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>VAKIFLAR BANKASI</td>\n",
       "      <td>1.562017</td>\n",
       "      <td>5.354911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>T. HALK BANKASI</td>\n",
       "      <td>1.343121</td>\n",
       "      <td>3.268083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>T.S.K.B.</td>\n",
       "      <td>0.406916</td>\n",
       "      <td>1.682636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ALBARAKA TURK</td>\n",
       "      <td>0.238569</td>\n",
       "      <td>0.159744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>SEKERBANK</td>\n",
       "      <td>0.218410</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              shortName   marketCap  prediction\n",
       "0             HDFC BANK  119.246483   82.248817\n",
       "1            ICICI BANK   67.968793   45.202789\n",
       "2     STATE BK OF INDIA   55.169843   42.277294\n",
       "3    KOTAK MAHINDRA BAN   54.205208   21.268042\n",
       "4             AXIS BANK   33.720593   20.644005\n",
       "..                  ...         ...         ...\n",
       "123    VAKIFLAR BANKASI    1.562017    5.354911\n",
       "124     T. HALK BANKASI    1.343121    3.268083\n",
       "125            T.S.K.B.    0.406916    1.682636\n",
       "126       ALBARAKA TURK    0.238569    0.159744\n",
       "127           SEKERBANK    0.218410    0.000000\n",
       "\n",
       "[128 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developing[['shortName', 'marketCap', 'prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE on Developing Banking Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 53.5697 - mae: 3.6093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[53.56966781616211, 3.6093146800994873]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developing_score = model.evaluate(X_scaled_developing, y_developing, verbose=1)\n",
    "developing_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction mean: 6.865645408630371 \n",
      "marketCap mean: 8.18444582285047\n"
     ]
    }
   ],
   "source": [
    "print('prediction mean:', developing['prediction'].mean(),'\\nmarketCap mean:', developing['marketCap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Turkish Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey = pd.read_csv('turkey_dropped.csv')\n",
    "turkey = turkey.fillna(turkey.median())\n",
    "turkey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tur = turkey['marketCap']\n",
    "best_feature_names = pd.read_csv('best_feature_names2.csv')['0'].to_list()\n",
    "X_tur = turkey[best_feature_names]\n",
    "\n",
    "columns_tur = list(X_tur.columns)\n",
    "X_scaled_tur = scale_prediction(n, columns_tur, X_tur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_tur = model.predict(X_scaled_tur)\n",
    "\n",
    "turkey['prediction'] = pd.DataFrame(predict_tur)\n",
    "turkey['marketCap'] = turkey['marketCap'] / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortName</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GARANTI BANKASI</td>\n",
       "      <td>4.585135</td>\n",
       "      <td>9.755918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKBANK</td>\n",
       "      <td>3.355317</td>\n",
       "      <td>9.450097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS BANKASI (C)</td>\n",
       "      <td>2.761096</td>\n",
       "      <td>7.289739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAPI VE KREDI BANK.</td>\n",
       "      <td>2.406071</td>\n",
       "      <td>8.160076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SABANCI HOLDING</td>\n",
       "      <td>2.291788</td>\n",
       "      <td>7.381636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAKIFLAR BANKASI</td>\n",
       "      <td>1.562017</td>\n",
       "      <td>5.354911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T. HALK BANKASI</td>\n",
       "      <td>1.343121</td>\n",
       "      <td>3.268083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T.S.K.B.</td>\n",
       "      <td>0.406916</td>\n",
       "      <td>1.682636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALBARAKA TURK</td>\n",
       "      <td>0.238569</td>\n",
       "      <td>0.159744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEKERBANK</td>\n",
       "      <td>0.218410</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             shortName  marketCap  prediction\n",
       "0      GARANTI BANKASI   4.585135    9.755918\n",
       "1               AKBANK   3.355317    9.450097\n",
       "2       IS BANKASI (C)   2.761096    7.289739\n",
       "3  YAPI VE KREDI BANK.   2.406071    8.160076\n",
       "4      SABANCI HOLDING   2.291788    7.381636\n",
       "5     VAKIFLAR BANKASI   1.562017    5.354911\n",
       "6      T. HALK BANKASI   1.343121    3.268083\n",
       "7             T.S.K.B.   0.406916    1.682636\n",
       "8        ALBARAKA TURK   0.238569    0.159744\n",
       "9            SEKERBANK   0.218410    0.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey[['shortName', 'marketCap', 'prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turkey Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction mean: 5.250284194946289 \n",
      "marketCap mean: 1.9168440234551287\n"
     ]
    }
   ],
   "source": [
    "print('prediction mean:', turkey['prediction'].mean(),'\\nmarketCap mean:', turkey['marketCap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Confidence Intervals for Turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 2\n",
    "\"\"\"\n",
    "def fit_model(X_train, y_train, optimizer, dropout_rate, batch_size):\n",
    "    model = create_model(n, optimizer, dropout_rate)\n",
    "    # fit the model on the training dataset\n",
    "    model.fit(X_train, y_train, validation_split = 0.2, \n",
    "              epochs=200, batch_size=batch_size, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 5\n",
    "\"\"\"\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test, optimizer, dropout_rate, batch_size):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        # define and fit the model on the training set\n",
    "        model = fit_model(X_train, y_train, optimizer, dropout_rate, batch_size)\n",
    "        # evaluate model on the test set\n",
    "        yhat = model.predict(X_test, verbose=0)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        # store the model\n",
    "        ensemble.append(model)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 5, this needs to be adapted so I can have multiple inputs\n",
    "\"\"\"\n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X):\n",
    "    # make predictions\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    # calculate 95% gaussian prediction interval\n",
    "    interval = 1.96 * yhat.std()\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 216.8482 - mae: 3.8307 - val_loss: 158.8501 - val_mae: 3.5413\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 354.0474 - mae: 4.0937 - val_loss: 149.8277 - val_mae: 3.5738\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 246.4409 - mae: 3.4878 - val_loss: 127.0762 - val_mae: 3.2615\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 116.6865 - mae: 2.7191 - val_loss: 130.5362 - val_mae: 2.9970\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 129.3053 - mae: 2.8123 - val_loss: 103.4702 - val_mae: 2.6417\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 107.8079 - mae: 2.3919 - val_loss: 406.4452 - val_mae: 4.5871\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 167.4833 - mae: 2.7532 - val_loss: 388.8951 - val_mae: 4.3629\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 54.7427 - mae: 2.0083 - val_loss: 197.9120 - val_mae: 3.5064\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 73.7669 - mae: 2.3546 - val_loss: 227.3317 - val_mae: 3.6597\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 130.6249 - mae: 2.7543 - val_loss: 369.9127 - val_mae: 4.1898\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 46.9183 - mae: 2.0425 - val_loss: 305.1897 - val_mae: 3.9318\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 49.9591 - mae: 1.9825 - val_loss: 243.2514 - val_mae: 3.5123\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 68.0140 - mae: 2.1197 - val_loss: 462.2509 - val_mae: 4.5778\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.3533 - mae: 1.9301 - val_loss: 478.9218 - val_mae: 4.7311\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 85.4221 - mae: 2.3388 - val_loss: 164.2335 - val_mae: 3.2940\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 44.9071 - mae: 1.9343 - val_loss: 315.0560 - val_mae: 3.9073\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 38.7241 - mae: 1.8783 - val_loss: 193.1568 - val_mae: 3.2656\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.2827 - mae: 1.9802 - val_loss: 406.9244 - val_mae: 4.3738\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.0237 - mae: 2.0322 - val_loss: 596.9072 - val_mae: 5.1412\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.2120 - mae: 2.2445 - val_loss: 191.4152 - val_mae: 3.3634\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.5344 - mae: 1.9441 - val_loss: 365.1285 - val_mae: 4.1624\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.0859 - mae: 1.8339 - val_loss: 319.8451 - val_mae: 4.0534\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.7636 - mae: 1.9056 - val_loss: 274.5699 - val_mae: 3.7497\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.5825 - mae: 1.6921 - val_loss: 266.8029 - val_mae: 3.6546\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.9342 - mae: 1.6761 - val_loss: 384.3096 - val_mae: 4.2447\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 83.3699 - mae: 2.0567 - val_loss: 329.2039 - val_mae: 3.8877\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7909 - mae: 1.7199 - val_loss: 398.9493 - val_mae: 4.1474\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.8694 - mae: 1.7699 - val_loss: 372.6214 - val_mae: 4.0482\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 61.3116 - mae: 2.0258 - val_loss: 503.5207 - val_mae: 4.5439\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.9868 - mae: 1.7706 - val_loss: 400.8805 - val_mae: 4.1053\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 48.3690 - mae: 1.8170 - val_loss: 219.6848 - val_mae: 3.3880\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.8381 - mae: 1.8018 - val_loss: 187.4182 - val_mae: 3.1408\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.7719 - mae: 1.7261 - val_loss: 295.2293 - val_mae: 3.7611\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.0273 - mae: 1.6118 - val_loss: 195.4958 - val_mae: 3.2601\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6014 - mae: 1.6463 - val_loss: 315.1524 - val_mae: 3.8899\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 29.9418 - mae: 1.6866 - val_loss: 264.3681 - val_mae: 3.5676\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.5968 - mae: 1.6358 - val_loss: 399.2303 - val_mae: 4.2288\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 60.4727 - mae: 1.9142 - val_loss: 273.4501 - val_mae: 3.7343\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.3064 - mae: 1.6834 - val_loss: 259.9111 - val_mae: 3.6226\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3196 - mae: 1.5096 - val_loss: 266.0587 - val_mae: 3.6233\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.3550 - mae: 1.7037 - val_loss: 163.8888 - val_mae: 3.0429\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.6972 - mae: 1.7479 - val_loss: 185.3508 - val_mae: 3.1174\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 51.5959 - mae: 1.8207 - val_loss: 240.8309 - val_mae: 3.5313\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.0847 - mae: 1.4799 - val_loss: 249.1359 - val_mae: 3.5729\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.8744 - mae: 1.4668 - val_loss: 184.6848 - val_mae: 3.2891\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 31.3812 - mae: 1.6127 - val_loss: 392.7510 - val_mae: 4.2325\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 28.7367 - mae: 1.5602 - val_loss: 250.1187 - val_mae: 3.5233\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.9365 - mae: 1.5321 - val_loss: 318.5700 - val_mae: 3.8711\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 28.0662 - mae: 1.6387 - val_loss: 323.1895 - val_mae: 3.8876\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 58.5202 - mae: 1.8882 - val_loss: 281.7477 - val_mae: 3.6704\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 20.9006 - mae: 1.4205 - val_loss: 191.2384 - val_mae: 3.2113\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.2268 - mae: 1.5371 - val_loss: 273.3033 - val_mae: 3.7249\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.7057 - mae: 1.5212 - val_loss: 233.0213 - val_mae: 3.4699\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 64.1363 - mae: 1.8516 - val_loss: 143.9067 - val_mae: 2.9023\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.1493 - mae: 1.7552 - val_loss: 499.4604 - val_mae: 4.8117\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6602 - mae: 1.5563 - val_loss: 321.9804 - val_mae: 3.9151\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 22.7544 - mae: 1.3482 - val_loss: 302.5428 - val_mae: 3.7479\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 25.4271 - mae: 1.4811 - val_loss: 293.4521 - val_mae: 3.7036\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6856 - mae: 1.6199 - val_loss: 200.2675 - val_mae: 3.2094\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.6184 - mae: 1.7138 - val_loss: 221.5205 - val_mae: 3.3110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.8430 - mae: 1.2745 - val_loss: 219.6886 - val_mae: 3.3071\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.6938 - mae: 1.4694 - val_loss: 238.6792 - val_mae: 3.4892\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.1218 - mae: 1.5328 - val_loss: 266.2675 - val_mae: 3.6473\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.0202 - mae: 1.4716 - val_loss: 230.4177 - val_mae: 3.3783\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5738 - mae: 1.3946 - val_loss: 217.1052 - val_mae: 3.2860\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.3986 - mae: 1.4786 - val_loss: 291.8027 - val_mae: 3.7048\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.3777 - mae: 1.3711 - val_loss: 256.1138 - val_mae: 3.5028\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.7453 - mae: 1.6840 - val_loss: 401.6756 - val_mae: 4.1912\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.2302 - mae: 1.8127 - val_loss: 179.6232 - val_mae: 3.1060\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.3885 - mae: 1.4803 - val_loss: 153.5695 - val_mae: 2.9432\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7772 - mae: 1.5071 - val_loss: 181.3803 - val_mae: 3.1223\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.5351 - mae: 1.4259 - val_loss: 192.8606 - val_mae: 3.1466\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5645 - mae: 1.5189 - val_loss: 287.5740 - val_mae: 3.7014\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.0174 - mae: 1.3757 - val_loss: 238.6501 - val_mae: 3.3805\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.2026 - mae: 1.3653 - val_loss: 272.5064 - val_mae: 3.5463\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.3565 - mae: 1.3545 - val_loss: 243.1423 - val_mae: 3.5549\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.1341 - mae: 1.3827 - val_loss: 148.4385 - val_mae: 2.9609\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.3790 - mae: 1.3898 - val_loss: 155.9578 - val_mae: 3.0006\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.5892 - mae: 1.6237 - val_loss: 167.1960 - val_mae: 3.0437\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8680 - mae: 1.4824 - val_loss: 246.9405 - val_mae: 3.5188\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.9593 - mae: 1.4021 - val_loss: 182.3152 - val_mae: 3.1250\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2289 - mae: 1.2966 - val_loss: 211.6236 - val_mae: 3.2671\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0292 - mae: 1.3338 - val_loss: 171.6610 - val_mae: 3.0432\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6128 - mae: 1.2938 - val_loss: 181.3826 - val_mae: 3.1204\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.5694 - mae: 1.4736 - val_loss: 269.2863 - val_mae: 3.6241\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8798 - mae: 1.3272 - val_loss: 221.7899 - val_mae: 3.3270\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.8178 - mae: 1.2493 - val_loss: 178.6040 - val_mae: 3.1145\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.4136 - mae: 1.2841 - val_loss: 200.4017 - val_mae: 3.2725\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2659 - mae: 1.2841 - val_loss: 209.7148 - val_mae: 3.3506\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7424 - mae: 1.3329 - val_loss: 236.7280 - val_mae: 3.4553\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.4180 - mae: 1.4467 - val_loss: 194.8774 - val_mae: 3.3320\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.9712 - mae: 1.2567 - val_loss: 159.8440 - val_mae: 3.0325\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.3989 - mae: 1.5678 - val_loss: 209.2571 - val_mae: 3.2723\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.4808 - mae: 1.4245 - val_loss: 380.8293 - val_mae: 4.0749\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.2121 - mae: 1.4990 - val_loss: 211.5289 - val_mae: 3.2803\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.0404 - mae: 1.2462 - val_loss: 290.8387 - val_mae: 3.6591\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.7428 - mae: 1.3530 - val_loss: 165.4385 - val_mae: 2.9775\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.2801 - mae: 1.4252 - val_loss: 195.9040 - val_mae: 3.1953\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2235 - mae: 1.2555 - val_loss: 186.9187 - val_mae: 3.1637\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.8401 - mae: 1.3115 - val_loss: 253.4744 - val_mae: 3.4621\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6330 - mae: 1.3022 - val_loss: 188.0029 - val_mae: 3.1255\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8866 - mae: 1.4123 - val_loss: 266.4031 - val_mae: 3.5610\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0070 - mae: 1.3344 - val_loss: 152.4766 - val_mae: 2.9148\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4494 - mae: 1.2464 - val_loss: 287.6524 - val_mae: 3.6127\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.0797 - mae: 1.2103 - val_loss: 251.7382 - val_mae: 3.4528\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6974 - mae: 1.4104 - val_loss: 161.9272 - val_mae: 2.9977\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.7857 - mae: 1.2307 - val_loss: 202.0947 - val_mae: 3.2413\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6923 - mae: 1.4274 - val_loss: 179.7653 - val_mae: 3.0516\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.1468 - mae: 1.3586 - val_loss: 213.6806 - val_mae: 3.2717\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.8615 - mae: 1.4111 - val_loss: 164.8432 - val_mae: 3.0574\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.1344 - mae: 1.2659 - val_loss: 173.4433 - val_mae: 3.0449\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5351 - mae: 1.2239 - val_loss: 162.8068 - val_mae: 3.0061\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8392 - mae: 1.2469 - val_loss: 165.4945 - val_mae: 3.0329\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.4950 - mae: 1.2615 - val_loss: 194.1833 - val_mae: 3.1662\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.4114 - mae: 1.3376 - val_loss: 165.2050 - val_mae: 2.9552\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.1140 - mae: 1.1889 - val_loss: 174.8586 - val_mae: 2.9949\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.3958 - mae: 1.5208 - val_loss: 263.8437 - val_mae: 3.4641\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.9097 - mae: 1.5344 - val_loss: 120.5929 - val_mae: 2.6101\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2084 - mae: 1.3483 - val_loss: 176.4569 - val_mae: 3.0041\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.0076 - mae: 1.3670 - val_loss: 208.8552 - val_mae: 3.2437\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5429 - mae: 1.3372 - val_loss: 206.0347 - val_mae: 3.2833\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8863 - mae: 1.2478 - val_loss: 202.0779 - val_mae: 3.2761\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6473 - mae: 1.1517 - val_loss: 211.7321 - val_mae: 3.3221\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6311 - mae: 1.1303 - val_loss: 178.6169 - val_mae: 3.0796\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0029 - mae: 1.3399 - val_loss: 170.5087 - val_mae: 3.0311\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.7687 - mae: 1.2732 - val_loss: 219.4403 - val_mae: 3.2599\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.6874 - mae: 1.2460 - val_loss: 162.6315 - val_mae: 3.1223\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.7903 - mae: 1.1860 - val_loss: 146.6630 - val_mae: 2.8971\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.4537 - mae: 1.2307 - val_loss: 174.4952 - val_mae: 3.1007\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.3351 - mae: 1.3643 - val_loss: 164.9347 - val_mae: 3.0705\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.6791 - mae: 1.1321 - val_loss: 160.8312 - val_mae: 3.1072\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5034 - mae: 1.2033 - val_loss: 246.2706 - val_mae: 3.5237\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.5583 - mae: 1.2634 - val_loss: 188.2398 - val_mae: 3.1854\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.3534 - mae: 1.3032 - val_loss: 164.8537 - val_mae: 2.9725\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4801 - mae: 1.1971 - val_loss: 126.0700 - val_mae: 2.6927\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.7192 - mae: 1.4070 - val_loss: 155.9600 - val_mae: 2.8868\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.5610 - mae: 1.2816 - val_loss: 176.3537 - val_mae: 3.0388\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.4004 - mae: 1.2109 - val_loss: 136.3922 - val_mae: 2.7826\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.8623 - mae: 1.2237 - val_loss: 201.8189 - val_mae: 3.1640\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5599 - mae: 1.2060 - val_loss: 210.1253 - val_mae: 3.2371\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.0318 - mae: 1.3514 - val_loss: 127.2026 - val_mae: 2.7345\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.9459 - mae: 1.1570 - val_loss: 176.7821 - val_mae: 3.0721\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.7433 - mae: 1.2941 - val_loss: 149.4378 - val_mae: 2.8649\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.4888 - mae: 1.1480 - val_loss: 162.6083 - val_mae: 2.9165\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 11.2794 - mae: 1.1307 - val_loss: 173.8678 - val_mae: 2.9814\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 14.0148 - mae: 1.1816 - val_loss: 142.5131 - val_mae: 2.7821\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.8154 - mae: 1.2771 - val_loss: 153.9362 - val_mae: 2.8514\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.2243 - mae: 1.1606 - val_loss: 151.8352 - val_mae: 2.8631\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.8607 - mae: 1.3903 - val_loss: 194.6970 - val_mae: 3.1172\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.2740 - mae: 1.2421 - val_loss: 222.3268 - val_mae: 3.3174\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.2780 - mae: 1.2389 - val_loss: 210.4905 - val_mae: 3.2007\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.7089 - mae: 1.2003 - val_loss: 207.9880 - val_mae: 3.2374\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2809 - mae: 1.1512 - val_loss: 131.4544 - val_mae: 2.6616\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.6976 - mae: 1.0494 - val_loss: 118.5542 - val_mae: 2.5421\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5051 - mae: 1.2756 - val_loss: 101.2963 - val_mae: 2.3200\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5026 - mae: 1.2666 - val_loss: 120.5326 - val_mae: 2.6043\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.7274 - mae: 1.2616 - val_loss: 108.9648 - val_mae: 2.4249\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9794 - mae: 1.1951 - val_loss: 150.6821 - val_mae: 2.7785\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.1755 - mae: 1.1463 - val_loss: 122.4272 - val_mae: 2.5825\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8704 - mae: 1.1818 - val_loss: 181.0711 - val_mae: 3.0001\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9455 - mae: 1.2292 - val_loss: 198.9961 - val_mae: 3.1363\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4344 - mae: 1.1670 - val_loss: 189.4169 - val_mae: 3.1011\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.9461 - mae: 1.3983 - val_loss: 134.5513 - val_mae: 2.7293\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5968 - mae: 1.3575 - val_loss: 179.8979 - val_mae: 3.0661\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.3889 - mae: 1.1027 - val_loss: 159.6600 - val_mae: 2.8779\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.8505 - mae: 1.1685 - val_loss: 178.1340 - val_mae: 3.0154\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.1614 - mae: 1.1583 - val_loss: 200.6820 - val_mae: 3.1253\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.9039 - mae: 1.2187 - val_loss: 200.9151 - val_mae: 3.1873\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8307 - mae: 1.1862 - val_loss: 154.0219 - val_mae: 2.8882\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.1828 - mae: 1.3320 - val_loss: 179.7843 - val_mae: 3.0837\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.5228 - mae: 1.2334 - val_loss: 217.5449 - val_mae: 3.3076\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.5757 - mae: 1.1537 - val_loss: 138.7811 - val_mae: 2.7532\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6320 - mae: 1.1792 - val_loss: 174.7419 - val_mae: 3.0282\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0194 - mae: 1.2442 - val_loss: 107.7198 - val_mae: 2.3970\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.9960 - mae: 1.2413 - val_loss: 139.0875 - val_mae: 2.7844\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.5389 - mae: 1.1406 - val_loss: 154.0887 - val_mae: 2.8482\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.1437 - mae: 1.1649 - val_loss: 195.1918 - val_mae: 3.1600\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.1739 - mae: 1.1194 - val_loss: 205.4337 - val_mae: 3.2041\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1363 - mae: 1.2620 - val_loss: 199.8501 - val_mae: 3.1531\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0385 - mae: 1.1565 - val_loss: 142.9221 - val_mae: 2.7548\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 7.8400 - mae: 0.9867 - val_loss: 171.1649 - val_mae: 2.9829\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.0156 - mae: 1.2183 - val_loss: 138.6127 - val_mae: 2.7146\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.4735 - mae: 1.3024 - val_loss: 186.5263 - val_mae: 3.0477\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.5002 - mae: 1.0770 - val_loss: 151.7021 - val_mae: 2.8075\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.6044 - mae: 1.3097 - val_loss: 144.9751 - val_mae: 2.7985\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 10.3153 - mae: 1.0550 - val_loss: 160.1494 - val_mae: 2.8722\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4009 - mae: 1.1025 - val_loss: 143.7580 - val_mae: 2.7762\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.5052 - mae: 1.0250 - val_loss: 167.1481 - val_mae: 2.9680\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.0780 - mae: 1.0526 - val_loss: 161.7792 - val_mae: 2.9301\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 23.5166 - mae: 1.3533 - val_loss: 120.2832 - val_mae: 2.4795\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.4919 - mae: 1.0836 - val_loss: 148.9726 - val_mae: 2.7501\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.4099 - mae: 1.1861 - val_loss: 157.1358 - val_mae: 2.8730\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 8.5279 - mae: 1.0300 - val_loss: 156.8202 - val_mae: 2.8480\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 8.6955 - mae: 1.0374 - val_loss: 158.8141 - val_mae: 2.8940\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 11.7811 - mae: 1.1429 - val_loss: 145.7069 - val_mae: 2.7906\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 9.1932 - mae: 1.0177 - val_loss: 152.1391 - val_mae: 2.7940\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 9.7571 - mae: 1.0486 - val_loss: 116.6315 - val_mae: 2.3970\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.6564 - mae: 1.1317 - val_loss: 146.5786 - val_mae: 2.7843\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 9.2708 - mae: 1.0522 - val_loss: 159.1264 - val_mae: 2.9654\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.9395 - mae: 1.0876 - val_loss: 142.7991 - val_mae: 2.7519\n",
      ">1, MAE: 2.003\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 373.1614 - mae: 4.4098 - val_loss: 154.7324 - val_mae: 3.2627\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 314.2506 - mae: 3.9234 - val_loss: 129.3831 - val_mae: 3.0667\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 225.0596 - mae: 3.1805 - val_loss: 324.0312 - val_mae: 4.9831\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 267.7626 - mae: 3.5414 - val_loss: 163.9348 - val_mae: 3.5553\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 165.6186 - mae: 3.1050 - val_loss: 256.9837 - val_mae: 4.0155\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 108.2535 - mae: 2.6374 - val_loss: 213.9932 - val_mae: 3.5060\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 118.4641 - mae: 2.8963 - val_loss: 196.5680 - val_mae: 3.2245\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 73.9532 - mae: 2.2700 - val_loss: 150.4968 - val_mae: 3.2342\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 161.9528 - mae: 2.7322 - val_loss: 346.4092 - val_mae: 3.8511\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 147.7872 - mae: 2.7201 - val_loss: 275.8303 - val_mae: 3.4949\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.7092 - mae: 2.1199 - val_loss: 368.2443 - val_mae: 3.7721\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 82.2401 - mae: 2.4523 - val_loss: 225.8496 - val_mae: 3.4039\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 63.0474 - mae: 2.2063 - val_loss: 261.2831 - val_mae: 3.5582\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 115.3664 - mae: 2.4659 - val_loss: 493.3864 - val_mae: 4.1358\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.3385 - mae: 2.0565 - val_loss: 256.0260 - val_mae: 3.4194\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.3528 - mae: 2.2347 - val_loss: 509.3725 - val_mae: 4.1569\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 83.0896 - mae: 2.2051 - val_loss: 511.0917 - val_mae: 4.1583\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.5834 - mae: 2.1892 - val_loss: 565.4127 - val_mae: 4.3117\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 52.8948 - mae: 2.1176 - val_loss: 576.0306 - val_mae: 4.2874\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 67.3112 - mae: 2.3297 - val_loss: 443.1702 - val_mae: 3.9305\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 108.9234 - mae: 2.5407 - val_loss: 545.2308 - val_mae: 4.2384\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.7059 - mae: 1.9209 - val_loss: 384.8711 - val_mae: 3.8547\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 58.6117 - mae: 2.1647 - val_loss: 592.2590 - val_mae: 4.2858\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.5883 - mae: 2.0149 - val_loss: 300.0548 - val_mae: 3.5854\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 48.0508 - mae: 2.0468 - val_loss: 307.3933 - val_mae: 3.6601\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.9431 - mae: 2.2022 - val_loss: 378.8550 - val_mae: 3.8856\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.2160 - mae: 2.0960 - val_loss: 314.6469 - val_mae: 3.6608\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 54.6445 - mae: 2.1009 - val_loss: 416.9192 - val_mae: 4.0791\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.8561 - mae: 1.9367 - val_loss: 525.7078 - val_mae: 4.3906\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.5431 - mae: 1.9581 - val_loss: 456.4701 - val_mae: 4.1413\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 73.6147 - mae: 2.1073 - val_loss: 470.1472 - val_mae: 4.1684\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2110 - mae: 1.7007 - val_loss: 449.1191 - val_mae: 4.1047\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.3158 - mae: 1.7507 - val_loss: 433.1018 - val_mae: 4.1176\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.1985 - mae: 1.7769 - val_loss: 309.4710 - val_mae: 3.6786\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 40.1374 - mae: 1.9258 - val_loss: 453.4964 - val_mae: 4.0978\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 76.3184 - mae: 2.1614 - val_loss: 433.3186 - val_mae: 3.9537\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 46.0385 - mae: 1.9532 - val_loss: 472.7857 - val_mae: 4.1362\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 35.6196 - mae: 1.8470 - val_loss: 518.4236 - val_mae: 4.3425\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 40.9926 - mae: 1.8925 - val_loss: 262.9318 - val_mae: 3.5824\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.9351 - mae: 1.9687 - val_loss: 482.7884 - val_mae: 4.3219\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.2273 - mae: 1.8240 - val_loss: 623.1415 - val_mae: 4.7312\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.3968 - mae: 1.9118 - val_loss: 380.1138 - val_mae: 4.0040\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.7601 - mae: 1.7610 - val_loss: 394.5481 - val_mae: 4.0742\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.5969 - mae: 1.7593 - val_loss: 365.9575 - val_mae: 3.9848\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.1079 - mae: 1.6796 - val_loss: 329.0183 - val_mae: 3.8111\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8816 - mae: 1.6410 - val_loss: 358.6136 - val_mae: 3.9342\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.7679 - mae: 1.8595 - val_loss: 456.5227 - val_mae: 4.2308\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.4079 - mae: 1.8319 - val_loss: 354.5063 - val_mae: 3.9110\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6361 - mae: 1.6014 - val_loss: 403.0447 - val_mae: 4.0445\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.7804 - mae: 1.8397 - val_loss: 387.7784 - val_mae: 3.9674\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.3348 - mae: 1.5629 - val_loss: 315.1662 - val_mae: 3.7516\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.5615 - mae: 1.8016 - val_loss: 291.1519 - val_mae: 3.6793\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.1100 - mae: 1.8267 - val_loss: 228.1889 - val_mae: 3.3873\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 52.3364 - mae: 1.8418 - val_loss: 291.6446 - val_mae: 3.6370\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.5742 - mae: 1.9028 - val_loss: 251.1876 - val_mae: 3.4928\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.0391 - mae: 1.6932 - val_loss: 422.6932 - val_mae: 4.1400\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.7790 - mae: 1.8683 - val_loss: 383.0034 - val_mae: 3.9388\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.5518 - mae: 1.8114 - val_loss: 265.9417 - val_mae: 3.4948\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6515 - mae: 1.6359 - val_loss: 373.8097 - val_mae: 3.8829\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.8519 - mae: 1.8116 - val_loss: 275.4652 - val_mae: 3.5225\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.6365 - mae: 1.7187 - val_loss: 228.4379 - val_mae: 3.3307\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.7715 - mae: 1.6920 - val_loss: 280.1977 - val_mae: 3.5918\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.7814 - mae: 1.8531 - val_loss: 414.7878 - val_mae: 4.0797\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.6795 - mae: 1.6986 - val_loss: 413.4395 - val_mae: 4.0705\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 54.5420 - mae: 1.8463 - val_loss: 208.4749 - val_mae: 3.2600\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.2516 - mae: 1.6972 - val_loss: 245.1508 - val_mae: 3.4841\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 88.9268 - mae: 2.1265 - val_loss: 242.0558 - val_mae: 3.4934\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.8798 - mae: 1.6324 - val_loss: 286.9355 - val_mae: 3.6848\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.8091 - mae: 1.6473 - val_loss: 293.5203 - val_mae: 3.6910\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.6834 - mae: 1.6657 - val_loss: 249.2900 - val_mae: 3.5137\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.7307 - mae: 1.7878 - val_loss: 340.0101 - val_mae: 3.8805\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.7491 - mae: 1.4160 - val_loss: 299.7611 - val_mae: 3.7379\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 23.5658 - mae: 1.5100 - val_loss: 241.8240 - val_mae: 3.4394\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.0520 - mae: 1.5785 - val_loss: 213.2069 - val_mae: 3.3277\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.0182 - mae: 1.7130 - val_loss: 200.8127 - val_mae: 3.2443\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6584 - mae: 1.5675 - val_loss: 242.8218 - val_mae: 3.4811\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6555 - mae: 1.5092 - val_loss: 221.1571 - val_mae: 3.4036\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.5229 - mae: 1.7243 - val_loss: 287.1989 - val_mae: 3.6602\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2480 - mae: 1.5950 - val_loss: 202.7364 - val_mae: 3.3112\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.4818 - mae: 1.4640 - val_loss: 384.1489 - val_mae: 4.0156\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.2483 - mae: 1.6426 - val_loss: 290.1283 - val_mae: 3.6986\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6643 - mae: 1.4445 - val_loss: 316.7191 - val_mae: 3.7771\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.1687 - mae: 1.6993 - val_loss: 241.4309 - val_mae: 3.4896\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.5690 - mae: 1.7361 - val_loss: 315.2554 - val_mae: 3.8592\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.8306 - mae: 1.6107 - val_loss: 268.2777 - val_mae: 3.5973\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.1519 - mae: 1.5896 - val_loss: 166.3795 - val_mae: 3.1056\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6665 - mae: 1.3259 - val_loss: 234.9535 - val_mae: 3.5014\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.3603 - mae: 1.5441 - val_loss: 167.4436 - val_mae: 3.1373\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.3480 - mae: 1.5754 - val_loss: 168.0849 - val_mae: 3.1579\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2463 - mae: 1.4615 - val_loss: 197.9109 - val_mae: 3.3269\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6180 - mae: 1.4102 - val_loss: 187.4800 - val_mae: 3.2571\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5583 - mae: 1.5870 - val_loss: 304.2897 - val_mae: 3.8138\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6232 - mae: 1.3683 - val_loss: 227.2905 - val_mae: 3.5092\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4296 - mae: 1.4539 - val_loss: 188.9154 - val_mae: 3.3035\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6349 - mae: 1.5725 - val_loss: 187.9692 - val_mae: 3.3107\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.4590 - mae: 1.4080 - val_loss: 188.4664 - val_mae: 3.3136\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.0690 - mae: 1.6523 - val_loss: 202.4618 - val_mae: 3.3546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.4129 - mae: 1.6114 - val_loss: 233.4901 - val_mae: 3.5333\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.1601 - mae: 1.4011 - val_loss: 233.5538 - val_mae: 3.5388\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6088 - mae: 1.5359 - val_loss: 305.7068 - val_mae: 3.8328\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6683 - mae: 1.5515 - val_loss: 338.8785 - val_mae: 4.0604\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.2667 - mae: 1.5771 - val_loss: 127.1020 - val_mae: 2.9504\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.4995 - mae: 1.6426 - val_loss: 187.0009 - val_mae: 3.2910\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.3685 - mae: 1.6176 - val_loss: 311.5139 - val_mae: 3.8212\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.0476 - mae: 1.6858 - val_loss: 205.9927 - val_mae: 3.3936\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.7538 - mae: 1.5976 - val_loss: 376.9829 - val_mae: 4.1293\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.9495 - mae: 1.7672 - val_loss: 169.6109 - val_mae: 3.2348\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0735 - mae: 1.4612 - val_loss: 170.0009 - val_mae: 3.2497\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.4874 - mae: 1.5518 - val_loss: 172.5815 - val_mae: 3.2664\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.7990 - mae: 1.5756 - val_loss: 185.3137 - val_mae: 3.3766\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.9701 - mae: 1.5958 - val_loss: 110.2159 - val_mae: 2.7249\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.2831 - mae: 1.5578 - val_loss: 101.3251 - val_mae: 2.7009\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.2225 - mae: 1.4379 - val_loss: 112.6977 - val_mae: 2.7681\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8780 - mae: 1.5304 - val_loss: 174.1742 - val_mae: 3.3499\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5793 - mae: 1.4319 - val_loss: 176.3054 - val_mae: 3.3119\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4913 - mae: 1.4006 - val_loss: 205.1498 - val_mae: 3.4619\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6532 - mae: 1.3224 - val_loss: 174.7326 - val_mae: 3.2906\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.1853 - mae: 1.5665 - val_loss: 131.5616 - val_mae: 2.9799\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8240 - mae: 1.4131 - val_loss: 186.4810 - val_mae: 3.3586\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5510 - mae: 1.4504 - val_loss: 151.2986 - val_mae: 3.1360\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.0881 - mae: 1.5487 - val_loss: 159.6988 - val_mae: 3.2027\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.6819 - mae: 1.3674 - val_loss: 169.3851 - val_mae: 3.2698\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.9848 - mae: 1.4592 - val_loss: 278.2419 - val_mae: 3.8238\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.1877 - mae: 1.3649 - val_loss: 186.1440 - val_mae: 3.3689\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.5555 - mae: 1.4810 - val_loss: 206.6216 - val_mae: 3.4715\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4377 - mae: 1.3444 - val_loss: 230.6056 - val_mae: 3.6162\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.1408 - mae: 1.3386 - val_loss: 155.2149 - val_mae: 3.1813\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2180 - mae: 1.5986 - val_loss: 254.1885 - val_mae: 3.7454\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.3892 - mae: 1.4013 - val_loss: 150.5750 - val_mae: 3.1557\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4189 - mae: 1.4083 - val_loss: 206.5439 - val_mae: 3.5044\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6817 - mae: 1.3106 - val_loss: 165.3600 - val_mae: 3.2314\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.6753 - mae: 1.4998 - val_loss: 222.6613 - val_mae: 3.5357\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.1337 - mae: 1.5282 - val_loss: 191.1059 - val_mae: 3.3971\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4098 - mae: 1.5322 - val_loss: 179.7672 - val_mae: 3.3344\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.3136 - mae: 1.4120 - val_loss: 146.2929 - val_mae: 3.0810\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.5683 - mae: 1.5304 - val_loss: 110.3228 - val_mae: 2.6917\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.7811 - mae: 1.5491 - val_loss: 156.6747 - val_mae: 3.1110\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6196 - mae: 1.4250 - val_loss: 164.0371 - val_mae: 3.1386\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.4816 - mae: 1.5587 - val_loss: 121.8476 - val_mae: 2.7540\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.2055 - mae: 1.2335 - val_loss: 141.0592 - val_mae: 2.9601\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4271 - mae: 1.3508 - val_loss: 138.2568 - val_mae: 2.9679\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.8588 - mae: 1.5163 - val_loss: 182.4015 - val_mae: 3.3085\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.4882 - mae: 1.3808 - val_loss: 116.9921 - val_mae: 2.7341\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 14.9221 - mae: 1.35 - 1s 2ms/step - loss: 14.8204 - mae: 1.3504 - val_loss: 165.5279 - val_mae: 3.1693\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.6951 - mae: 1.4486 - val_loss: 169.4482 - val_mae: 3.1801\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.2842 - mae: 1.3565 - val_loss: 184.2508 - val_mae: 3.2745\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.3219 - mae: 1.3541 - val_loss: 143.1530 - val_mae: 2.9334\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5633 - mae: 1.4936 - val_loss: 130.9744 - val_mae: 2.7100\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 23.6293 - mae: 1.5051 - val_loss: 143.6471 - val_mae: 2.9418\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5640 - mae: 1.4193 - val_loss: 177.4792 - val_mae: 3.2282\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2035 - mae: 1.3535 - val_loss: 158.8125 - val_mae: 3.1142\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.8025 - mae: 1.3264 - val_loss: 144.7534 - val_mae: 2.9720\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 43.5488 - mae: 1.6779 - val_loss: 115.6704 - val_mae: 2.6746\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 23.2220 - mae: 1.4526 - val_loss: 115.1201 - val_mae: 2.6569\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.1509 - mae: 1.4036 - val_loss: 156.0334 - val_mae: 3.1008\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.4013 - mae: 1.3744 - val_loss: 136.7807 - val_mae: 2.9224\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8317 - mae: 1.3295 - val_loss: 119.4275 - val_mae: 2.6704\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.2482 - mae: 1.4076 - val_loss: 137.9712 - val_mae: 2.9112\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 24.1264 - mae: 1.4197 - val_loss: 153.4041 - val_mae: 3.0775\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3927 - mae: 1.4685 - val_loss: 142.6839 - val_mae: 2.9788\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 23.2796 - mae: 1.4189 - val_loss: 190.3381 - val_mae: 3.3351\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.9719 - mae: 1.2819 - val_loss: 138.4641 - val_mae: 2.9308\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 9.3946 - mae: 1.2399 - val_loss: 142.3584 - val_mae: 2.9666\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.6100 - mae: 1.2511 - val_loss: 159.2951 - val_mae: 3.1065\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 16.9388 - mae: 1.3624 - val_loss: 115.3819 - val_mae: 2.6833\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 23.2999 - mae: 1.5002 - val_loss: 134.6399 - val_mae: 2.8643\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6299 - mae: 1.4524 - val_loss: 138.6097 - val_mae: 2.8775\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.4688 - mae: 1.2808 - val_loss: 120.7671 - val_mae: 2.6647\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.1957 - mae: 1.2877 - val_loss: 114.0625 - val_mae: 2.5722\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.8227 - mae: 1.3360 - val_loss: 111.9008 - val_mae: 2.5367\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 31.3249 - mae: 1.5998 - val_loss: 126.1181 - val_mae: 2.7697\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.0904 - mae: 1.2855 - val_loss: 160.8675 - val_mae: 3.1109\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.5886 - mae: 1.3057 - val_loss: 127.8750 - val_mae: 2.7616\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6362 - mae: 1.4097 - val_loss: 122.5752 - val_mae: 2.6264\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.3076 - mae: 1.3468 - val_loss: 119.1286 - val_mae: 2.6162\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.3860 - mae: 1.2893 - val_loss: 115.8828 - val_mae: 2.5264\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.9693 - mae: 1.3017 - val_loss: 122.6291 - val_mae: 2.6764\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.7283 - mae: 1.3844 - val_loss: 128.3606 - val_mae: 2.7345\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5973 - mae: 1.2594 - val_loss: 120.6623 - val_mae: 2.6012\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.9668 - mae: 1.3714 - val_loss: 126.0319 - val_mae: 2.7228\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.8728 - mae: 1.3288 - val_loss: 140.1155 - val_mae: 2.9217\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6433 - mae: 1.2368 - val_loss: 126.9292 - val_mae: 2.7194\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0404 - mae: 1.3496 - val_loss: 128.2884 - val_mae: 2.6908\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4893 - mae: 1.3813 - val_loss: 149.9862 - val_mae: 2.9631\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.2704 - mae: 1.3155 - val_loss: 155.5376 - val_mae: 3.0445\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.0439 - mae: 1.3191 - val_loss: 122.1592 - val_mae: 2.6985\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.7162 - mae: 1.1830 - val_loss: 128.4125 - val_mae: 2.7627\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.6724 - mae: 1.2164 - val_loss: 132.5260 - val_mae: 2.7858\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1792 - mae: 1.2746 - val_loss: 128.1640 - val_mae: 2.6667\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4757 - mae: 1.3235 - val_loss: 131.8183 - val_mae: 2.6755\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.0227 - mae: 1.2872 - val_loss: 146.2772 - val_mae: 2.8992\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.4500 - mae: 1.3148 - val_loss: 155.2879 - val_mae: 2.9978\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.2969 - mae: 1.1574 - val_loss: 133.1647 - val_mae: 2.7841\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.1111 - mae: 1.2730 - val_loss: 129.4889 - val_mae: 2.7174\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6460 - mae: 1.2260 - val_loss: 147.6048 - val_mae: 2.9673\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.5920 - mae: 1.2481 - val_loss: 136.7292 - val_mae: 2.8330\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 17.9833 - mae: 1.4243 - val_loss: 145.3456 - val_mae: 2.8985\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 10.3811 - mae: 1.1981 - val_loss: 123.8225 - val_mae: 2.5984\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.0327 - mae: 1.2714 - val_loss: 124.7980 - val_mae: 2.6215\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.2631 - mae: 1.3921 - val_loss: 168.0859 - val_mae: 3.2021\n",
      ">2, MAE: 2.203\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 454.3675 - mae: 4.2924 - val_loss: 143.0693 - val_mae: 3.6368\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 199.9263 - mae: 3.3780 - val_loss: 199.4993 - val_mae: 3.7771\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 169.7427 - mae: 3.1580 - val_loss: 211.0108 - val_mae: 4.0662\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 299.5970 - mae: 3.2797 - val_loss: 278.3863 - val_mae: 4.1543\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 178.5038 - mae: 2.8253 - val_loss: 235.4188 - val_mae: 3.5945\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 106.5385 - mae: 2.5586 - val_loss: 773.4504 - val_mae: 5.9490\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 107.6046 - mae: 2.5142 - val_loss: 268.3985 - val_mae: 3.5649\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 49.5197 - mae: 2.0368 - val_loss: 473.3580 - val_mae: 4.4862\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 76.4652 - mae: 2.3854 - val_loss: 249.6703 - val_mae: 3.1781\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 68.9574 - mae: 2.1266 - val_loss: 344.2380 - val_mae: 3.8616\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 54.4544 - mae: 2.1809 - val_loss: 209.7509 - val_mae: 3.1762\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 97.5606 - mae: 2.4492 - val_loss: 197.5375 - val_mae: 2.9724\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 73.8933 - mae: 2.1730 - val_loss: 305.5721 - val_mae: 3.5136\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.5511 - mae: 1.9927 - val_loss: 382.0591 - val_mae: 3.9675\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 63.4824 - mae: 2.0564 - val_loss: 365.9220 - val_mae: 3.7906\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 2ms/step - loss: 58.4832 - mae: 1.8195 - val_loss: 659.8591 - val_mae: 5.0415\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.3118 - mae: 1.6873 - val_loss: 229.4118 - val_mae: 3.2878\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.7319 - mae: 1.8055 - val_loss: 420.1666 - val_mae: 4.0679\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.8268 - mae: 1.8333 - val_loss: 149.9453 - val_mae: 2.9839\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 66.1787 - mae: 1.9760 - val_loss: 266.8097 - val_mae: 3.4534\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 52.1873 - mae: 1.8889 - val_loss: 347.2187 - val_mae: 3.8577\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 49.8391 - mae: 1.8035 - val_loss: 358.7379 - val_mae: 3.9696\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 68.2492 - mae: 2.0299 - val_loss: 163.0431 - val_mae: 2.9758\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 29.2273 - mae: 1.5880 - val_loss: 270.5329 - val_mae: 3.5681\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.4211 - mae: 1.7663 - val_loss: 301.4621 - val_mae: 3.6991\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 30.7963 - mae: 1.6641 - val_loss: 228.6084 - val_mae: 3.3781\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 48.3272 - mae: 1.8364 - val_loss: 254.8071 - val_mae: 3.4322\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 52.3397 - mae: 1.8896 - val_loss: 453.1916 - val_mae: 4.5326\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 63.7495 - mae: 1.8748 - val_loss: 208.9975 - val_mae: 3.3150\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6957 - mae: 1.5813 - val_loss: 391.2676 - val_mae: 4.2694\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 38.0063 - mae: 1.8275 - val_loss: 269.3625 - val_mae: 3.6114\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.5102 - mae: 1.6032 - val_loss: 300.9426 - val_mae: 3.8502\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.6242 - mae: 1.6465 - val_loss: 238.4181 - val_mae: 3.4197\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 47.7190 - mae: 1.8447 - val_loss: 453.3695 - val_mae: 4.5062\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.0726 - mae: 1.6738 - val_loss: 243.0678 - val_mae: 3.4841\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 33.9801 - mae: 1.7072 - val_loss: 202.3573 - val_mae: 3.2638\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 43.4371 - mae: 1.7379 - val_loss: 326.0354 - val_mae: 3.8573\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 22.6612 - mae: 1.4632 - val_loss: 247.9406 - val_mae: 3.4776\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.0089 - mae: 1.7461 - val_loss: 150.2740 - val_mae: 2.9037\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.5519 - mae: 1.7205 - val_loss: 162.9077 - val_mae: 3.0049\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 27.2298 - mae: 1.5408 - val_loss: 266.0329 - val_mae: 3.6350\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.1458 - mae: 1.5215 - val_loss: 227.9349 - val_mae: 3.4170\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 37.7355 - mae: 1.6122 - val_loss: 220.9072 - val_mae: 3.3795\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.5676 - mae: 1.3128 - val_loss: 189.9919 - val_mae: 3.1772\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.5049 - mae: 1.5601 - val_loss: 222.5136 - val_mae: 3.4447\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.1463 - mae: 1.6090 - val_loss: 324.1051 - val_mae: 4.0074\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 45.2287 - mae: 1.7678 - val_loss: 261.0055 - val_mae: 3.6457\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 38.1548 - mae: 1.6203 - val_loss: 170.9712 - val_mae: 3.2532\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 29.4764 - mae: 1.5398 - val_loss: 300.2253 - val_mae: 3.9560\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.6875 - mae: 1.5385 - val_loss: 212.6273 - val_mae: 3.3886\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.7458 - mae: 1.6604 - val_loss: 294.3110 - val_mae: 3.8080\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.2033 - mae: 1.6851 - val_loss: 165.4491 - val_mae: 3.0958\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 51.4073 - mae: 1.7141 - val_loss: 372.2291 - val_mae: 4.2197\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.7347 - mae: 1.5618 - val_loss: 208.5550 - val_mae: 3.3248\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.0185 - mae: 1.6531 - val_loss: 199.0320 - val_mae: 3.2427\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.2041 - mae: 1.6088 - val_loss: 219.0945 - val_mae: 3.3679\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.7840 - mae: 1.7840 - val_loss: 256.9700 - val_mae: 3.5506\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.0850 - mae: 1.6632 - val_loss: 300.7718 - val_mae: 3.9531\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.8859 - mae: 1.6038 - val_loss: 228.5705 - val_mae: 3.4775\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.1766 - mae: 1.4971 - val_loss: 116.7452 - val_mae: 2.7455\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.4431 - mae: 1.5299 - val_loss: 156.4445 - val_mae: 2.9833\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7938 - mae: 1.4642 - val_loss: 182.7066 - val_mae: 3.2110\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.3886 - mae: 1.5256 - val_loss: 231.6499 - val_mae: 3.5633\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6960 - mae: 1.3618 - val_loss: 227.5930 - val_mae: 3.5637\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5188 - mae: 1.3493 - val_loss: 173.2854 - val_mae: 3.1206\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.6631 - mae: 1.6866 - val_loss: 107.4715 - val_mae: 2.5750\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.5979 - mae: 1.5259 - val_loss: 250.1116 - val_mae: 3.6887\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.9538 - mae: 1.4362 - val_loss: 223.2310 - val_mae: 3.4452\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.5098 - mae: 1.4901 - val_loss: 184.1499 - val_mae: 3.2143\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.9188 - mae: 1.6685 - val_loss: 195.2884 - val_mae: 3.2874\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.9748 - mae: 1.5539 - val_loss: 265.6312 - val_mae: 3.7973\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.4340 - mae: 1.4908 - val_loss: 283.2155 - val_mae: 3.9134\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.0174 - mae: 1.3158 - val_loss: 253.6992 - val_mae: 3.7364\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.7436 - mae: 1.2058 - val_loss: 187.4998 - val_mae: 3.2544\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5900 - mae: 1.3065 - val_loss: 158.0051 - val_mae: 3.0558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.5978 - mae: 1.4915 - val_loss: 159.5056 - val_mae: 3.0585\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6054 - mae: 1.4015 - val_loss: 171.4864 - val_mae: 3.1551\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.9204 - mae: 1.4873 - val_loss: 209.3922 - val_mae: 3.3837\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.0721 - mae: 1.4236 - val_loss: 196.7557 - val_mae: 3.2784\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.4258 - mae: 1.3943 - val_loss: 202.0560 - val_mae: 3.3477\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 30.9336 - mae: 1.5121 - val_loss: 188.0111 - val_mae: 3.2191\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.9357 - mae: 1.3627 - val_loss: 228.1704 - val_mae: 3.5399\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6910 - mae: 1.2070 - val_loss: 130.0732 - val_mae: 2.7842\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7972 - mae: 1.3882 - val_loss: 146.8356 - val_mae: 2.9530\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.9829 - mae: 1.4225 - val_loss: 178.2659 - val_mae: 3.2069\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 26.8816 - mae: 1.3500 - val_loss: 129.4813 - val_mae: 2.8071\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 32.4989 - mae: 1.4259 - val_loss: 171.4631 - val_mae: 3.1880\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 18.1278 - mae: 1.3112 - val_loss: 169.5700 - val_mae: 3.1234\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.3172 - mae: 1.3345 - val_loss: 244.9289 - val_mae: 3.7571\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.8661 - mae: 1.3335 - val_loss: 139.6435 - val_mae: 2.8894\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.6122 - mae: 1.2603 - val_loss: 142.0454 - val_mae: 2.8995\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.2979 - mae: 1.1724 - val_loss: 163.8530 - val_mae: 3.0674\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0924 - mae: 1.2451 - val_loss: 128.0090 - val_mae: 2.7111\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.5267 - mae: 1.2363 - val_loss: 156.8527 - val_mae: 2.9866\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.4542 - mae: 1.2883 - val_loss: 156.0551 - val_mae: 2.9882\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.5187 - mae: 1.4450 - val_loss: 164.9327 - val_mae: 3.0733\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 19.1580 - mae: 1.2667 - val_loss: 144.2250 - val_mae: 2.8997\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 20.8065 - mae: 1.2516 - val_loss: 170.7332 - val_mae: 3.1228\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 24.1183 - mae: 1.3195 - val_loss: 144.6764 - val_mae: 2.8669\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 11.7399 - mae: 1.1008 - val_loss: 153.7130 - val_mae: 2.9797\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 24.4732 - mae: 1.3935 - val_loss: 143.6199 - val_mae: 2.9176\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.8002 - mae: 1.3404 - val_loss: 137.9375 - val_mae: 2.7877\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 23.8161 - mae: 1.3402 - val_loss: 138.4112 - val_mae: 2.7990\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.7193 - mae: 1.3700 - val_loss: 157.7074 - val_mae: 2.9164\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.4135 - mae: 1.2365 - val_loss: 110.0371 - val_mae: 2.6281\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.8982 - mae: 1.2854 - val_loss: 140.4207 - val_mae: 2.9067\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.8444 - mae: 1.2589 - val_loss: 124.6758 - val_mae: 2.7864\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 31.6900 - mae: 1.3623 - val_loss: 123.9414 - val_mae: 2.6339\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.6236 - mae: 1.2005 - val_loss: 127.9006 - val_mae: 2.7424\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 17.1733 - mae: 1.2373 - val_loss: 116.1650 - val_mae: 2.5897\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 25.6341 - mae: 1.2557 - val_loss: 155.1515 - val_mae: 3.0271\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 19.4414 - mae: 1.2946 - val_loss: 129.1129 - val_mae: 2.6244\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 19.9765 - mae: 1.3433 - val_loss: 112.5694 - val_mae: 2.4380\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 24.9400 - mae: 1.3967 - val_loss: 123.5167 - val_mae: 2.6399\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.1959 - mae: 1.1887 - val_loss: 146.7716 - val_mae: 2.9220\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.2011 - mae: 1.3958 - val_loss: 154.1329 - val_mae: 2.8819\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.1500 - mae: 1.4221 - val_loss: 135.0482 - val_mae: 2.7869\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0326 - mae: 1.2229 - val_loss: 154.6241 - val_mae: 3.0023\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3039 - mae: 1.2867 - val_loss: 145.0136 - val_mae: 2.8503\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.6272 - mae: 1.1884 - val_loss: 116.0578 - val_mae: 2.2871\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6359 - mae: 1.1992 - val_loss: 130.9465 - val_mae: 2.6066\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.0812 - mae: 1.2421 - val_loss: 178.9444 - val_mae: 3.1947\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.6808 - mae: 1.4124 - val_loss: 153.8251 - val_mae: 2.9449\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.0989 - mae: 1.2069 - val_loss: 126.0238 - val_mae: 2.5872\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3581 - mae: 1.2722 - val_loss: 131.4299 - val_mae: 2.5771\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.2692 - mae: 1.3171 - val_loss: 142.6047 - val_mae: 2.7825\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4383 - mae: 1.2197 - val_loss: 163.6636 - val_mae: 2.9733\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.2539 - mae: 1.2983 - val_loss: 137.0993 - val_mae: 2.7598\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.2825 - mae: 1.2422 - val_loss: 161.8795 - val_mae: 3.0266\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 13.8481 - mae: 1.1675 - val_loss: 145.0637 - val_mae: 2.8845\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 13.1083 - mae: 1.1589 - val_loss: 139.6296 - val_mae: 2.8502\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 8.9989 - mae: 1.0092 - val_loss: 137.5526 - val_mae: 2.8427\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.5918 - mae: 1.2883 - val_loss: 164.8481 - val_mae: 3.1420\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6561 - mae: 1.1343 - val_loss: 162.6496 - val_mae: 3.1065\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.3877 - mae: 1.2214 - val_loss: 159.9624 - val_mae: 3.0524\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.8610 - mae: 1.0912 - val_loss: 153.2026 - val_mae: 2.9556\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.3088 - mae: 1.2963 - val_loss: 168.1015 - val_mae: 3.0914\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2399 - mae: 1.1877 - val_loss: 149.8618 - val_mae: 2.7917\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.3921 - mae: 1.1755 - val_loss: 126.2023 - val_mae: 2.4286\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.0661 - mae: 1.3272 - val_loss: 132.2444 - val_mae: 2.5204\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 29.9585 - mae: 1.1958 - val_loss: 168.9118 - val_mae: 3.1026\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.3808 - mae: 1.1499 - val_loss: 135.1295 - val_mae: 2.6480\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.8599 - mae: 1.0442 - val_loss: 132.5545 - val_mae: 2.5153\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 13.1430 - mae: 1.0705 - val_loss: 135.8523 - val_mae: 2.6270\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.4820 - mae: 1.1940 - val_loss: 157.5939 - val_mae: 2.9332\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.2576 - mae: 1.1150 - val_loss: 129.4923 - val_mae: 2.6760\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.8848 - mae: 1.1771 - val_loss: 142.3652 - val_mae: 2.8336\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6772 - mae: 1.1008 - val_loss: 138.2790 - val_mae: 2.7076\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.4038 - mae: 1.1977 - val_loss: 120.5878 - val_mae: 2.4285\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.9408 - mae: 1.0785 - val_loss: 129.9095 - val_mae: 2.5322\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6977 - mae: 1.1317 - val_loss: 151.5006 - val_mae: 2.8220\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.7051 - mae: 1.3317 - val_loss: 141.5401 - val_mae: 2.8101\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.3653 - mae: 1.2227 - val_loss: 163.3934 - val_mae: 3.0403\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0434 - mae: 1.0672 - val_loss: 142.6820 - val_mae: 2.7011\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2938 - mae: 1.2144 - val_loss: 148.8675 - val_mae: 2.8374\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.6909 - mae: 1.0807 - val_loss: 163.7392 - val_mae: 2.9264\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.4963 - mae: 1.2806 - val_loss: 174.6198 - val_mae: 3.0218\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7982 - mae: 1.2016 - val_loss: 173.9841 - val_mae: 3.0646\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.5128 - mae: 1.0655 - val_loss: 138.3214 - val_mae: 2.6183\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.4514 - mae: 1.3579 - val_loss: 140.9144 - val_mae: 2.5373\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 13.2860 - mae: 1.0614 - val_loss: 147.7802 - val_mae: 2.5777\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6912 - mae: 1.1064 - val_loss: 159.1272 - val_mae: 2.7880\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.9060 - mae: 1.2844 - val_loss: 145.7667 - val_mae: 2.6350\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6007 - mae: 1.0534 - val_loss: 151.8746 - val_mae: 2.8257\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.0256 - mae: 1.0542 - val_loss: 150.5636 - val_mae: 2.7974\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.7304 - mae: 1.1323 - val_loss: 147.7117 - val_mae: 2.7439\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.4492 - mae: 1.0714 - val_loss: 169.4791 - val_mae: 2.9964\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.0735 - mae: 1.1419 - val_loss: 141.1354 - val_mae: 2.5779\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.5738 - mae: 1.1703 - val_loss: 147.1232 - val_mae: 2.6845\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.1622 - mae: 1.1134 - val_loss: 141.8998 - val_mae: 2.6329\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.5854 - mae: 1.1613 - val_loss: 163.8013 - val_mae: 2.9453\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.8387 - mae: 1.1793 - val_loss: 160.9094 - val_mae: 2.8131\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.3818 - mae: 1.3628 - val_loss: 144.7210 - val_mae: 2.5470\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.0036 - mae: 1.0410 - val_loss: 141.7701 - val_mae: 2.5959\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.7104 - mae: 0.9980 - val_loss: 141.3552 - val_mae: 2.5841\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9787 - mae: 1.1447 - val_loss: 174.2059 - val_mae: 3.0207\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 22.8241 - mae: 1.2276 - val_loss: 191.7150 - val_mae: 3.3327\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.3402 - mae: 1.1597 - val_loss: 136.3515 - val_mae: 2.5489\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 20.3715 - mae: 1.2796 - val_loss: 158.2901 - val_mae: 2.8890\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.0596 - mae: 1.1564 - val_loss: 134.4862 - val_mae: 2.4684\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.7774 - mae: 1.2536 - val_loss: 148.5244 - val_mae: 2.5978\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 13.9713 - mae: 1.0860 - val_loss: 144.5543 - val_mae: 2.5578\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0777 - mae: 1.1707 - val_loss: 160.6836 - val_mae: 2.8928\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0508 - mae: 1.1206 - val_loss: 148.5336 - val_mae: 2.6335\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.7493 - mae: 1.1320 - val_loss: 169.8422 - val_mae: 2.9860\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.4558 - mae: 1.0750 - val_loss: 161.8906 - val_mae: 2.8168\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.9347 - mae: 1.0948 - val_loss: 152.3426 - val_mae: 2.6545\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.0992 - mae: 0.9701 - val_loss: 150.9362 - val_mae: 2.6680\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.0799 - mae: 1.1293 - val_loss: 157.7122 - val_mae: 2.7009\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.7667 - mae: 1.0126 - val_loss: 152.5636 - val_mae: 2.6481\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.9988 - mae: 1.1119 - val_loss: 185.2836 - val_mae: 3.0892\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6834 - mae: 1.0997 - val_loss: 150.7814 - val_mae: 2.4867\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.7932 - mae: 1.0432 - val_loss: 147.5396 - val_mae: 2.5119\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 2ms/step - loss: 10.3057 - mae: 1.0068 - val_loss: 174.6617 - val_mae: 3.0136\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4296 - mae: 1.0189 - val_loss: 149.9446 - val_mae: 2.5796\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.8852 - mae: 1.0655 - val_loss: 150.1581 - val_mae: 2.6249\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.7292 - mae: 1.0478 - val_loss: 149.7529 - val_mae: 2.5514\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.7015 - mae: 1.0859 - val_loss: 147.9910 - val_mae: 2.5989\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.2032 - mae: 1.0731 - val_loss: 152.4289 - val_mae: 2.6014\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8362 - mae: 1.0228 - val_loss: 177.2165 - val_mae: 3.1099\n",
      ">3, MAE: 2.126\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 3s 4ms/step - loss: 3183.0620 - mae: 6.5968 - val_loss: 202.2784 - val_mae: 3.6864\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 357.1951 - mae: 3.9298 - val_loss: 153.9853 - val_mae: 3.0917\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 157.9778 - mae: 3.3318 - val_loss: 130.7434 - val_mae: 2.8838\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 205.7285 - mae: 3.1255 - val_loss: 412.0552 - val_mae: 5.4385\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 196.7128 - mae: 3.0682 - val_loss: 276.3137 - val_mae: 4.4419\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 134.1785 - mae: 2.9061 - val_loss: 173.7305 - val_mae: 3.4559\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 130.0570 - mae: 2.8099 - val_loss: 210.4354 - val_mae: 3.7172\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 78.0800 - mae: 2.3800 - val_loss: 204.9364 - val_mae: 3.5695\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 70.1298 - mae: 2.3134 - val_loss: 270.4884 - val_mae: 3.8859\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 107.1496 - mae: 2.4186 - val_loss: 588.6940 - val_mae: 5.4544\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.5828 - mae: 2.1734 - val_loss: 330.7458 - val_mae: 3.9152\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 74.4705 - mae: 2.2050 - val_loss: 355.8187 - val_mae: 4.0287\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 57.6526 - mae: 2.1641 - val_loss: 196.2444 - val_mae: 3.2424\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.3190 - mae: 1.9663 - val_loss: 334.6859 - val_mae: 3.9674\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 67.2867 - mae: 2.2793 - val_loss: 330.8693 - val_mae: 3.9807\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 72.1371 - mae: 2.2469 - val_loss: 312.1755 - val_mae: 3.7070\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 54.4710 - mae: 2.0698 - val_loss: 385.7121 - val_mae: 4.0882\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 96.9409 - mae: 2.3412 - val_loss: 423.0692 - val_mae: 4.2361\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 64.7143 - mae: 2.1113 - val_loss: 495.8278 - val_mae: 4.6652\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.7354 - mae: 2.1045 - val_loss: 501.5874 - val_mae: 4.6160\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.7281 - mae: 1.7794 - val_loss: 333.2470 - val_mae: 3.8539\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.6185 - mae: 1.8583 - val_loss: 340.2736 - val_mae: 3.9278\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.7800 - mae: 2.0861 - val_loss: 370.7209 - val_mae: 4.1044\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.0152 - mae: 1.9764 - val_loss: 299.6780 - val_mae: 3.7496\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.0517 - mae: 1.6842 - val_loss: 322.6413 - val_mae: 3.9409\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 40.1804 - mae: 1.9423 - val_loss: 300.6560 - val_mae: 3.8335\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 55.1396 - mae: 1.9950 - val_loss: 278.8820 - val_mae: 3.6855\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 39.9323 - mae: 1.9805 - val_loss: 329.3788 - val_mae: 3.9795\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 67.2161 - mae: 1.9857 - val_loss: 325.4000 - val_mae: 3.9255\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 44.0459 - mae: 1.8135 - val_loss: 378.1951 - val_mae: 4.2148\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 68.7702 - mae: 2.1087 - val_loss: 356.4815 - val_mae: 4.0701\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.2183 - mae: 1.8911 - val_loss: 417.9364 - val_mae: 4.3948\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.8661 - mae: 1.9999 - val_loss: 268.1848 - val_mae: 3.7984\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.5604 - mae: 1.7296 - val_loss: 228.1903 - val_mae: 3.4385\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.0488 - mae: 1.8916 - val_loss: 321.2359 - val_mae: 3.9503\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.2356 - mae: 1.7253 - val_loss: 385.5346 - val_mae: 4.2629\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.2371 - mae: 1.7984 - val_loss: 323.3823 - val_mae: 3.9119\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.5620 - mae: 1.7989 - val_loss: 264.5341 - val_mae: 3.5935\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.7131 - mae: 1.9175 - val_loss: 310.5591 - val_mae: 3.9453\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.9590 - mae: 1.7940 - val_loss: 317.8569 - val_mae: 4.0062\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 57.8773 - mae: 1.9217 - val_loss: 281.6465 - val_mae: 3.8507\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 52.6106 - mae: 1.8952 - val_loss: 424.4990 - val_mae: 4.6001\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3575 - mae: 1.6030 - val_loss: 289.3280 - val_mae: 3.9324\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.9772 - mae: 1.6640 - val_loss: 335.0807 - val_mae: 4.1421\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.8048 - mae: 1.6797 - val_loss: 305.1735 - val_mae: 3.9053\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.4429 - mae: 1.6973 - val_loss: 334.4854 - val_mae: 4.0820\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.2549 - mae: 1.6922 - val_loss: 353.4219 - val_mae: 4.1926\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.5517 - mae: 1.7128 - val_loss: 376.3095 - val_mae: 4.3468\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 51.2356 - mae: 1.8524 - val_loss: 347.5610 - val_mae: 4.1633\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0194 - mae: 1.5131 - val_loss: 285.9900 - val_mae: 3.8166\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.0542 - mae: 1.9188 - val_loss: 249.9126 - val_mae: 3.7684\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.8585 - mae: 1.6695 - val_loss: 336.5005 - val_mae: 4.2336\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.8240 - mae: 1.7564 - val_loss: 329.3377 - val_mae: 4.1897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.2992 - mae: 1.7055 - val_loss: 235.6807 - val_mae: 3.6620\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 31.2949 - mae: 1.6913 - val_loss: 360.9947 - val_mae: 4.3464\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.4077 - mae: 1.6984 - val_loss: 407.3047 - val_mae: 4.4774\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.9438 - mae: 1.6174 - val_loss: 307.2726 - val_mae: 4.0096\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.5373 - mae: 1.6188 - val_loss: 224.9470 - val_mae: 3.5158\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.8136 - mae: 1.6536 - val_loss: 255.3037 - val_mae: 3.7110\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.8543 - mae: 1.7079 - val_loss: 268.3788 - val_mae: 3.7718\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.3121 - mae: 1.5253 - val_loss: 248.0563 - val_mae: 3.6431\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.4375 - mae: 1.7408 - val_loss: 298.6674 - val_mae: 3.8563\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.7088 - mae: 1.4613 - val_loss: 309.0583 - val_mae: 3.9003\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.1779 - mae: 1.4728 - val_loss: 342.7730 - val_mae: 4.0840\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.0985 - mae: 1.7708 - val_loss: 232.7185 - val_mae: 3.5353\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.7915 - mae: 1.5048 - val_loss: 272.5915 - val_mae: 3.7520\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.3907 - mae: 1.5606 - val_loss: 206.6512 - val_mae: 3.3976\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.1374 - mae: 1.6562 - val_loss: 309.6264 - val_mae: 3.9509\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.4368 - mae: 1.6445 - val_loss: 287.0396 - val_mae: 3.8469\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6248 - mae: 1.4634 - val_loss: 270.7452 - val_mae: 3.7414\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.1561 - mae: 1.7129 - val_loss: 342.2542 - val_mae: 4.1725\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.2594 - mae: 1.5239 - val_loss: 299.2201 - val_mae: 3.9425\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.6111 - mae: 1.7428 - val_loss: 376.2977 - val_mae: 4.3721\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.9122 - mae: 1.6711 - val_loss: 334.6822 - val_mae: 4.1299\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.0555 - mae: 1.5088 - val_loss: 284.1814 - val_mae: 3.8589\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.1106 - mae: 1.7607 - val_loss: 374.1486 - val_mae: 4.2838\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.4541 - mae: 1.5572 - val_loss: 271.9742 - val_mae: 3.8032\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.7767 - mae: 1.6420 - val_loss: 311.8565 - val_mae: 4.0136\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.5285 - mae: 1.6677 - val_loss: 242.3879 - val_mae: 3.6243\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.7229 - mae: 1.6233 - val_loss: 297.7723 - val_mae: 3.9621\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.1062 - mae: 1.4871 - val_loss: 295.1661 - val_mae: 3.9003\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.7441 - mae: 1.7971 - val_loss: 289.7721 - val_mae: 3.9509\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5281 - mae: 1.4993 - val_loss: 296.2133 - val_mae: 3.9602\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.8870 - mae: 1.6436 - val_loss: 212.3252 - val_mae: 3.4150\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.2849 - mae: 1.6459 - val_loss: 352.0885 - val_mae: 4.1607\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.8805 - mae: 1.5082 - val_loss: 370.9812 - val_mae: 4.1975\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.1990 - mae: 1.5304 - val_loss: 327.4445 - val_mae: 4.0045\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.7990 - mae: 1.5647 - val_loss: 261.2758 - val_mae: 3.6869\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.1805 - mae: 1.5704 - val_loss: 252.4804 - val_mae: 3.6614\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.6956 - mae: 1.5211 - val_loss: 220.3765 - val_mae: 3.4485\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.0439 - mae: 1.3882 - val_loss: 272.4895 - val_mae: 3.7925\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8214 - mae: 1.6216 - val_loss: 241.9103 - val_mae: 3.5903\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.0891 - mae: 1.6293 - val_loss: 338.3087 - val_mae: 4.1247\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.9824 - mae: 1.5752 - val_loss: 246.1171 - val_mae: 3.5746\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.8505 - mae: 1.4734 - val_loss: 295.7804 - val_mae: 3.8437\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.8291 - mae: 1.5495 - val_loss: 285.2237 - val_mae: 3.8424\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5932 - mae: 1.3901 - val_loss: 332.3933 - val_mae: 4.0715\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.6860 - mae: 1.5403 - val_loss: 287.9953 - val_mae: 3.8541\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.4291 - mae: 1.5335 - val_loss: 257.8962 - val_mae: 3.6633\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.4494 - mae: 1.4247 - val_loss: 261.2751 - val_mae: 3.6961\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.2441 - mae: 1.4281 - val_loss: 243.3211 - val_mae: 3.5664\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9794 - mae: 1.2810 - val_loss: 267.8109 - val_mae: 3.7131\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.6700 - mae: 1.5642 - val_loss: 253.4881 - val_mae: 3.6356\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.4100 - mae: 1.6376 - val_loss: 187.6791 - val_mae: 3.2259\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.4265 - mae: 1.2257 - val_loss: 228.1043 - val_mae: 3.4627\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.5931 - mae: 1.4366 - val_loss: 239.1385 - val_mae: 3.5539\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4890 - mae: 1.2528 - val_loss: 231.7880 - val_mae: 3.5062\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.0202 - mae: 1.5060 - val_loss: 300.6793 - val_mae: 3.8891\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.7359 - mae: 1.5342 - val_loss: 260.6414 - val_mae: 3.6794\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.8101 - mae: 1.5144 - val_loss: 232.7349 - val_mae: 3.5321\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.6230 - mae: 1.5033 - val_loss: 251.2025 - val_mae: 3.6215\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.9726 - mae: 1.2325 - val_loss: 201.8520 - val_mae: 3.3014\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.9644 - mae: 1.5040 - val_loss: 238.7625 - val_mae: 3.5660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 37.7598 - mae: 1.6124 - val_loss: 257.4448 - val_mae: 3.6607\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.7198 - mae: 1.4617 - val_loss: 253.3282 - val_mae: 3.6513\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 19.4106 - mae: 1.3856 - val_loss: 225.6421 - val_mae: 3.4598\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.7677 - mae: 1.4227 - val_loss: 246.5674 - val_mae: 3.6061\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 29.7978 - mae: 1.4187 - val_loss: 274.6278 - val_mae: 3.7059\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.2693 - mae: 1.3375 - val_loss: 226.7720 - val_mae: 3.4634\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.5523 - mae: 1.4517 - val_loss: 351.5822 - val_mae: 4.1339\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.9180 - mae: 1.3692 - val_loss: 278.6611 - val_mae: 3.7313\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.8232 - mae: 1.3666 - val_loss: 196.7387 - val_mae: 3.2678\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 39.2571 - mae: 1.6517 - val_loss: 271.7822 - val_mae: 3.6591\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 27.5134 - mae: 1.5432 - val_loss: 258.8205 - val_mae: 3.6001\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6421 - mae: 1.4348 - val_loss: 285.6464 - val_mae: 3.7326\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.0594 - mae: 1.4170 - val_loss: 294.1490 - val_mae: 3.8203\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.9560 - mae: 1.3296 - val_loss: 246.5783 - val_mae: 3.5501\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.3452 - mae: 1.4713 - val_loss: 271.1706 - val_mae: 3.7041\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.3106 - mae: 1.3965 - val_loss: 283.8537 - val_mae: 3.7529\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8176 - mae: 1.3667 - val_loss: 234.8402 - val_mae: 3.5094\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.6331 - mae: 1.5698 - val_loss: 288.2281 - val_mae: 3.8272\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.0435 - mae: 1.4878 - val_loss: 309.3050 - val_mae: 3.9283\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.5374 - mae: 1.3998 - val_loss: 241.9336 - val_mae: 3.5673\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8196 - mae: 1.2969 - val_loss: 289.4250 - val_mae: 3.8423\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.7062 - mae: 1.3257 - val_loss: 225.7259 - val_mae: 3.4493\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.7914 - mae: 1.5202 - val_loss: 305.3983 - val_mae: 3.9096\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.2018 - mae: 1.3970 - val_loss: 218.2481 - val_mae: 3.3940\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.1494 - mae: 1.4024 - val_loss: 249.5403 - val_mae: 3.5765\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.5785 - mae: 1.3030 - val_loss: 267.8812 - val_mae: 3.6918\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5066 - mae: 1.2698 - val_loss: 257.7618 - val_mae: 3.6556\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9238 - mae: 1.2974 - val_loss: 247.4120 - val_mae: 3.5937\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.5246 - mae: 1.0934 - val_loss: 265.2942 - val_mae: 3.7221\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8320 - mae: 1.2521 - val_loss: 272.4536 - val_mae: 3.7511\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0025 - mae: 1.3061 - val_loss: 282.9564 - val_mae: 3.8288\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.0014 - mae: 1.5312 - val_loss: 309.9555 - val_mae: 3.9214\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3993 - mae: 1.4770 - val_loss: 273.1046 - val_mae: 3.7762\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3661 - mae: 1.3552 - val_loss: 322.4724 - val_mae: 4.0555\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6933 - mae: 1.2348 - val_loss: 296.9995 - val_mae: 3.8553\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.8284 - mae: 1.3435 - val_loss: 316.6144 - val_mae: 3.9618\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0342 - mae: 1.4367 - val_loss: 317.1238 - val_mae: 3.9571\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.7298 - mae: 1.4360 - val_loss: 225.8968 - val_mae: 3.4554\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.0010 - mae: 1.3315 - val_loss: 201.5495 - val_mae: 3.3637\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.9208 - mae: 1.4353 - val_loss: 266.9563 - val_mae: 3.7396\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.5437 - mae: 1.3303 - val_loss: 301.0133 - val_mae: 3.9130\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8232 - mae: 1.2383 - val_loss: 268.4424 - val_mae: 3.7280\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.8040 - mae: 1.3118 - val_loss: 218.0605 - val_mae: 3.4074\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.7582 - mae: 1.3962 - val_loss: 227.5933 - val_mae: 3.4698\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.5660 - mae: 1.1300 - val_loss: 261.5924 - val_mae: 3.6915\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.1730 - mae: 1.3743 - val_loss: 274.7162 - val_mae: 3.7470\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 17.6356 - mae: 1.3010 - val_loss: 266.8818 - val_mae: 3.7633\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.2765 - mae: 1.2439 - val_loss: 272.5772 - val_mae: 3.7327\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.1404 - mae: 1.5233 - val_loss: 220.0491 - val_mae: 3.4269\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 37.5044 - mae: 1.4600 - val_loss: 278.6349 - val_mae: 3.8071\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.1656 - mae: 1.2523 - val_loss: 298.0309 - val_mae: 3.8804\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 20.4166 - mae: 1.3452 - val_loss: 217.7993 - val_mae: 3.3932\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.9179 - mae: 1.1941 - val_loss: 229.5562 - val_mae: 3.4772\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9583 - mae: 1.3483 - val_loss: 231.6832 - val_mae: 3.4687\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.4070 - mae: 1.2937 - val_loss: 282.2879 - val_mae: 3.7512\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.3628 - mae: 1.2010 - val_loss: 230.0662 - val_mae: 3.4240\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.5095 - mae: 1.3137 - val_loss: 245.7634 - val_mae: 3.5257\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.9395 - mae: 1.3144 - val_loss: 235.0808 - val_mae: 3.5129\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.2465 - mae: 1.2760 - val_loss: 198.7702 - val_mae: 3.2799\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.8880 - mae: 1.4260 - val_loss: 230.3429 - val_mae: 3.4692\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.5035 - mae: 1.2042 - val_loss: 250.7927 - val_mae: 3.5382\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.1357 - mae: 1.2661 - val_loss: 273.0677 - val_mae: 3.6743\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.8240 - mae: 1.3521 - val_loss: 213.1700 - val_mae: 3.3471\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.7473 - mae: 1.2013 - val_loss: 244.8114 - val_mae: 3.5447\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0856 - mae: 1.0951 - val_loss: 255.9695 - val_mae: 3.6112\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.9209 - mae: 1.3986 - val_loss: 278.9807 - val_mae: 3.7349\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8365 - mae: 1.1971 - val_loss: 233.6083 - val_mae: 3.4721\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.8155 - mae: 1.4647 - val_loss: 206.2159 - val_mae: 3.2633\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.7714 - mae: 1.3922 - val_loss: 284.6665 - val_mae: 3.8270\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.6949 - mae: 1.2490 - val_loss: 195.3638 - val_mae: 3.1955\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4536 - mae: 1.4618 - val_loss: 237.6339 - val_mae: 3.4730\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7611 - mae: 1.4155 - val_loss: 211.1574 - val_mae: 3.3446\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.3903 - mae: 1.2388 - val_loss: 219.1175 - val_mae: 3.4573\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.2865 - mae: 1.3296 - val_loss: 237.6232 - val_mae: 3.5147\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7711 - mae: 1.4257 - val_loss: 285.1243 - val_mae: 3.8189\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.4250 - mae: 1.3040 - val_loss: 197.3505 - val_mae: 3.2763\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.1768 - mae: 1.1885 - val_loss: 226.4900 - val_mae: 3.4195\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9473 - mae: 1.2305 - val_loss: 236.9382 - val_mae: 3.5398\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4083 - mae: 1.3616 - val_loss: 236.0425 - val_mae: 3.4553\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.5576 - mae: 1.5043 - val_loss: 194.6761 - val_mae: 3.1559\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.0395 - mae: 1.2519 - val_loss: 209.5261 - val_mae: 3.2783\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.8855 - mae: 1.1766 - val_loss: 259.3080 - val_mae: 3.6064\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.9808 - mae: 1.1557 - val_loss: 221.7414 - val_mae: 3.3224\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6148 - mae: 1.1748 - val_loss: 221.8777 - val_mae: 3.3481\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0121 - mae: 1.1060 - val_loss: 230.8058 - val_mae: 3.4236\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.0115 - mae: 1.3045 - val_loss: 232.8640 - val_mae: 3.4444\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.2273 - mae: 1.3270 - val_loss: 168.7053 - val_mae: 2.9437\n",
      ">4, MAE: 2.145\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 915.6861 - mae: 6.2490 - val_loss: 532.0915 - val_mae: 5.8724\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 510.5499 - mae: 3.7866 - val_loss: 111.3268 - val_mae: 2.4512\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 132.8200 - mae: 2.7130 - val_loss: 774.8466 - val_mae: 6.8315\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 281.2994 - mae: 3.0965 - val_loss: 271.2485 - val_mae: 4.2193\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 124.8791 - mae: 2.6623 - val_loss: 187.8585 - val_mae: 3.5090\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 187.6100 - mae: 2.9582 - val_loss: 185.0164 - val_mae: 3.1961\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 162.7838 - mae: 2.7314 - val_loss: 220.5192 - val_mae: 3.2744\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 75.4131 - mae: 2.3311 - val_loss: 317.0839 - val_mae: 3.8529\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 60.1610 - mae: 2.1741 - val_loss: 238.5219 - val_mae: 3.3060\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 111.4744 - mae: 2.3408 - val_loss: 281.8983 - val_mae: 3.5058\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 60.4367 - mae: 2.0766 - val_loss: 252.5850 - val_mae: 3.4777\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.8866 - mae: 2.0628 - val_loss: 312.6093 - val_mae: 3.7129\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 60.9441 - mae: 2.2224 - val_loss: 496.3432 - val_mae: 4.4981\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.5810 - mae: 2.0492 - val_loss: 278.5622 - val_mae: 3.5201\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 48.8178 - mae: 2.0089 - val_loss: 478.4219 - val_mae: 4.3407\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.3323 - mae: 2.0061 - val_loss: 643.8098 - val_mae: 4.8356\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 61.0955 - mae: 2.1444 - val_loss: 486.4098 - val_mae: 4.2517\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.1699 - mae: 1.7980 - val_loss: 350.5818 - val_mae: 3.7474\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.4685 - mae: 1.8766 - val_loss: 538.7144 - val_mae: 4.5297\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 75.4133 - mae: 2.1478 - val_loss: 531.4010 - val_mae: 4.4081\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6143 - mae: 1.7966 - val_loss: 376.9873 - val_mae: 3.8744\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 48.7271 - mae: 1.9944 - val_loss: 393.3192 - val_mae: 3.9575\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.1228 - mae: 1.9845 - val_loss: 536.1909 - val_mae: 4.5230\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 79.8265 - mae: 2.1153 - val_loss: 547.6052 - val_mae: 4.5666\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.8541 - mae: 1.9750 - val_loss: 374.7235 - val_mae: 3.9297\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.8866 - mae: 1.7527 - val_loss: 393.9021 - val_mae: 3.9892\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.5246 - mae: 1.6598 - val_loss: 339.2831 - val_mae: 3.7899\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.8050 - mae: 1.9439 - val_loss: 264.5119 - val_mae: 3.3876\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 58.7147 - mae: 1.9559 - val_loss: 380.7919 - val_mae: 3.9246\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.4041 - mae: 1.8539 - val_loss: 275.3386 - val_mae: 3.5134\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.3021 - mae: 1.9431 - val_loss: 220.4429 - val_mae: 3.3628\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 2ms/step - loss: 51.9088 - mae: 1.8709 - val_loss: 474.5031 - val_mae: 4.2588\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.3203 - mae: 1.5208 - val_loss: 316.4279 - val_mae: 3.6323\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.4446 - mae: 1.5560 - val_loss: 372.4552 - val_mae: 3.9116\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.4702 - mae: 1.6261 - val_loss: 193.7813 - val_mae: 3.1486\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.6471 - mae: 1.7518 - val_loss: 310.6302 - val_mae: 3.6700\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.9323 - mae: 1.6589 - val_loss: 508.5302 - val_mae: 4.4998\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.2908 - mae: 1.7798 - val_loss: 270.0318 - val_mae: 3.5482\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.5092 - mae: 1.7576 - val_loss: 330.1645 - val_mae: 3.7853\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3277 - mae: 1.4670 - val_loss: 237.0227 - val_mae: 3.4225\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.5609 - mae: 1.5473 - val_loss: 381.5623 - val_mae: 3.9948\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.9000 - mae: 1.6082 - val_loss: 322.9026 - val_mae: 3.7274\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.8993 - mae: 1.5536 - val_loss: 213.2710 - val_mae: 3.1824\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.1858 - mae: 1.5911 - val_loss: 292.7971 - val_mae: 3.5730\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 57.5329 - mae: 1.8805 - val_loss: 539.8884 - val_mae: 4.5363\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.6437 - mae: 1.5896 - val_loss: 281.5556 - val_mae: 3.4798\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.9013 - mae: 1.7136 - val_loss: 322.3875 - val_mae: 3.6825\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.8587 - mae: 1.7113 - val_loss: 466.2695 - val_mae: 4.2533\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.1045 - mae: 1.6253 - val_loss: 370.9923 - val_mae: 3.8818\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.8640 - mae: 1.4720 - val_loss: 343.1836 - val_mae: 3.7727\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.5794 - mae: 1.6584 - val_loss: 225.9101 - val_mae: 3.3233\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7422 - mae: 1.6060 - val_loss: 238.4357 - val_mae: 3.3651\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.8381 - mae: 1.4450 - val_loss: 321.6129 - val_mae: 3.7075\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3187 - mae: 1.4346 - val_loss: 357.0124 - val_mae: 3.8679\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.3674 - mae: 1.6447 - val_loss: 223.3529 - val_mae: 3.2924\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.1001 - mae: 1.4641 - val_loss: 294.0677 - val_mae: 3.6080\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8548 - mae: 1.4915 - val_loss: 261.7732 - val_mae: 3.5548\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.2801 - mae: 1.4300 - val_loss: 296.7096 - val_mae: 3.6583\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.1441 - mae: 1.4678 - val_loss: 243.7187 - val_mae: 3.4718\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.6981 - mae: 1.4678 - val_loss: 420.8961 - val_mae: 4.1394\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.0978 - mae: 1.5253 - val_loss: 183.4247 - val_mae: 3.2128\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.3874 - mae: 1.5243 - val_loss: 265.8422 - val_mae: 3.5638\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.1594 - mae: 1.4706 - val_loss: 279.7577 - val_mae: 3.6034\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.3083 - mae: 1.5765 - val_loss: 272.2732 - val_mae: 3.5784\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.8872 - mae: 1.5901 - val_loss: 257.3253 - val_mae: 3.5577\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8744 - mae: 1.4342 - val_loss: 255.9849 - val_mae: 3.5018\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.1872 - mae: 1.6648 - val_loss: 238.9429 - val_mae: 3.4176\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.9540 - mae: 1.5668 - val_loss: 253.7457 - val_mae: 3.5128\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.3234 - mae: 1.3802 - val_loss: 274.8612 - val_mae: 3.5792\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.2102 - mae: 1.5860 - val_loss: 285.2387 - val_mae: 3.6891\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.8335 - mae: 1.5349 - val_loss: 322.5851 - val_mae: 3.8320\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.4540 - mae: 1.4453 - val_loss: 319.8781 - val_mae: 3.7961\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5802 - mae: 1.4346 - val_loss: 296.9682 - val_mae: 3.7012\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9972 - mae: 1.3275 - val_loss: 383.3172 - val_mae: 4.0243\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7425 - mae: 1.2850 - val_loss: 322.4581 - val_mae: 3.8652\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.9227 - mae: 1.4322 - val_loss: 369.4113 - val_mae: 3.9908\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.9642 - mae: 1.4251 - val_loss: 195.3356 - val_mae: 3.3356\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.9817 - mae: 1.4211 - val_loss: 215.8657 - val_mae: 3.3934\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.2766 - mae: 1.4623 - val_loss: 263.6756 - val_mae: 3.6188\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.9468 - mae: 1.6890 - val_loss: 221.7478 - val_mae: 3.4192\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.9324 - mae: 1.5251 - val_loss: 297.7606 - val_mae: 3.7070\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3648 - mae: 1.4353 - val_loss: 230.1041 - val_mae: 3.3937\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.0730 - mae: 1.4217 - val_loss: 228.8255 - val_mae: 3.4505\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.1377 - mae: 1.4979 - val_loss: 301.3015 - val_mae: 3.6696\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.2685 - mae: 1.4482 - val_loss: 193.0169 - val_mae: 3.1430\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.3021 - mae: 1.4653 - val_loss: 210.1505 - val_mae: 3.2848\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.1511 - mae: 1.5562 - val_loss: 248.5734 - val_mae: 3.4391\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.8746 - mae: 1.3838 - val_loss: 308.2067 - val_mae: 3.7160\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.0520 - mae: 1.3549 - val_loss: 222.4530 - val_mae: 3.3608\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.0136 - mae: 1.6033 - val_loss: 250.5533 - val_mae: 3.4242\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.4845 - mae: 1.3742 - val_loss: 288.8627 - val_mae: 3.5979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.5289 - mae: 1.4809 - val_loss: 196.7187 - val_mae: 3.2402\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.8766 - mae: 1.6026 - val_loss: 259.9516 - val_mae: 3.4739\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.9127 - mae: 1.5648 - val_loss: 111.7968 - val_mae: 2.6891\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.2175 - mae: 1.6224 - val_loss: 248.4921 - val_mae: 3.4797\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5080 - mae: 1.4183 - val_loss: 276.7568 - val_mae: 3.5021\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8271 - mae: 1.4656 - val_loss: 187.4908 - val_mae: 3.1891\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.2040 - mae: 1.3594 - val_loss: 189.8846 - val_mae: 3.2351\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.2631 - mae: 1.3122 - val_loss: 306.9323 - val_mae: 3.7084\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.0439 - mae: 1.4282 - val_loss: 254.4953 - val_mae: 3.4881\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.9454 - mae: 1.5142 - val_loss: 335.7342 - val_mae: 3.7707\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2360 - mae: 1.3256 - val_loss: 273.4042 - val_mae: 3.5484\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5660 - mae: 1.3042 - val_loss: 243.8500 - val_mae: 3.4267\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2547 - mae: 1.3280 - val_loss: 158.9066 - val_mae: 2.9991\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.0221 - mae: 1.4495 - val_loss: 308.3647 - val_mae: 3.6925\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6512 - mae: 1.3711 - val_loss: 292.0172 - val_mae: 3.6591\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.9203 - mae: 1.3449 - val_loss: 295.5706 - val_mae: 3.6885\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.5032 - mae: 1.5442 - val_loss: 368.4072 - val_mae: 4.0208\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.3808 - mae: 1.5383 - val_loss: 238.1378 - val_mae: 3.4410\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.3148 - mae: 1.3410 - val_loss: 207.2358 - val_mae: 3.2618\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0516 - mae: 1.2252 - val_loss: 185.3497 - val_mae: 3.1484\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.2097 - mae: 1.3769 - val_loss: 280.8571 - val_mae: 3.6032\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.8094 - mae: 1.4556 - val_loss: 127.9149 - val_mae: 2.7499\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 34.1690 - mae: 1.5459 - val_loss: 340.1655 - val_mae: 3.8911\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.2662 - mae: 1.3468 - val_loss: 215.8642 - val_mae: 3.3448\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0476 - mae: 1.2931 - val_loss: 203.0216 - val_mae: 3.2436\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.4330 - mae: 1.3354 - val_loss: 234.0654 - val_mae: 3.3963\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 913us/step - loss: 12.1589 - mae: 1.1368 - val_loss: 247.3277 - val_mae: 3.4882\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 903us/step - loss: 16.8879 - mae: 1.2915 - val_loss: 246.4671 - val_mae: 3.5161\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 912us/step - loss: 11.7857 - mae: 1.1688 - val_loss: 220.1092 - val_mae: 3.4053\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 891us/step - loss: 12.8362 - mae: 1.1749 - val_loss: 237.6400 - val_mae: 3.4256\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 917us/step - loss: 23.6373 - mae: 1.3179 - val_loss: 173.1501 - val_mae: 3.1113\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 904us/step - loss: 28.1519 - mae: 1.4054 - val_loss: 261.6082 - val_mae: 3.5619\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 907us/step - loss: 18.8728 - mae: 1.3666 - val_loss: 286.4695 - val_mae: 3.6569\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 904us/step - loss: 14.0833 - mae: 1.2839 - val_loss: 264.9653 - val_mae: 3.5220\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 908us/step - loss: 14.8071 - mae: 1.2410 - val_loss: 212.7700 - val_mae: 3.2494\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 914us/step - loss: 29.5412 - mae: 1.3966 - val_loss: 457.9693 - val_mae: 4.3866\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 918us/step - loss: 30.1603 - mae: 1.4933 - val_loss: 260.9247 - val_mae: 3.4916\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 917us/step - loss: 18.8887 - mae: 1.3033 - val_loss: 235.8979 - val_mae: 3.4600\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 928us/step - loss: 13.6851 - mae: 1.1608 - val_loss: 220.6966 - val_mae: 3.4155\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 931us/step - loss: 13.4960 - mae: 1.1663 - val_loss: 229.1615 - val_mae: 3.4677\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 922us/step - loss: 25.2808 - mae: 1.3884 - val_loss: 209.2308 - val_mae: 3.3390\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 911us/step - loss: 24.0503 - mae: 1.3679 - val_loss: 206.0909 - val_mae: 3.3160\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 917us/step - loss: 14.0124 - mae: 1.1420 - val_loss: 227.7533 - val_mae: 3.4364\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 928us/step - loss: 21.2048 - mae: 1.4003 - val_loss: 151.1799 - val_mae: 2.9774\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 921us/step - loss: 23.3045 - mae: 1.3900 - val_loss: 166.3394 - val_mae: 3.0743\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 913us/step - loss: 24.4234 - mae: 1.3963 - val_loss: 148.9512 - val_mae: 2.9677\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 914us/step - loss: 29.0174 - mae: 1.3880 - val_loss: 197.8730 - val_mae: 3.2547\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 917us/step - loss: 23.8731 - mae: 1.3351 - val_loss: 190.1781 - val_mae: 3.1933\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 905us/step - loss: 14.8813 - mae: 1.2464 - val_loss: 207.7191 - val_mae: 3.3359\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 899us/step - loss: 28.5995 - mae: 1.4148 - val_loss: 275.7178 - val_mae: 3.6996\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 915us/step - loss: 18.5310 - mae: 1.3267 - val_loss: 282.1364 - val_mae: 3.7408\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 909us/step - loss: 15.0176 - mae: 1.2476 - val_loss: 169.3609 - val_mae: 3.1247\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 925us/step - loss: 15.8174 - mae: 1.2630 - val_loss: 190.0799 - val_mae: 3.2857\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 925us/step - loss: 17.8824 - mae: 1.3294 - val_loss: 183.0826 - val_mae: 3.1644\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 908us/step - loss: 20.2888 - mae: 1.2571 - val_loss: 132.2744 - val_mae: 2.7560\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 896us/step - loss: 14.5710 - mae: 1.2193 - val_loss: 154.2609 - val_mae: 2.9569\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 918us/step - loss: 20.3436 - mae: 1.3302 - val_loss: 244.6648 - val_mae: 3.5150\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 902us/step - loss: 18.4844 - mae: 1.2965 - val_loss: 154.9983 - val_mae: 2.9896\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 910us/step - loss: 15.3762 - mae: 1.2131 - val_loss: 145.2099 - val_mae: 2.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 911us/step - loss: 19.0404 - mae: 1.2960 - val_loss: 182.6471 - val_mae: 3.1892\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 910us/step - loss: 14.4452 - mae: 1.1703 - val_loss: 174.4027 - val_mae: 3.1008\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 912us/step - loss: 13.8564 - mae: 1.2067 - val_loss: 237.0160 - val_mae: 3.4344\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 925us/step - loss: 14.5484 - mae: 1.2597 - val_loss: 190.6979 - val_mae: 3.2150\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 920us/step - loss: 15.1781 - mae: 1.2082 - val_loss: 222.7197 - val_mae: 3.4238\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 903us/step - loss: 12.2049 - mae: 1.1239 - val_loss: 189.3143 - val_mae: 3.2457\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 15.8361 - mae: 1.24 - 1s 905us/step - loss: 16.4662 - mae: 1.2576 - val_loss: 199.4301 - val_mae: 3.3163\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 925us/step - loss: 25.7636 - mae: 1.4613 - val_loss: 188.5354 - val_mae: 3.1479\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 903us/step - loss: 14.3240 - mae: 1.1945 - val_loss: 197.2419 - val_mae: 3.2965\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 921us/step - loss: 15.8332 - mae: 1.1902 - val_loss: 158.1359 - val_mae: 3.0334\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 909us/step - loss: 20.1647 - mae: 1.3197 - val_loss: 300.9044 - val_mae: 3.7982\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 900us/step - loss: 27.5503 - mae: 1.3697 - val_loss: 153.7736 - val_mae: 2.9710\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 913us/step - loss: 14.3742 - mae: 1.1874 - val_loss: 167.3264 - val_mae: 3.0813\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 929us/step - loss: 26.0641 - mae: 1.4078 - val_loss: 210.7579 - val_mae: 3.3234\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 918us/step - loss: 22.9217 - mae: 1.2866 - val_loss: 149.6034 - val_mae: 2.9301\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 908us/step - loss: 22.9235 - mae: 1.3743 - val_loss: 240.8550 - val_mae: 3.4574\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 908us/step - loss: 13.6233 - mae: 1.2084 - val_loss: 167.8077 - val_mae: 3.0678\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 916us/step - loss: 17.3452 - mae: 1.2739 - val_loss: 201.6661 - val_mae: 3.3490\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 911us/step - loss: 12.3779 - mae: 1.1535 - val_loss: 152.0170 - val_mae: 2.9847\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 901us/step - loss: 11.3084 - mae: 1.1176 - val_loss: 180.9156 - val_mae: 3.1665\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 915us/step - loss: 15.3015 - mae: 1.2013 - val_loss: 214.2654 - val_mae: 3.3692\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 985us/step - loss: 9.6380 - mae: 1.1159 - val_loss: 166.4606 - val_mae: 3.0513\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3452 - mae: 1.2592 - val_loss: 128.4165 - val_mae: 2.7356\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5610 - mae: 1.3327 - val_loss: 221.5092 - val_mae: 3.4211\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0672 - mae: 1.1976 - val_loss: 199.6484 - val_mae: 3.2542\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2018 - mae: 1.1515 - val_loss: 205.0897 - val_mae: 3.3084\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8693 - mae: 1.1773 - val_loss: 165.5260 - val_mae: 3.0601\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5922 - mae: 1.1046 - val_loss: 159.8044 - val_mae: 3.0123\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9939 - mae: 1.1220 - val_loss: 200.6182 - val_mae: 3.2543\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2528 - mae: 1.1628 - val_loss: 148.7364 - val_mae: 2.8601\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0938 - mae: 1.1864 - val_loss: 151.5309 - val_mae: 2.9047\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2570 - mae: 1.2112 - val_loss: 182.5192 - val_mae: 3.1316\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6502 - mae: 1.0844 - val_loss: 137.2683 - val_mae: 2.7866\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7800 - mae: 1.2295 - val_loss: 201.0560 - val_mae: 3.2392\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4700 - mae: 1.2283 - val_loss: 146.5917 - val_mae: 2.8064\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0236 - mae: 1.1019 - val_loss: 156.6840 - val_mae: 2.8952\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3713 - mae: 1.2103 - val_loss: 203.9407 - val_mae: 3.3041\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8493 - mae: 1.1293 - val_loss: 151.9226 - val_mae: 2.8637\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0340 - mae: 1.1826 - val_loss: 162.6131 - val_mae: 2.9479\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3213 - mae: 1.1237 - val_loss: 183.0389 - val_mae: 3.1408\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.2788 - mae: 1.0593 - val_loss: 148.0011 - val_mae: 2.8786\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5289 - mae: 1.1801 - val_loss: 204.4029 - val_mae: 3.3262\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 12.5059 - mae: 1.08 - 1s 1ms/step - loss: 12.2605 - mae: 1.0893 - val_loss: 183.5203 - val_mae: 3.1766\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2795 - mae: 1.2409 - val_loss: 177.9697 - val_mae: 3.1334\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1633 - mae: 1.1920 - val_loss: 159.1964 - val_mae: 2.9792\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8005 - mae: 1.1552 - val_loss: 197.2241 - val_mae: 3.2823\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7734 - mae: 1.1454 - val_loss: 191.0486 - val_mae: 3.2360\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6538 - mae: 1.1202 - val_loss: 130.9581 - val_mae: 2.6144\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4589 - mae: 1.3973 - val_loss: 177.5670 - val_mae: 3.0848\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.7532 - mae: 1.3734 - val_loss: 185.7352 - val_mae: 3.1780\n",
      ">5, MAE: 2.036\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 411.6002 - mae: 4.5360 - val_loss: 157.1218 - val_mae: 3.3913\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 139.2207 - mae: 3.1115 - val_loss: 402.5676 - val_mae: 5.3895\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 216.9960 - mae: 3.2089 - val_loss: 129.1149 - val_mae: 3.2859\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 993us/step - loss: 166.4245 - mae: 3.0461 - val_loss: 115.6247 - val_mae: 3.0160\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 147.4365 - mae: 2.9588 - val_loss: 166.5995 - val_mae: 3.3399\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 146.7375 - mae: 2.7043 - val_loss: 376.2764 - val_mae: 4.4911\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 100.7587 - mae: 2.5521 - val_loss: 166.6759 - val_mae: 3.1488\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 83.5191 - mae: 2.4459 - val_loss: 282.9491 - val_mae: 3.7642\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.9452 - mae: 2.2496 - val_loss: 391.8422 - val_mae: 4.1255\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.6749 - mae: 2.1630 - val_loss: 227.7360 - val_mae: 3.3529\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.8394 - mae: 2.2146 - val_loss: 261.9207 - val_mae: 3.6159\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 66.0129 - mae: 2.1382 - val_loss: 329.2628 - val_mae: 3.8986\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.3645 - mae: 1.8638 - val_loss: 383.3560 - val_mae: 4.1087\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.2530 - mae: 1.9387 - val_loss: 468.1102 - val_mae: 4.3777\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 75.4986 - mae: 2.0373 - val_loss: 296.1531 - val_mae: 3.4788\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.3080 - mae: 2.1642 - val_loss: 442.6093 - val_mae: 4.0664\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.0546 - mae: 1.9554 - val_loss: 543.6406 - val_mae: 4.5596\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 59.9826 - mae: 2.0833 - val_loss: 384.7328 - val_mae: 3.9899\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.5996 - mae: 2.0139 - val_loss: 385.5162 - val_mae: 3.9788\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.3371 - mae: 1.8497 - val_loss: 443.9451 - val_mae: 4.2006\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.3271 - mae: 1.6869 - val_loss: 363.2442 - val_mae: 3.8390\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.9475 - mae: 1.9818 - val_loss: 234.9731 - val_mae: 3.3326\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.2037 - mae: 1.8493 - val_loss: 425.7984 - val_mae: 4.2391\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.5545 - mae: 1.9842 - val_loss: 421.5906 - val_mae: 4.1031\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.1123 - mae: 1.6853 - val_loss: 417.5287 - val_mae: 4.0903\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.8164 - mae: 1.8923 - val_loss: 323.5617 - val_mae: 3.6589\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.0693 - mae: 1.7627 - val_loss: 273.3300 - val_mae: 3.5086\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.9377 - mae: 1.8696 - val_loss: 254.3708 - val_mae: 3.4575\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 995us/step - loss: 42.1224 - mae: 1.9145 - val_loss: 455.2326 - val_mae: 4.2925\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.2281 - mae: 1.7749 - val_loss: 400.5706 - val_mae: 4.0022\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.1287 - mae: 1.8306 - val_loss: 433.9611 - val_mae: 4.2002\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 75.5830 - mae: 2.1171 - val_loss: 216.3703 - val_mae: 3.2687\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.8249 - mae: 1.7435 - val_loss: 387.3709 - val_mae: 4.1101\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.9100 - mae: 1.8393 - val_loss: 496.9659 - val_mae: 4.4813\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.2498 - mae: 1.8152 - val_loss: 420.0689 - val_mae: 4.1890\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.7048 - mae: 1.7568 - val_loss: 369.7993 - val_mae: 4.0042\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.2443 - mae: 1.9093 - val_loss: 330.4701 - val_mae: 3.6880\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.5757 - mae: 1.6607 - val_loss: 322.1692 - val_mae: 3.6614\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.7245 - mae: 1.7739 - val_loss: 302.5521 - val_mae: 3.5268\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.1344 - mae: 1.6243 - val_loss: 410.5221 - val_mae: 3.9791\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.0408 - mae: 1.6558 - val_loss: 339.9582 - val_mae: 3.7691\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.8226 - mae: 1.6499 - val_loss: 265.8111 - val_mae: 3.4273\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6698 - mae: 1.6123 - val_loss: 332.9743 - val_mae: 3.7620\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.5027 - mae: 1.6980 - val_loss: 292.2992 - val_mae: 3.6199\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6127 - mae: 1.6318 - val_loss: 346.5000 - val_mae: 3.7761\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.7105 - mae: 1.6666 - val_loss: 222.1086 - val_mae: 3.2757\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.1259 - mae: 1.7363 - val_loss: 336.3608 - val_mae: 3.7596\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.6421 - mae: 1.7313 - val_loss: 405.3453 - val_mae: 3.9595\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8691 - mae: 1.3619 - val_loss: 372.8843 - val_mae: 3.8239\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3346 - mae: 1.3524 - val_loss: 434.2498 - val_mae: 4.1117\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.3939 - mae: 1.7125 - val_loss: 323.1334 - val_mae: 3.7160\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3552 - mae: 1.4769 - val_loss: 310.4384 - val_mae: 3.6222\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1039 - mae: 1.5557 - val_loss: 281.6867 - val_mae: 3.5271\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5618 - mae: 1.5303 - val_loss: 298.8688 - val_mae: 3.6541\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2447 - mae: 1.5613 - val_loss: 303.1839 - val_mae: 3.6094\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.8824 - mae: 1.4920 - val_loss: 322.5603 - val_mae: 3.6796\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.8450 - mae: 1.6358 - val_loss: 307.8886 - val_mae: 3.6241\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 997us/step - loss: 29.2340 - mae: 1.6165 - val_loss: 329.0606 - val_mae: 3.6820\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 993us/step - loss: 24.1471 - mae: 1.4377 - val_loss: 219.3406 - val_mae: 3.2323\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.5110 - mae: 1.5905 - val_loss: 350.6436 - val_mae: 3.7975\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.8709 - mae: 1.6288 - val_loss: 355.3968 - val_mae: 3.8348\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.7993 - mae: 1.6135 - val_loss: 235.2143 - val_mae: 3.3062\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.9576 - mae: 1.7286 - val_loss: 336.0062 - val_mae: 3.8330\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2861 - mae: 1.3579 - val_loss: 247.4050 - val_mae: 3.4139\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.9802 - mae: 1.6151 - val_loss: 322.8790 - val_mae: 3.7918\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.3891 - mae: 1.4753 - val_loss: 253.4889 - val_mae: 3.3453\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 994us/step - loss: 32.4408 - mae: 1.6156 - val_loss: 404.0442 - val_mae: 4.0785\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.7699 - mae: 1.4895 - val_loss: 303.8582 - val_mae: 3.6313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.2969 - mae: 1.6398 - val_loss: 376.8699 - val_mae: 3.9665\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.8841 - mae: 1.6941 - val_loss: 249.9905 - val_mae: 3.3577\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 994us/step - loss: 41.3248 - mae: 1.7426 - val_loss: 260.0918 - val_mae: 3.3888\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.8743 - mae: 1.4899 - val_loss: 287.6089 - val_mae: 3.4741\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.5859 - mae: 1.5917 - val_loss: 290.4994 - val_mae: 3.5472\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5356 - mae: 1.3983 - val_loss: 385.2123 - val_mae: 4.0085\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1003 - mae: 1.4444 - val_loss: 347.7810 - val_mae: 3.8059\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.3531 - mae: 1.5888 - val_loss: 199.8507 - val_mae: 3.1539\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.0288 - mae: 1.4509 - val_loss: 365.5709 - val_mae: 3.9076\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 995us/step - loss: 43.3560 - mae: 1.5556 - val_loss: 184.4452 - val_mae: 3.1496\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 986us/step - loss: 31.4526 - mae: 1.4563 - val_loss: 208.2501 - val_mae: 3.2975\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.0061 - mae: 1.5434 - val_loss: 277.3208 - val_mae: 3.5303\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 990us/step - loss: 26.5026 - mae: 1.4904 - val_loss: 328.6145 - val_mae: 3.7414\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.0565 - mae: 1.3889 - val_loss: 244.9576 - val_mae: 3.4102\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4031 - mae: 1.3547 - val_loss: 241.3304 - val_mae: 3.4273\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.8046 - mae: 1.4508 - val_loss: 260.2784 - val_mae: 3.4465\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.2413 - mae: 1.4516 - val_loss: 206.9642 - val_mae: 3.2824\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.8064 - mae: 1.6486 - val_loss: 265.6538 - val_mae: 3.5991\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7667 - mae: 1.3208 - val_loss: 213.9067 - val_mae: 3.3464\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9393 - mae: 1.4005 - val_loss: 236.7587 - val_mae: 3.4416\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1720 - mae: 1.3079 - val_loss: 326.5583 - val_mae: 3.8152\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.2571 - mae: 1.4994 - val_loss: 344.4254 - val_mae: 3.8438\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 996us/step - loss: 57.2136 - mae: 1.7532 - val_loss: 201.2485 - val_mae: 3.2700\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3244 - mae: 1.4017 - val_loss: 244.8013 - val_mae: 3.4623\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4926 - mae: 1.3042 - val_loss: 236.3671 - val_mae: 3.4246\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.9077 - mae: 1.4440 - val_loss: 269.8544 - val_mae: 3.6537\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3239 - mae: 1.3516 - val_loss: 228.0669 - val_mae: 3.4343\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9093 - mae: 1.3783 - val_loss: 235.3689 - val_mae: 3.4472\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1103 - mae: 1.3543 - val_loss: 200.3285 - val_mae: 3.2578\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.7435 - mae: 1.4325 - val_loss: 254.3798 - val_mae: 3.5293\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.3724 - mae: 1.4906 - val_loss: 278.5399 - val_mae: 3.6632\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.3055 - mae: 1.5012 - val_loss: 324.5746 - val_mae: 3.8193\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2863 - mae: 1.3278 - val_loss: 231.8057 - val_mae: 3.4427\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.9936 - mae: 1.3490 - val_loss: 259.5654 - val_mae: 3.5805\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.1642 - mae: 1.4525 - val_loss: 244.6257 - val_mae: 3.4945\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4689 - mae: 1.1368 - val_loss: 251.1072 - val_mae: 3.5492\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 991us/step - loss: 18.1595 - mae: 1.3123 - val_loss: 264.0851 - val_mae: 3.5898\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 994us/step - loss: 12.9227 - mae: 1.1845 - val_loss: 234.1199 - val_mae: 3.4383\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 977us/step - loss: 20.4867 - mae: 1.3199 - val_loss: 187.7883 - val_mae: 3.1984\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 982us/step - loss: 27.7966 - mae: 1.4414 - val_loss: 261.3640 - val_mae: 3.5566\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 961us/step - loss: 19.3135 - mae: 1.2824 - val_loss: 200.0989 - val_mae: 3.3085\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3079 - mae: 1.2869 - val_loss: 197.4294 - val_mae: 3.2331\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6860 - mae: 1.2502 - val_loss: 208.5461 - val_mae: 3.3012\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.1249 - mae: 1.2632 - val_loss: 225.8569 - val_mae: 3.4230\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0579 - mae: 1.1614 - val_loss: 194.1944 - val_mae: 3.2169\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3620 - mae: 1.2594 - val_loss: 238.0197 - val_mae: 3.5101\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.5122 - mae: 1.5242 - val_loss: 219.6498 - val_mae: 3.3618\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7790 - mae: 1.2452 - val_loss: 272.3274 - val_mae: 3.6199\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9523 - mae: 1.3704 - val_loss: 195.4647 - val_mae: 3.2857\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7757 - mae: 1.3452 - val_loss: 230.7815 - val_mae: 3.4809\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5564 - mae: 1.2643 - val_loss: 203.7278 - val_mae: 3.3428\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7290 - mae: 1.2939 - val_loss: 151.1664 - val_mae: 2.9687\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.7823 - mae: 1.5817 - val_loss: 252.7968 - val_mae: 3.6041\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.5493 - mae: 1.0675 - val_loss: 234.7300 - val_mae: 3.5292\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2931 - mae: 1.1973 - val_loss: 190.8516 - val_mae: 3.2788\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9067 - mae: 1.2013 - val_loss: 217.2773 - val_mae: 3.4022\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 989us/step - loss: 12.7106 - mae: 1.2134 - val_loss: 199.4854 - val_mae: 3.2856\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3819 - mae: 1.3512 - val_loss: 228.1201 - val_mae: 3.4320\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.9518 - mae: 1.3002 - val_loss: 185.5959 - val_mae: 3.1825\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6642 - mae: 1.2394 - val_loss: 226.5432 - val_mae: 3.4202\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.6168 - mae: 1.3013 - val_loss: 200.0854 - val_mae: 3.3311\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2888 - mae: 1.1727 - val_loss: 222.2767 - val_mae: 3.4085\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7823 - mae: 1.3320 - val_loss: 167.7014 - val_mae: 3.0996\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4308 - mae: 1.2187 - val_loss: 164.5845 - val_mae: 3.0497\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0346 - mae: 1.2262 - val_loss: 160.0858 - val_mae: 3.0461\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3876 - mae: 1.2228 - val_loss: 197.2147 - val_mae: 3.2977\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.1379 - mae: 1.1205 - val_loss: 173.3558 - val_mae: 3.1299\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0277 - mae: 1.2958 - val_loss: 208.5000 - val_mae: 3.3366\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4581 - mae: 1.2727 - val_loss: 265.5027 - val_mae: 3.7000\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.8750 - mae: 1.4324 - val_loss: 231.1253 - val_mae: 3.4892\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7875 - mae: 1.2185 - val_loss: 189.7678 - val_mae: 3.2564\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.3970 - mae: 1.3225 - val_loss: 183.6347 - val_mae: 3.2233\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4878 - mae: 1.1681 - val_loss: 177.5825 - val_mae: 3.1633\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.1049 - mae: 1.3164 - val_loss: 211.4105 - val_mae: 3.3724\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.8578 - mae: 1.2720 - val_loss: 193.3564 - val_mae: 3.2398\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0128 - mae: 1.1469 - val_loss: 183.7288 - val_mae: 3.1758\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.9629 - mae: 1.3368 - val_loss: 219.0605 - val_mae: 3.4212\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.6257 - mae: 1.4070 - val_loss: 131.3162 - val_mae: 2.7989\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6538 - mae: 1.1577 - val_loss: 177.3829 - val_mae: 3.1507\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2429 - mae: 1.2920 - val_loss: 161.8552 - val_mae: 3.0886\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6680 - mae: 1.2406 - val_loss: 149.4028 - val_mae: 2.8892\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6348 - mae: 1.1492 - val_loss: 175.6685 - val_mae: 3.1694\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 10.5584 - mae: 1.09 - 1s 1ms/step - loss: 9.9241 - mae: 1.0657 - val_loss: 181.5227 - val_mae: 3.1898\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5088 - mae: 1.2767 - val_loss: 159.9538 - val_mae: 3.0637\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7727 - mae: 1.1852 - val_loss: 148.0312 - val_mae: 2.9634\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8250 - mae: 1.0797 - val_loss: 183.7531 - val_mae: 3.1739\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5082 - mae: 1.2606 - val_loss: 131.7021 - val_mae: 2.7648\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.4886 - mae: 1.0475 - val_loss: 146.2753 - val_mae: 2.8994\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1523 - mae: 1.3986 - val_loss: 180.4334 - val_mae: 3.1214\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5714 - mae: 1.1875 - val_loss: 200.9299 - val_mae: 3.2812\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2435 - mae: 1.2059 - val_loss: 161.5213 - val_mae: 3.0140\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.5902 - mae: 1.0402 - val_loss: 161.3990 - val_mae: 3.0564\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0597 - mae: 1.1170 - val_loss: 163.4392 - val_mae: 3.1600\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2292 - mae: 1.2428 - val_loss: 202.4710 - val_mae: 3.3351\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.1234 - mae: 1.2038 - val_loss: 162.9774 - val_mae: 3.0700\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.3633 - mae: 1.3637 - val_loss: 188.1584 - val_mae: 3.2931\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8871 - mae: 1.1971 - val_loss: 155.0459 - val_mae: 3.0204\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6286 - mae: 1.1223 - val_loss: 203.8752 - val_mae: 3.3290\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8144 - mae: 1.1780 - val_loss: 137.9876 - val_mae: 2.8017\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9401 - mae: 1.2328 - val_loss: 138.3589 - val_mae: 2.8012\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6365 - mae: 1.0504 - val_loss: 138.3416 - val_mae: 2.7936\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.5714 - mae: 1.0882 - val_loss: 153.8434 - val_mae: 2.9892\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.5303 - mae: 0.9933 - val_loss: 145.2273 - val_mae: 2.9350\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3582 - mae: 1.1807 - val_loss: 133.3312 - val_mae: 2.7771\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5058 - mae: 1.2528 - val_loss: 179.3021 - val_mae: 3.1403\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9832 - mae: 1.0301 - val_loss: 165.2136 - val_mae: 3.0421\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8691 - mae: 1.0673 - val_loss: 184.8100 - val_mae: 3.1889\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7139 - mae: 1.1861 - val_loss: 135.3179 - val_mae: 2.7598\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8642 - mae: 1.1963 - val_loss: 170.1929 - val_mae: 3.1225\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0896 - mae: 1.1118 - val_loss: 143.8866 - val_mae: 2.8390\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6751 - mae: 1.1974 - val_loss: 142.4449 - val_mae: 2.7586\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6631 - mae: 1.1164 - val_loss: 146.5173 - val_mae: 2.7807\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6658 - mae: 1.0758 - val_loss: 133.0032 - val_mae: 2.6050\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9123 - mae: 1.0670 - val_loss: 147.3264 - val_mae: 2.8120\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.0980 - mae: 1.0216 - val_loss: 141.9856 - val_mae: 2.7539\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.9450 - mae: 1.1060 - val_loss: 161.3599 - val_mae: 2.9521\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8965 - mae: 1.2240 - val_loss: 137.3383 - val_mae: 2.6714\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.0656 - mae: 1.3560 - val_loss: 184.5441 - val_mae: 3.1738\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3887 - mae: 1.1502 - val_loss: 166.0807 - val_mae: 3.0401\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.0604 - mae: 1.0685 - val_loss: 181.9057 - val_mae: 3.1584\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0755 - mae: 1.1635 - val_loss: 188.8047 - val_mae: 3.1838\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0948 - mae: 1.1886 - val_loss: 155.9208 - val_mae: 2.9044\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.3002 - mae: 0.9886 - val_loss: 171.9291 - val_mae: 3.0368\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.3243 - mae: 1.2994 - val_loss: 171.7284 - val_mae: 3.0982\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3044 - mae: 1.0557 - val_loss: 162.3332 - val_mae: 3.0169\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6227 - mae: 1.1795 - val_loss: 201.6665 - val_mae: 3.3261\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5601 - mae: 1.1411 - val_loss: 164.2431 - val_mae: 3.0105\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.8898 - mae: 0.9564 - val_loss: 146.3053 - val_mae: 2.8739\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4730 - mae: 1.1877 - val_loss: 192.5386 - val_mae: 3.2065\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0637 - mae: 1.1267 - val_loss: 171.3332 - val_mae: 3.0226\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3142 - mae: 1.0358 - val_loss: 176.8990 - val_mae: 3.0860\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4366 - mae: 1.1963 - val_loss: 161.9943 - val_mae: 2.9823\n",
      ">6, MAE: 1.960\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 414.6221 - mae: 4.3228 - val_loss: 248.0259 - val_mae: 4.0996\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 285.1992 - mae: 4.1507 - val_loss: 199.2976 - val_mae: 3.8890\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 164.2256 - mae: 3.2706 - val_loss: 452.8558 - val_mae: 5.5797\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 222.6159 - mae: 3.3959 - val_loss: 109.3488 - val_mae: 2.7899\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 140.9294 - mae: 2.9443 - val_loss: 176.1752 - val_mae: 3.4284\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 103.7015 - mae: 2.6737 - val_loss: 322.9854 - val_mae: 4.2371\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 132.2063 - mae: 2.6595 - val_loss: 463.0425 - val_mae: 4.7966\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 76.5512 - mae: 2.2404 - val_loss: 184.6979 - val_mae: 3.2199\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.5040 - mae: 2.0579 - val_loss: 260.1703 - val_mae: 3.5148\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 75.8163 - mae: 2.2746 - val_loss: 194.7702 - val_mae: 3.2158\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 66.3785 - mae: 2.0583 - val_loss: 583.8875 - val_mae: 4.9324\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 137.1105 - mae: 2.5565 - val_loss: 652.0637 - val_mae: 5.0656\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.7041 - mae: 2.0084 - val_loss: 211.0878 - val_mae: 3.1350\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 59.6480 - mae: 2.1138 - val_loss: 311.5342 - val_mae: 3.5844\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.7191 - mae: 1.7541 - val_loss: 484.9171 - val_mae: 4.4298\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 79.7126 - mae: 2.2198 - val_loss: 775.8828 - val_mae: 5.4805\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.7944 - mae: 1.9254 - val_loss: 645.3528 - val_mae: 4.9102\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.3029 - mae: 1.7759 - val_loss: 197.4899 - val_mae: 3.2124\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.8256 - mae: 1.9854 - val_loss: 348.1915 - val_mae: 3.8946\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.2659 - mae: 2.0081 - val_loss: 570.3279 - val_mae: 4.8118\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 85.6967 - mae: 2.2314 - val_loss: 307.5112 - val_mae: 3.7121\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.4058 - mae: 1.5025 - val_loss: 374.4124 - val_mae: 3.9532\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.1883 - mae: 1.8999 - val_loss: 481.8878 - val_mae: 4.3892\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.0815 - mae: 1.8541 - val_loss: 318.8343 - val_mae: 3.5965\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 59.3164 - mae: 1.9716 - val_loss: 506.5504 - val_mae: 4.3876\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8743 - mae: 1.4588 - val_loss: 432.4686 - val_mae: 4.0418\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.1571 - mae: 1.9278 - val_loss: 294.4424 - val_mae: 3.6360\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.4049 - mae: 1.9594 - val_loss: 385.1206 - val_mae: 3.9692\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.5927 - mae: 1.8170 - val_loss: 301.2248 - val_mae: 3.6303\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.0776 - mae: 1.7152 - val_loss: 341.6248 - val_mae: 3.7781\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.5212 - mae: 1.6580 - val_loss: 369.1456 - val_mae: 3.8840\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.3678 - mae: 1.7058 - val_loss: 278.0645 - val_mae: 3.4877\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.8517 - mae: 1.7033 - val_loss: 359.1678 - val_mae: 3.7833\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.3996 - mae: 1.7305 - val_loss: 183.0238 - val_mae: 3.0622\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.9902 - mae: 1.6085 - val_loss: 297.7760 - val_mae: 3.6351\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7500 - mae: 1.5845 - val_loss: 277.0240 - val_mae: 3.5291\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.6540 - mae: 1.7089 - val_loss: 256.9576 - val_mae: 3.4677\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.6816 - mae: 1.8659 - val_loss: 436.5678 - val_mae: 4.2727\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.0137 - mae: 1.7861 - val_loss: 411.5072 - val_mae: 4.0361\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.9866 - mae: 1.6732 - val_loss: 334.0409 - val_mae: 3.8216\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.3688 - mae: 1.5732 - val_loss: 238.0444 - val_mae: 3.2923\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.8689 - mae: 1.7409 - val_loss: 271.3310 - val_mae: 3.5035\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7465 - mae: 1.4735 - val_loss: 387.5419 - val_mae: 3.9870\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.3041 - mae: 1.5710 - val_loss: 193.7910 - val_mae: 3.0970\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.4118 - mae: 1.5484 - val_loss: 151.5367 - val_mae: 2.8697\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.7409 - mae: 1.7499 - val_loss: 191.6074 - val_mae: 3.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2575 - mae: 1.4769 - val_loss: 304.1003 - val_mae: 3.6652\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2341 - mae: 1.4825 - val_loss: 236.0386 - val_mae: 3.2834\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6521 - mae: 1.4374 - val_loss: 221.3602 - val_mae: 3.1496\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2381 - mae: 1.5126 - val_loss: 193.6468 - val_mae: 2.9983\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5864 - mae: 1.4009 - val_loss: 231.8184 - val_mae: 3.2392\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.7951 - mae: 1.6161 - val_loss: 158.1998 - val_mae: 2.8171\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.7365 - mae: 1.5944 - val_loss: 295.4533 - val_mae: 3.5857\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.1525 - mae: 1.5478 - val_loss: 306.8805 - val_mae: 3.5916\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.3557 - mae: 1.5446 - val_loss: 215.9716 - val_mae: 3.1612\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.6537 - mae: 1.5908 - val_loss: 334.3278 - val_mae: 3.6787\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8438 - mae: 1.3346 - val_loss: 260.3491 - val_mae: 3.4453\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.5692 - mae: 1.4298 - val_loss: 248.6654 - val_mae: 3.3105\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.1549 - mae: 1.3227 - val_loss: 176.9267 - val_mae: 2.9919\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4184 - mae: 1.4776 - val_loss: 228.3895 - val_mae: 3.2412\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.0589 - mae: 1.4092 - val_loss: 131.3337 - val_mae: 2.6153\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.3657 - mae: 1.5078 - val_loss: 130.2029 - val_mae: 2.5884\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.8357 - mae: 1.7765 - val_loss: 191.5874 - val_mae: 3.1424\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3723 - mae: 1.4220 - val_loss: 224.4503 - val_mae: 3.2910\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9756 - mae: 1.4842 - val_loss: 274.7155 - val_mae: 3.4248\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9612 - mae: 1.4712 - val_loss: 215.2909 - val_mae: 3.1430\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0955 - mae: 1.4947 - val_loss: 167.9496 - val_mae: 2.9411\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 32.6757 - mae: 1.50 - 1s 1ms/step - loss: 31.0303 - mae: 1.5015 - val_loss: 286.8911 - val_mae: 3.5293\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7613 - mae: 1.3922 - val_loss: 148.6609 - val_mae: 2.8084\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.7761 - mae: 1.5925 - val_loss: 206.7870 - val_mae: 3.0978\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1099 - mae: 1.2367 - val_loss: 245.7647 - val_mae: 3.3328\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.5871 - mae: 1.5302 - val_loss: 112.7708 - val_mae: 2.5783\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.0490 - mae: 1.5335 - val_loss: 233.1224 - val_mae: 3.2911\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9581 - mae: 1.3154 - val_loss: 215.5382 - val_mae: 3.2224\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.3205 - mae: 1.5334 - val_loss: 110.1030 - val_mae: 2.5592\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3571 - mae: 1.3977 - val_loss: 169.9430 - val_mae: 2.8983\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.5382 - mae: 1.4256 - val_loss: 188.3772 - val_mae: 3.0703\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3299 - mae: 1.2859 - val_loss: 163.2619 - val_mae: 2.9444\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7166 - mae: 1.2834 - val_loss: 136.5171 - val_mae: 2.7360\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.5699 - mae: 1.2653 - val_loss: 157.4267 - val_mae: 2.9330\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8234 - mae: 1.2867 - val_loss: 181.6427 - val_mae: 3.0747\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6781 - mae: 1.2015 - val_loss: 201.5211 - val_mae: 3.1257\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.4681 - mae: 1.2935 - val_loss: 199.6643 - val_mae: 3.1260\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.7222 - mae: 1.4305 - val_loss: 190.4826 - val_mae: 3.0756\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.9349 - mae: 1.5110 - val_loss: 197.5949 - val_mae: 3.1421\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3696 - mae: 1.4140 - val_loss: 250.8016 - val_mae: 3.3882\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.0325 - mae: 1.3757 - val_loss: 155.7591 - val_mae: 2.8288\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.5039 - mae: 1.3388 - val_loss: 170.7797 - val_mae: 2.9578\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.2380 - mae: 1.4462 - val_loss: 116.7137 - val_mae: 2.5819\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4542 - mae: 1.3998 - val_loss: 160.4116 - val_mae: 2.8805\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.4638 - mae: 1.1665 - val_loss: 185.9008 - val_mae: 3.0611\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3443 - mae: 1.2938 - val_loss: 167.6823 - val_mae: 3.0652\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3561 - mae: 1.3077 - val_loss: 194.6658 - val_mae: 3.1390\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5806 - mae: 1.3337 - val_loss: 213.6316 - val_mae: 3.2305\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.0159 - mae: 1.2854 - val_loss: 151.2411 - val_mae: 2.8293\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8602 - mae: 1.2511 - val_loss: 213.6054 - val_mae: 3.2301\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5162 - mae: 1.3191 - val_loss: 189.6828 - val_mae: 3.1960\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5666 - mae: 1.2764 - val_loss: 171.8907 - val_mae: 2.9999\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.2871 - mae: 1.4483 - val_loss: 360.8025 - val_mae: 4.0582\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9842 - mae: 1.4835 - val_loss: 141.1762 - val_mae: 2.8032\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.0977 - mae: 1.4654 - val_loss: 282.4081 - val_mae: 3.6580\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.2343 - mae: 1.6606 - val_loss: 201.1827 - val_mae: 3.2098\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0737 - mae: 1.3302 - val_loss: 216.8783 - val_mae: 3.3057\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0289 - mae: 1.3352 - val_loss: 212.0813 - val_mae: 3.2895\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.1977 - mae: 1.3546 - val_loss: 188.1203 - val_mae: 3.1245\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8537 - mae: 1.3750 - val_loss: 200.5776 - val_mae: 3.2336\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1375 - mae: 1.1812 - val_loss: 264.7006 - val_mae: 3.5785\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1440 - mae: 1.4131 - val_loss: 325.1085 - val_mae: 3.8548\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.8508 - mae: 1.4120 - val_loss: 224.4723 - val_mae: 3.3931\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4688 - mae: 1.2797 - val_loss: 244.0230 - val_mae: 3.5033\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.2322 - mae: 1.4210 - val_loss: 163.8295 - val_mae: 3.0062\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3658 - mae: 1.4454 - val_loss: 157.6274 - val_mae: 2.9237\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2492 - mae: 1.1540 - val_loss: 207.2581 - val_mae: 3.2570\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2439 - mae: 1.3180 - val_loss: 157.3176 - val_mae: 2.9026\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9174 - mae: 1.1410 - val_loss: 179.8807 - val_mae: 3.0959\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.1095 - mae: 1.4590 - val_loss: 226.1803 - val_mae: 3.3479\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5567 - mae: 1.2187 - val_loss: 223.2719 - val_mae: 3.3563\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.0829 - mae: 1.1982 - val_loss: 147.8501 - val_mae: 2.9053\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3302 - mae: 1.2394 - val_loss: 188.5268 - val_mae: 3.1447\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.9125 - mae: 1.5283 - val_loss: 290.9816 - val_mae: 3.6862\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.5045 - mae: 1.3463 - val_loss: 149.4405 - val_mae: 2.8774\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5641 - mae: 1.2154 - val_loss: 202.5428 - val_mae: 3.2572\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.8846 - mae: 1.1410 - val_loss: 166.8412 - val_mae: 3.0020\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8308 - mae: 1.3456 - val_loss: 181.9288 - val_mae: 3.1039\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.9206 - mae: 1.1327 - val_loss: 176.6992 - val_mae: 3.0728\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6444 - mae: 1.2185 - val_loss: 167.5224 - val_mae: 2.9939\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7672 - mae: 1.1348 - val_loss: 155.0416 - val_mae: 2.9130\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.7448 - mae: 1.2336 - val_loss: 186.3531 - val_mae: 3.1941\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6592 - mae: 1.2278 - val_loss: 188.8836 - val_mae: 3.1472\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7061 - mae: 1.1730 - val_loss: 150.3574 - val_mae: 2.8048\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.1832 - mae: 1.1704 - val_loss: 159.0021 - val_mae: 2.9435\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.0901 - mae: 1.0967 - val_loss: 231.2362 - val_mae: 3.4118\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.9340 - mae: 1.1359 - val_loss: 161.1792 - val_mae: 2.9275\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5737 - mae: 1.1630 - val_loss: 198.5363 - val_mae: 3.2452\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.3962 - mae: 1.2660 - val_loss: 239.5416 - val_mae: 3.5122\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.0302 - mae: 1.2464 - val_loss: 197.5326 - val_mae: 3.2129\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.1848 - mae: 1.3660 - val_loss: 202.9231 - val_mae: 3.2304\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.2288 - mae: 1.1713 - val_loss: 187.8148 - val_mae: 3.1451\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.8359 - mae: 1.0501 - val_loss: 149.0250 - val_mae: 2.8468\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4284 - mae: 1.2036 - val_loss: 183.3197 - val_mae: 3.1365\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0489 - mae: 1.1067 - val_loss: 163.5469 - val_mae: 2.9818\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7647 - mae: 1.1389 - val_loss: 148.5609 - val_mae: 2.8429\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.2291 - mae: 1.2684 - val_loss: 133.4432 - val_mae: 2.6782\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.3416 - mae: 1.3557 - val_loss: 202.2465 - val_mae: 3.2594\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.9147 - mae: 1.1788 - val_loss: 198.8349 - val_mae: 3.2024\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.1515 - mae: 1.1472 - val_loss: 218.0993 - val_mae: 3.3516\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6641 - mae: 1.1946 - val_loss: 277.1734 - val_mae: 3.6339\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5075 - mae: 1.3091 - val_loss: 165.8465 - val_mae: 3.0543\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6050 - mae: 1.1293 - val_loss: 176.2902 - val_mae: 3.0990\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6333 - mae: 1.1553 - val_loss: 226.9400 - val_mae: 3.3504\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.9807 - mae: 0.9841 - val_loss: 190.6622 - val_mae: 3.1977\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.9819 - mae: 1.0605 - val_loss: 164.7886 - val_mae: 2.9930\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.2052 - mae: 1.0153 - val_loss: 159.8421 - val_mae: 2.9531\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.3234 - mae: 1.1130 - val_loss: 147.3819 - val_mae: 2.8594\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.1228 - mae: 1.2946 - val_loss: 196.5285 - val_mae: 3.2560\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.7332 - mae: 1.0744 - val_loss: 177.7038 - val_mae: 3.0990\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.7277 - mae: 1.0446 - val_loss: 190.1546 - val_mae: 3.1623\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.1238 - mae: 1.1229 - val_loss: 196.8535 - val_mae: 3.1906\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5544 - mae: 1.2686 - val_loss: 144.9168 - val_mae: 2.7688\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.4295 - mae: 1.1394 - val_loss: 143.1782 - val_mae: 2.7896\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.0306 - mae: 1.3410 - val_loss: 181.0138 - val_mae: 3.1004\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6445 - mae: 1.1891 - val_loss: 153.6952 - val_mae: 2.8578\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6321 - mae: 1.1287 - val_loss: 152.5434 - val_mae: 2.8855\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4462 - mae: 1.1494 - val_loss: 161.9018 - val_mae: 2.9003\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 10.3448 - mae: 1.0670 - val_loss: 164.2794 - val_mae: 2.9665\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.5986 - mae: 1.0193 - val_loss: 158.4677 - val_mae: 2.9278\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9763 - mae: 1.1593 - val_loss: 183.6889 - val_mae: 3.1238\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6941 - mae: 1.1144 - val_loss: 177.3918 - val_mae: 3.0615\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.8225 - mae: 0.9603 - val_loss: 147.3288 - val_mae: 2.8329\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.5320 - mae: 1.2386 - val_loss: 142.6153 - val_mae: 2.7349\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0775 - mae: 1.1331 - val_loss: 153.1357 - val_mae: 2.7989\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6673 - mae: 1.3099 - val_loss: 176.4163 - val_mae: 3.0534\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0674 - mae: 1.1032 - val_loss: 185.8625 - val_mae: 3.1763\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.2694 - mae: 1.0748 - val_loss: 137.2533 - val_mae: 2.7340\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.8003 - mae: 1.0427 - val_loss: 130.2250 - val_mae: 2.5932\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.8322 - mae: 1.0662 - val_loss: 163.0549 - val_mae: 2.9875\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.7528 - mae: 1.0475 - val_loss: 175.0679 - val_mae: 3.0370\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9505 - mae: 1.1436 - val_loss: 146.6499 - val_mae: 2.7794\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.4505 - mae: 1.1201 - val_loss: 173.5740 - val_mae: 3.0648\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3339 - mae: 1.1292 - val_loss: 201.1491 - val_mae: 3.2909\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5006 - mae: 1.2393 - val_loss: 135.2296 - val_mae: 2.6904\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.7628 - mae: 1.0299 - val_loss: 150.2325 - val_mae: 2.8881\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0019 - mae: 1.0876 - val_loss: 179.1460 - val_mae: 3.1102\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.4580 - mae: 1.1283 - val_loss: 205.4339 - val_mae: 3.3085\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.0277 - mae: 1.2761 - val_loss: 124.9200 - val_mae: 2.6083\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6428 - mae: 1.0639 - val_loss: 148.1259 - val_mae: 2.8795\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.7201 - mae: 0.9846 - val_loss: 135.1889 - val_mae: 2.7251\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7981 - mae: 1.1196 - val_loss: 125.0156 - val_mae: 2.6094\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.5793 - mae: 1.0560 - val_loss: 156.7284 - val_mae: 2.9611\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.0108 - mae: 1.0108 - val_loss: 159.7840 - val_mae: 2.9556\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.3980 - mae: 1.0257 - val_loss: 165.3208 - val_mae: 3.0280\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4349 - mae: 1.1203 - val_loss: 140.2594 - val_mae: 2.7678\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.6785 - mae: 1.2991 - val_loss: 165.6910 - val_mae: 2.9999\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5932 - mae: 1.0590 - val_loss: 142.5182 - val_mae: 2.7984\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5384 - mae: 1.2513 - val_loss: 137.1797 - val_mae: 2.7156\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.7883 - mae: 1.1322 - val_loss: 172.9837 - val_mae: 3.0659\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.1737 - mae: 1.2457 - val_loss: 194.9513 - val_mae: 3.2382\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.7556 - mae: 1.1214 - val_loss: 219.1285 - val_mae: 3.4221\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0021 - mae: 1.1231 - val_loss: 145.6574 - val_mae: 2.8393\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.1092 - mae: 0.9764 - val_loss: 161.4039 - val_mae: 3.0586\n",
      ">7, MAE: 2.125\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 694.7238 - mae: 4.8121 - val_loss: 262.0445 - val_mae: 4.6730\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 215.9072 - mae: 3.4216 - val_loss: 153.7299 - val_mae: 2.8735\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 228.1099 - mae: 3.5260 - val_loss: 156.6216 - val_mae: 3.4706\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 174.2521 - mae: 3.1063 - val_loss: 138.9566 - val_mae: 3.2084\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 182.4144 - mae: 2.9732 - val_loss: 112.6906 - val_mae: 2.6962\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 197.1758 - mae: 3.1335 - val_loss: 182.6614 - val_mae: 3.6198\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 131.4836 - mae: 2.6989 - val_loss: 161.3477 - val_mae: 3.2844\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 122.3997 - mae: 2.6538 - val_loss: 203.3216 - val_mae: 3.5290\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 135.9671 - mae: 2.6334 - val_loss: 214.2610 - val_mae: 3.4853\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 84.3685 - mae: 2.3703 - val_loss: 251.2204 - val_mae: 3.5178\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 70.5756 - mae: 2.1875 - val_loss: 332.1265 - val_mae: 3.9313\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 122.3868 - mae: 2.4874 - val_loss: 271.1375 - val_mae: 3.7094\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 58.8094 - mae: 2.1596 - val_loss: 415.7754 - val_mae: 4.3941\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 71.0313 - mae: 2.2251 - val_loss: 334.8999 - val_mae: 3.7658\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 84.5491 - mae: 2.2622 - val_loss: 574.6331 - val_mae: 4.6879\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 73.9948 - mae: 2.2173 - val_loss: 259.9430 - val_mae: 3.7815\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.1046 - mae: 1.9577 - val_loss: 220.1275 - val_mae: 3.4748\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.7519 - mae: 1.9448 - val_loss: 482.1906 - val_mae: 4.2172\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.0296 - mae: 1.9341 - val_loss: 428.6342 - val_mae: 4.1067\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.4917 - mae: 1.8651 - val_loss: 504.5190 - val_mae: 4.3340\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.4211 - mae: 1.9146 - val_loss: 318.5374 - val_mae: 3.7133\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.2943 - mae: 1.8310 - val_loss: 323.6959 - val_mae: 3.7554\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.1327 - mae: 1.8144 - val_loss: 237.7120 - val_mae: 3.4686\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 69.4023 - mae: 1.9891 - val_loss: 538.4731 - val_mae: 4.4745\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 58.3649 - mae: 1.9971 - val_loss: 307.3238 - val_mae: 3.6297\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.7488 - mae: 1.7515 - val_loss: 308.8774 - val_mae: 3.6663\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.6470 - mae: 1.9663 - val_loss: 295.9080 - val_mae: 3.5874\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.4921 - mae: 1.7776 - val_loss: 538.1863 - val_mae: 4.4356\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.5295 - mae: 1.7340 - val_loss: 377.8441 - val_mae: 3.9575\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.8208 - mae: 1.7530 - val_loss: 492.1450 - val_mae: 4.3253\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.4265 - mae: 1.8024 - val_loss: 264.5364 - val_mae: 3.5068\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.7853 - mae: 1.7197 - val_loss: 321.9682 - val_mae: 3.7520\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1856 - mae: 1.5403 - val_loss: 323.5928 - val_mae: 3.7637\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7056 - mae: 1.4849 - val_loss: 350.3842 - val_mae: 3.8839\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.4161 - mae: 1.6652 - val_loss: 346.6327 - val_mae: 3.8821\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.2707 - mae: 1.5145 - val_loss: 356.5277 - val_mae: 3.9568\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.8674 - mae: 1.7348 - val_loss: 308.1636 - val_mae: 3.7927\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.8920 - mae: 1.6226 - val_loss: 367.0618 - val_mae: 3.9909\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.6354 - mae: 1.4277 - val_loss: 295.4326 - val_mae: 3.7264\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.8692 - mae: 1.6521 - val_loss: 286.5412 - val_mae: 3.7422\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.0661 - mae: 1.6430 - val_loss: 496.2215 - val_mae: 4.4225\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.0705 - mae: 1.5733 - val_loss: 378.1117 - val_mae: 4.1001\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.9851 - mae: 1.4427 - val_loss: 283.5207 - val_mae: 3.7631\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.1756 - mae: 1.4710 - val_loss: 265.4478 - val_mae: 3.6753\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.7941 - mae: 1.5553 - val_loss: 277.6086 - val_mae: 3.7224\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4202 - mae: 1.3981 - val_loss: 289.0444 - val_mae: 3.7331\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.8570 - mae: 1.5224 - val_loss: 243.5661 - val_mae: 3.5067\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.6354 - mae: 1.4658 - val_loss: 208.5441 - val_mae: 3.4873\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4107 - mae: 1.3538 - val_loss: 247.3663 - val_mae: 3.6188\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.5311 - mae: 1.6885 - val_loss: 418.9208 - val_mae: 4.2885\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.1135 - mae: 1.7056 - val_loss: 286.4723 - val_mae: 3.7841\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1553 - mae: 1.4499 - val_loss: 190.7300 - val_mae: 3.3543\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2904 - mae: 1.4061 - val_loss: 319.5372 - val_mae: 3.9082\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.4837 - mae: 1.6750 - val_loss: 189.0263 - val_mae: 3.3967\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.5313 - mae: 1.6215 - val_loss: 171.1235 - val_mae: 3.2640\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.7342 - mae: 1.5190 - val_loss: 227.8540 - val_mae: 3.5025\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.7513 - mae: 1.5819 - val_loss: 469.2501 - val_mae: 4.3872\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.5550 - mae: 1.4610 - val_loss: 292.9690 - val_mae: 3.9970\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 29.3116 - mae: 1.4985 - val_loss: 343.6747 - val_mae: 4.0339\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.5265 - mae: 1.3559 - val_loss: 304.0565 - val_mae: 3.8762\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 25.1988 - mae: 1.4467 - val_loss: 291.9774 - val_mae: 3.9668\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 30.3636 - mae: 1.5335 - val_loss: 176.7104 - val_mae: 3.2206\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 47.1549 - mae: 1.5348 - val_loss: 329.4543 - val_mae: 4.0252\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.9484 - mae: 1.4253 - val_loss: 363.7454 - val_mae: 4.0661\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7290 - mae: 1.4813 - val_loss: 289.8398 - val_mae: 3.8094\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.8820 - mae: 1.4557 - val_loss: 175.5729 - val_mae: 3.2343\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0006 - mae: 1.4019 - val_loss: 227.8267 - val_mae: 3.6256\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.6099 - mae: 1.3647 - val_loss: 253.0647 - val_mae: 3.6777\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 19.5426 - mae: 1.3758 - val_loss: 196.2361 - val_mae: 3.4419\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.1084 - mae: 1.3960 - val_loss: 306.1682 - val_mae: 4.2501\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4533 - mae: 1.5200 - val_loss: 211.6176 - val_mae: 3.5494\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.6420 - mae: 1.6382 - val_loss: 258.0700 - val_mae: 3.7939\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1497 - mae: 1.4560 - val_loss: 325.2156 - val_mae: 4.0282\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 19.3324 - mae: 1.3385 - val_loss: 305.6204 - val_mae: 3.9158\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.5624 - mae: 1.5565 - val_loss: 192.0096 - val_mae: 3.3617\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 20.6010 - mae: 1.3276 - val_loss: 233.8067 - val_mae: 3.5866\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 27.1751 - mae: 1.4660 - val_loss: 176.3450 - val_mae: 3.3019\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.4966 - mae: 1.4298 - val_loss: 249.5796 - val_mae: 3.6815\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2760 - mae: 1.4039 - val_loss: 247.4594 - val_mae: 3.7215\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9883 - mae: 1.4239 - val_loss: 210.6748 - val_mae: 3.6510\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.8668 - mae: 1.2601 - val_loss: 255.3110 - val_mae: 3.7629\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8574 - mae: 1.2600 - val_loss: 247.5095 - val_mae: 3.6920\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0536 - mae: 1.3240 - val_loss: 252.1229 - val_mae: 3.7212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.4756 - mae: 1.4583 - val_loss: 180.7449 - val_mae: 3.3147\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.6453 - mae: 1.2817 - val_loss: 223.9598 - val_mae: 3.5940\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.2047 - mae: 1.3720 - val_loss: 215.7390 - val_mae: 3.5213\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1640 - mae: 1.1927 - val_loss: 221.5811 - val_mae: 3.5349\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.9598 - mae: 1.2310 - val_loss: 226.3771 - val_mae: 3.5254\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3891 - mae: 1.3701 - val_loss: 185.7033 - val_mae: 3.3831\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7027 - mae: 1.2817 - val_loss: 176.3360 - val_mae: 3.2696\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0670 - mae: 1.3479 - val_loss: 214.3832 - val_mae: 3.5234\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6858 - mae: 1.2451 - val_loss: 173.3646 - val_mae: 3.2870\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2307 - mae: 1.3933 - val_loss: 160.2626 - val_mae: 3.2425\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.2747 - mae: 1.4739 - val_loss: 249.5208 - val_mae: 3.7178\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6838 - mae: 1.2831 - val_loss: 245.5988 - val_mae: 3.7580\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5919 - mae: 1.3331 - val_loss: 231.3094 - val_mae: 3.6694\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.7432 - mae: 1.3250 - val_loss: 210.2585 - val_mae: 3.5974\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5194 - mae: 1.2473 - val_loss: 170.9597 - val_mae: 3.3078\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3795 - mae: 1.1754 - val_loss: 188.8774 - val_mae: 3.4629\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.9189 - mae: 1.3279 - val_loss: 195.3270 - val_mae: 3.5223\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.3646 - mae: 1.1973 - val_loss: 222.3231 - val_mae: 3.6650\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.7349 - mae: 1.1743 - val_loss: 231.3691 - val_mae: 3.6234\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.7532 - mae: 1.2798 - val_loss: 211.9766 - val_mae: 3.5527\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3641 - mae: 1.2890 - val_loss: 160.2578 - val_mae: 3.2067\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.0369 - mae: 1.2370 - val_loss: 205.4261 - val_mae: 3.4725\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.2960 - mae: 1.1505 - val_loss: 203.2150 - val_mae: 3.5881\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6117 - mae: 1.2386 - val_loss: 201.9216 - val_mae: 3.5018\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.1084 - mae: 1.3332 - val_loss: 337.3319 - val_mae: 4.0883\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.3553 - mae: 1.2900 - val_loss: 206.3613 - val_mae: 3.5938\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 22.9059 - mae: 1.3262 - val_loss: 193.9649 - val_mae: 3.4413\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.3396 - mae: 1.3146 - val_loss: 193.7926 - val_mae: 3.4336\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 26.2937 - mae: 1.4387 - val_loss: 236.2524 - val_mae: 3.8051\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0680 - mae: 1.2720 - val_loss: 143.7039 - val_mae: 3.0698\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.5815 - mae: 1.4038 - val_loss: 177.7332 - val_mae: 3.3025\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.2471 - mae: 1.1735 - val_loss: 284.9364 - val_mae: 3.9206\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.3722 - mae: 1.3478 - val_loss: 134.9609 - val_mae: 2.9628\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.6207 - mae: 1.1125 - val_loss: 188.3724 - val_mae: 3.3994\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0238 - mae: 1.2633 - val_loss: 291.3912 - val_mae: 4.0007\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5925 - mae: 1.2035 - val_loss: 259.6855 - val_mae: 3.8441\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5943 - mae: 1.2059 - val_loss: 221.8805 - val_mae: 3.6472\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.0452 - mae: 1.1783 - val_loss: 221.9161 - val_mae: 3.6470\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.6869 - mae: 1.0907 - val_loss: 213.6899 - val_mae: 3.6325\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.8350 - mae: 1.3156 - val_loss: 285.0718 - val_mae: 3.9164\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 28.0658 - mae: 1.3979 - val_loss: 243.0725 - val_mae: 3.7754\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 11.7880 - mae: 1.1248 - val_loss: 209.2070 - val_mae: 3.6038\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 23.5757 - mae: 1.3333 - val_loss: 218.2223 - val_mae: 3.6643\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.5265 - mae: 1.3717 - val_loss: 214.7582 - val_mae: 3.6203\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.1278 - mae: 1.2357 - val_loss: 206.8241 - val_mae: 3.5842\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 12.7405 - mae: 1.1378 - val_loss: 259.7871 - val_mae: 3.8600\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 23.6952 - mae: 1.3548 - val_loss: 273.2116 - val_mae: 3.9916\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.5418 - mae: 1.2407 - val_loss: 195.6151 - val_mae: 3.5191\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4477 - mae: 1.2223 - val_loss: 213.2187 - val_mae: 3.6417\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.2214 - mae: 1.4013 - val_loss: 254.3287 - val_mae: 3.8241\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6629 - mae: 1.2919 - val_loss: 238.5780 - val_mae: 3.7070\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1472 - mae: 1.1501 - val_loss: 279.1978 - val_mae: 3.8735\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5906 - mae: 1.2370 - val_loss: 256.8649 - val_mae: 3.7810\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.3065 - mae: 1.2250 - val_loss: 286.0884 - val_mae: 3.9081\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5032 - mae: 1.1288 - val_loss: 223.7796 - val_mae: 3.6115\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.9396 - mae: 1.1573 - val_loss: 222.2456 - val_mae: 3.6351\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.2180 - mae: 1.2337 - val_loss: 267.2538 - val_mae: 3.8852\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0077 - mae: 1.2397 - val_loss: 255.4218 - val_mae: 3.7968\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 58.0926 - mae: 1.4561 - val_loss: 446.7352 - val_mae: 4.3998\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 20.9169 - mae: 1.1878 - val_loss: 247.6410 - val_mae: 3.7059\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 10.0796 - mae: 1.0938 - val_loss: 319.3300 - val_mae: 4.0310\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.3622 - mae: 1.2349 - val_loss: 434.1320 - val_mae: 4.3924\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4836 - mae: 1.1717 - val_loss: 292.3812 - val_mae: 3.8847\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.2072 - mae: 1.1589 - val_loss: 196.7345 - val_mae: 3.4710\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.5207 - mae: 1.2982 - val_loss: 295.9083 - val_mae: 4.0211\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.7806 - mae: 1.0134 - val_loss: 212.7235 - val_mae: 3.5620\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.0752 - mae: 1.2806 - val_loss: 285.1856 - val_mae: 3.9559\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1736 - mae: 1.1563 - val_loss: 250.8803 - val_mae: 3.8106\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.1145 - mae: 1.1223 - val_loss: 264.0238 - val_mae: 3.9342\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 9.2504 - mae: 1.0228 - val_loss: 270.0863 - val_mae: 3.8761\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.9544 - mae: 1.1830 - val_loss: 308.4820 - val_mae: 4.0416\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.4434 - mae: 1.1563 - val_loss: 194.0673 - val_mae: 3.4441\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.6959 - mae: 1.1578 - val_loss: 169.9396 - val_mae: 3.2298\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.8080 - mae: 1.3606 - val_loss: 276.3026 - val_mae: 3.9006\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.6093 - mae: 1.0110 - val_loss: 249.4480 - val_mae: 3.7651\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.8556 - mae: 1.2038 - val_loss: 255.8042 - val_mae: 3.8211\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.5539 - mae: 1.1051 - val_loss: 241.1561 - val_mae: 3.8189\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.2841 - mae: 1.1291 - val_loss: 217.0069 - val_mae: 3.5517\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9230 - mae: 1.2346 - val_loss: 276.2672 - val_mae: 3.9799\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1628 - mae: 1.1719 - val_loss: 177.1635 - val_mae: 3.3125\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3620 - mae: 1.1604 - val_loss: 246.9483 - val_mae: 3.7890\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1513 - mae: 1.1294 - val_loss: 265.2914 - val_mae: 3.8959\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8000 - mae: 1.3519 - val_loss: 238.9061 - val_mae: 3.6485\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0462 - mae: 1.2045 - val_loss: 267.1268 - val_mae: 3.8948\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.5887 - mae: 1.0936 - val_loss: 235.1007 - val_mae: 3.6581\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.3066 - mae: 1.0185 - val_loss: 235.0809 - val_mae: 3.6340\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1169 - mae: 1.2432 - val_loss: 304.5017 - val_mae: 4.0029\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.1067 - mae: 1.0091 - val_loss: 234.3865 - val_mae: 3.6442\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4857 - mae: 1.2290 - val_loss: 246.5023 - val_mae: 3.7606\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.9452 - mae: 0.9985 - val_loss: 292.4112 - val_mae: 3.9739\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1902 - mae: 1.1600 - val_loss: 209.9277 - val_mae: 3.5692\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 24.4907 - mae: 1.2881 - val_loss: 307.4713 - val_mae: 4.0089\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6252 - mae: 1.1808 - val_loss: 209.3869 - val_mae: 3.5738\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 24.9486 - mae: 1.3242 - val_loss: 178.9877 - val_mae: 3.3225\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.9974 - mae: 1.1650 - val_loss: 204.5833 - val_mae: 3.5382\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.4973 - mae: 1.1192 - val_loss: 242.6195 - val_mae: 3.6845\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.4562 - mae: 1.0461 - val_loss: 268.7244 - val_mae: 3.7954\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.5542 - mae: 1.1189 - val_loss: 215.5558 - val_mae: 3.5570\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.3082 - mae: 1.2035 - val_loss: 175.4354 - val_mae: 3.2807\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 7.5798 - mae: 0.9559 - val_loss: 214.9750 - val_mae: 3.5441\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.4493 - mae: 1.1801 - val_loss: 158.0892 - val_mae: 3.0784\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6264 - mae: 1.1292 - val_loss: 245.4864 - val_mae: 3.7530\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.9070 - mae: 1.1152 - val_loss: 228.9674 - val_mae: 3.6672\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6880 - mae: 1.1029 - val_loss: 232.8471 - val_mae: 3.7567\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4643 - mae: 1.0860 - val_loss: 241.5512 - val_mae: 3.7385\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8118 - mae: 1.1660 - val_loss: 210.6649 - val_mae: 3.5461\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0028 - mae: 1.1299 - val_loss: 236.2770 - val_mae: 3.6743\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4587 - mae: 1.2479 - val_loss: 164.7227 - val_mae: 3.1566\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.2736 - mae: 1.1779 - val_loss: 297.0340 - val_mae: 4.0026\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 11.6075 - mae: 1.1558 - val_loss: 226.0825 - val_mae: 3.6112\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 14.3198 - mae: 1.1421 - val_loss: 248.8416 - val_mae: 3.7330\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 7.5230 - mae: 0.9780 - val_loss: 255.9012 - val_mae: 3.7585\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 17.4957 - mae: 1.2069 - val_loss: 266.5339 - val_mae: 3.9002\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.8616 - mae: 1.3504 - val_loss: 212.7339 - val_mae: 3.5489\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.2834 - mae: 1.1252 - val_loss: 160.7535 - val_mae: 3.1362\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.4933 - mae: 1.2980 - val_loss: 171.0180 - val_mae: 3.2145\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.1028 - mae: 1.1668 - val_loss: 207.5550 - val_mae: 3.5402\n",
      ">8, MAE: 2.028\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 556.6029 - mae: 5.0426 - val_loss: 127.1137 - val_mae: 2.7948\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 290.8068 - mae: 3.4540 - val_loss: 190.3707 - val_mae: 3.8612\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 167.2760 - mae: 3.0894 - val_loss: 113.9832 - val_mae: 2.8826\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 111.0254 - mae: 2.7735 - val_loss: 144.3652 - val_mae: 3.1420\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 99.8200 - mae: 2.4783 - val_loss: 380.0018 - val_mae: 4.4959\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 128.2688 - mae: 2.9422 - val_loss: 245.1435 - val_mae: 3.5659\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 84.5652 - mae: 2.4170 - val_loss: 270.3829 - val_mae: 3.5722\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.9575 - mae: 2.0865 - val_loss: 204.7810 - val_mae: 3.0492\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 84.4102 - mae: 2.2741 - val_loss: 258.9803 - val_mae: 3.2759\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.5221 - mae: 2.0107 - val_loss: 518.9656 - val_mae: 4.5973\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 72.5804 - mae: 2.2930 - val_loss: 525.2034 - val_mae: 4.2780\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 90.2786 - mae: 2.3167 - val_loss: 523.3184 - val_mae: 4.1591\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6510 - mae: 1.6966 - val_loss: 436.6812 - val_mae: 3.8972\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.9911 - mae: 1.9272 - val_loss: 487.4070 - val_mae: 4.0309\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.3107 - mae: 1.9064 - val_loss: 394.1181 - val_mae: 3.7845\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 61.7798 - mae: 2.0428 - val_loss: 452.1845 - val_mae: 3.9843\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 77.5749 - mae: 2.1432 - val_loss: 322.6702 - val_mae: 3.6292\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 89.5285 - mae: 2.2402 - val_loss: 666.0643 - val_mae: 4.5364\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 81.8401 - mae: 2.1958 - val_loss: 281.2400 - val_mae: 3.4793\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.3173 - mae: 1.8088 - val_loss: 361.7886 - val_mae: 3.7322\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 54.1577 - mae: 1.9282 - val_loss: 308.0676 - val_mae: 3.4801\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.6620 - mae: 1.6754 - val_loss: 413.2470 - val_mae: 3.8542\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.9180 - mae: 1.6657 - val_loss: 411.1870 - val_mae: 3.8197\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.0964 - mae: 1.8179 - val_loss: 437.3567 - val_mae: 3.9476\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.9887 - mae: 1.7672 - val_loss: 591.2548 - val_mae: 4.3909\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.0129 - mae: 1.6439 - val_loss: 346.6939 - val_mae: 3.6755\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 58.5780 - mae: 1.9142 - val_loss: 314.1922 - val_mae: 3.5789\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.5006 - mae: 1.7062 - val_loss: 431.0403 - val_mae: 3.9011\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.8356 - mae: 1.7958 - val_loss: 417.4103 - val_mae: 3.8892\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 74.4006 - mae: 2.1126 - val_loss: 480.9938 - val_mae: 4.1041\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 49.5743 - mae: 1.8929 - val_loss: 376.0475 - val_mae: 3.7273\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.5157 - mae: 1.6672 - val_loss: 658.7971 - val_mae: 4.6959\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.9079 - mae: 1.7439 - val_loss: 608.6766 - val_mae: 4.4549\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.8785 - mae: 1.9336 - val_loss: 427.6987 - val_mae: 4.0078\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.2832 - mae: 1.6583 - val_loss: 290.3237 - val_mae: 3.5646\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4926 - mae: 1.4638 - val_loss: 414.0463 - val_mae: 3.9278\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.5212 - mae: 1.5627 - val_loss: 472.3947 - val_mae: 4.1275\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.9021 - mae: 1.6492 - val_loss: 297.1849 - val_mae: 3.5527\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.6501 - mae: 1.5240 - val_loss: 341.0824 - val_mae: 3.7248\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.4069 - mae: 1.6103 - val_loss: 304.8161 - val_mae: 3.5141\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.7110 - mae: 1.4837 - val_loss: 286.8337 - val_mae: 3.4585\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.5888 - mae: 1.6002 - val_loss: 356.5502 - val_mae: 3.9049\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.6373 - mae: 1.5268 - val_loss: 380.9197 - val_mae: 3.9735\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.1044 - mae: 1.6036 - val_loss: 521.8259 - val_mae: 4.4399\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.6995 - mae: 1.5620 - val_loss: 359.2601 - val_mae: 3.8381\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.0076 - mae: 1.5708 - val_loss: 217.9498 - val_mae: 3.3106\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.6288 - mae: 1.5171 - val_loss: 344.7737 - val_mae: 3.7749\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 48.2823 - mae: 1.6981 - val_loss: 565.9679 - val_mae: 4.3201\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.8341 - mae: 1.7366 - val_loss: 441.6194 - val_mae: 4.0811\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.2135 - mae: 1.5276 - val_loss: 210.4623 - val_mae: 3.2479\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.7428 - mae: 1.5317 - val_loss: 286.4886 - val_mae: 3.5884\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.3470 - mae: 1.6128 - val_loss: 675.7271 - val_mae: 5.0969\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.7465 - mae: 1.6647 - val_loss: 414.3202 - val_mae: 3.9876\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.5808 - mae: 1.6425 - val_loss: 185.7682 - val_mae: 3.0974\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9694 - mae: 1.5252 - val_loss: 374.5243 - val_mae: 3.9463\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.0520 - mae: 1.3561 - val_loss: 376.4203 - val_mae: 3.9108\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3418 - mae: 1.3207 - val_loss: 287.8983 - val_mae: 3.6147\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6837 - mae: 1.4035 - val_loss: 302.2013 - val_mae: 3.6827\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.3742 - mae: 1.4748 - val_loss: 293.9810 - val_mae: 3.6644\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6644 - mae: 1.3142 - val_loss: 303.3891 - val_mae: 3.6606\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.3209 - mae: 1.3424 - val_loss: 274.6366 - val_mae: 3.5428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9072 - mae: 1.4882 - val_loss: 316.8587 - val_mae: 3.7159\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.2273 - mae: 1.4625 - val_loss: 249.7702 - val_mae: 3.4967\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.5848 - mae: 1.2992 - val_loss: 249.2170 - val_mae: 3.5405\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4663 - mae: 1.4032 - val_loss: 282.0145 - val_mae: 3.6667\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2848 - mae: 1.3553 - val_loss: 305.2540 - val_mae: 3.7623\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.4153 - mae: 1.4290 - val_loss: 357.4026 - val_mae: 3.9109\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0188 - mae: 1.3697 - val_loss: 293.5797 - val_mae: 3.7639\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.8210 - mae: 1.5127 - val_loss: 259.4480 - val_mae: 3.6093\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.1733 - mae: 1.2940 - val_loss: 242.7677 - val_mae: 3.5862\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.2373 - mae: 1.4355 - val_loss: 239.2419 - val_mae: 3.5181\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.5893 - mae: 1.4297 - val_loss: 266.6123 - val_mae: 3.5925\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4681 - mae: 1.4334 - val_loss: 436.5502 - val_mae: 4.2235\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.9649 - mae: 1.5232 - val_loss: 334.2955 - val_mae: 3.8522\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.2746 - mae: 1.5870 - val_loss: 310.3331 - val_mae: 3.7492\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.2652 - mae: 1.5567 - val_loss: 407.2686 - val_mae: 4.1258\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.6543 - mae: 1.3350 - val_loss: 250.1065 - val_mae: 3.5065\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8769 - mae: 1.1974 - val_loss: 326.0318 - val_mae: 3.8476\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2367 - mae: 1.3059 - val_loss: 363.8518 - val_mae: 3.9545\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.5883 - mae: 1.5615 - val_loss: 475.2833 - val_mae: 4.2910\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0096 - mae: 1.3563 - val_loss: 471.8416 - val_mae: 4.3110\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2851 - mae: 1.3821 - val_loss: 352.7030 - val_mae: 3.8020\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0684 - mae: 1.2645 - val_loss: 273.3657 - val_mae: 3.5861\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4987 - mae: 1.3853 - val_loss: 316.3117 - val_mae: 3.7789\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.7268 - mae: 1.2119 - val_loss: 326.1880 - val_mae: 3.7852\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0765 - mae: 1.1685 - val_loss: 323.0557 - val_mae: 3.7985\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2730 - mae: 1.4217 - val_loss: 281.1304 - val_mae: 3.6376\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7706 - mae: 1.4960 - val_loss: 176.7820 - val_mae: 3.0787\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0713 - mae: 1.2594 - val_loss: 259.4785 - val_mae: 3.5372\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4984 - mae: 1.1717 - val_loss: 247.4435 - val_mae: 3.4445\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2267 - mae: 1.2786 - val_loss: 297.4608 - val_mae: 3.6450\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4665 - mae: 1.2302 - val_loss: 267.3252 - val_mae: 3.5264\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.5002 - mae: 1.3558 - val_loss: 408.5761 - val_mae: 4.0373\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8890 - mae: 1.3320 - val_loss: 371.5207 - val_mae: 3.9634\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3548 - mae: 1.1895 - val_loss: 275.2722 - val_mae: 3.6203\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8149 - mae: 1.2680 - val_loss: 176.1909 - val_mae: 3.1493\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2726 - mae: 1.1937 - val_loss: 342.3303 - val_mae: 3.8607\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8160 - mae: 1.2815 - val_loss: 348.2594 - val_mae: 3.8680\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5416 - mae: 1.2359 - val_loss: 287.4575 - val_mae: 3.6530\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.5302 - mae: 1.4127 - val_loss: 263.3748 - val_mae: 3.5654\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0502 - mae: 1.2893 - val_loss: 259.9100 - val_mae: 3.6157\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1138 - mae: 1.2638 - val_loss: 304.5235 - val_mae: 3.7338\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.4914 - mae: 1.3024 - val_loss: 241.5580 - val_mae: 3.5003\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4572 - mae: 1.2826 - val_loss: 276.4659 - val_mae: 3.6389\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.9579 - mae: 1.1859 - val_loss: 225.4660 - val_mae: 3.4550\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.0494 - mae: 1.3125 - val_loss: 214.0682 - val_mae: 3.3950\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9255 - mae: 1.2393 - val_loss: 311.9884 - val_mae: 3.8079\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.1664 - mae: 1.4413 - val_loss: 253.3362 - val_mae: 3.5731\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0408 - mae: 1.2332 - val_loss: 279.4833 - val_mae: 3.6887\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.4740 - mae: 1.3109 - val_loss: 167.4514 - val_mae: 3.0971\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.1832 - mae: 1.3333 - val_loss: 339.8002 - val_mae: 3.9429\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9151 - mae: 1.1111 - val_loss: 291.2391 - val_mae: 3.7812\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.9599 - mae: 1.2555 - val_loss: 239.6164 - val_mae: 3.5179\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9951 - mae: 1.3395 - val_loss: 328.8232 - val_mae: 3.8998\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1358 - mae: 1.3034 - val_loss: 177.8530 - val_mae: 3.1412\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3002 - mae: 1.1978 - val_loss: 172.1860 - val_mae: 3.1078\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7486 - mae: 1.1688 - val_loss: 208.4285 - val_mae: 3.3061\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2925 - mae: 1.2580 - val_loss: 314.8711 - val_mae: 3.7638\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7200 - mae: 1.1998 - val_loss: 295.8033 - val_mae: 3.7072\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4035 - mae: 1.2845 - val_loss: 195.7189 - val_mae: 3.2549\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2914 - mae: 1.2971 - val_loss: 192.7736 - val_mae: 3.2442\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3473 - mae: 1.1582 - val_loss: 227.6235 - val_mae: 3.4092\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0029 - mae: 1.1693 - val_loss: 223.1470 - val_mae: 3.3824\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9419 - mae: 1.1593 - val_loss: 212.3890 - val_mae: 3.3364\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7235 - mae: 1.3143 - val_loss: 383.9516 - val_mae: 4.1575\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7272 - mae: 1.2047 - val_loss: 226.1674 - val_mae: 3.4751\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.0773 - mae: 1.3015 - val_loss: 213.2071 - val_mae: 3.4422\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.5982 - mae: 1.4210 - val_loss: 167.4854 - val_mae: 3.1450\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7702 - mae: 1.2384 - val_loss: 175.4835 - val_mae: 3.2040\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5797 - mae: 1.1276 - val_loss: 186.5027 - val_mae: 3.2410\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.5724 - mae: 1.3781 - val_loss: 242.6392 - val_mae: 3.5608\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9456 - mae: 1.1480 - val_loss: 292.2973 - val_mae: 3.8007\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.8275 - mae: 1.2893 - val_loss: 186.9510 - val_mae: 3.2929\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6092 - mae: 1.2535 - val_loss: 304.6043 - val_mae: 3.8662\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6803 - mae: 1.1478 - val_loss: 236.6008 - val_mae: 3.5771\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0905 - mae: 1.1151 - val_loss: 252.1804 - val_mae: 3.5887\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.3847 - mae: 1.1639 - val_loss: 290.1425 - val_mae: 3.8016\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0571 - mae: 1.1759 - val_loss: 292.4212 - val_mae: 3.7902\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6317 - mae: 1.2094 - val_loss: 145.8940 - val_mae: 2.9733\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.0315 - mae: 1.4041 - val_loss: 221.1535 - val_mae: 3.4879\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.7709 - mae: 1.0982 - val_loss: 227.0627 - val_mae: 3.5136\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9664 - mae: 1.2875 - val_loss: 172.0471 - val_mae: 3.1934\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5052 - mae: 1.1664 - val_loss: 233.2397 - val_mae: 3.4936\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.7186 - mae: 1.0509 - val_loss: 192.5421 - val_mae: 3.2618\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.4735 - mae: 1.0047 - val_loss: 193.4381 - val_mae: 3.2044\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.8259 - mae: 1.0926 - val_loss: 310.0520 - val_mae: 3.8488\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.1927 - mae: 1.3105 - val_loss: 130.9393 - val_mae: 2.7808\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.3828 - mae: 1.4693 - val_loss: 342.8445 - val_mae: 4.0457\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0195 - mae: 1.1504 - val_loss: 164.5157 - val_mae: 3.1078\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9229 - mae: 1.2364 - val_loss: 291.0966 - val_mae: 3.7494\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1343 - mae: 1.1996 - val_loss: 256.2387 - val_mae: 3.5713\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.6361 - mae: 1.0313 - val_loss: 255.5905 - val_mae: 3.5939\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4662 - mae: 1.1451 - val_loss: 187.7478 - val_mae: 3.2460\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.3689 - mae: 1.3015 - val_loss: 328.3248 - val_mae: 3.9042\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.7942 - mae: 1.2662 - val_loss: 257.7021 - val_mae: 3.6493\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.2965 - mae: 1.0419 - val_loss: 265.5863 - val_mae: 3.6718\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.8440 - mae: 1.1341 - val_loss: 267.4485 - val_mae: 3.6550\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.4292 - mae: 1.3862 - val_loss: 299.5902 - val_mae: 3.7939\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1341 - mae: 1.2006 - val_loss: 253.8937 - val_mae: 3.6776\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6138 - mae: 1.0971 - val_loss: 235.3858 - val_mae: 3.5685\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2211 - mae: 1.1058 - val_loss: 184.5434 - val_mae: 3.3006\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1734 - mae: 1.0548 - val_loss: 259.4593 - val_mae: 3.6925\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.8875 - mae: 1.2005 - val_loss: 173.9811 - val_mae: 3.2161\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.0221 - mae: 1.1930 - val_loss: 177.3260 - val_mae: 3.2090\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8619 - mae: 1.1165 - val_loss: 216.5370 - val_mae: 3.4436\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0164 - mae: 1.0387 - val_loss: 264.7104 - val_mae: 3.6927\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 7.0221 - mae: 0.9673 - val_loss: 274.4138 - val_mae: 3.7356\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.2680 - mae: 1.0867 - val_loss: 300.2277 - val_mae: 3.8270\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.1051 - mae: 0.9464 - val_loss: 267.7858 - val_mae: 3.6513\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9768 - mae: 1.1456 - val_loss: 240.0139 - val_mae: 3.6439\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.9067 - mae: 1.1802 - val_loss: 146.7619 - val_mae: 2.9590\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.5823 - mae: 1.0209 - val_loss: 213.0570 - val_mae: 3.4418\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 15.8199 - mae: 1.1181 - val_loss: 198.9993 - val_mae: 3.3371\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.3346 - mae: 1.1130 - val_loss: 211.0005 - val_mae: 3.4090\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.8147 - mae: 1.0171 - val_loss: 181.2741 - val_mae: 3.1703\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7702 - mae: 1.1529 - val_loss: 280.9656 - val_mae: 3.7805\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 21.6697 - mae: 1.2177 - val_loss: 210.5979 - val_mae: 3.3393\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 10.9657 - mae: 1.1019 - val_loss: 179.5451 - val_mae: 3.1236\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 9.3833 - mae: 0.9727 - val_loss: 190.9627 - val_mae: 3.2400\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 2s 3ms/step - loss: 12.6096 - mae: 1.1068 - val_loss: 195.3351 - val_mae: 3.3250\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.4473 - mae: 1.1128 - val_loss: 244.0967 - val_mae: 3.5870\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.9504 - mae: 1.0607 - val_loss: 255.8426 - val_mae: 3.6875\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.7746 - mae: 1.1099 - val_loss: 254.6064 - val_mae: 3.6594\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.1332 - mae: 1.2370 - val_loss: 189.5295 - val_mae: 3.3115\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 10.0757 - mae: 1.0261 - val_loss: 236.2063 - val_mae: 3.6008\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.3833 - mae: 0.9851 - val_loss: 197.7276 - val_mae: 3.3434\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.9921 - mae: 1.0529 - val_loss: 204.6963 - val_mae: 3.3785\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0165 - mae: 1.0419 - val_loss: 332.3983 - val_mae: 4.0445\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.9402 - mae: 1.2848 - val_loss: 174.7723 - val_mae: 3.1576\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0104 - mae: 1.1653 - val_loss: 184.6810 - val_mae: 3.2804\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.1708 - mae: 1.1687 - val_loss: 186.9575 - val_mae: 3.2860\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0439 - mae: 1.0027 - val_loss: 231.6270 - val_mae: 3.5532\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.1492 - mae: 1.1196 - val_loss: 261.4478 - val_mae: 3.7321\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.2888 - mae: 1.2943 - val_loss: 240.3665 - val_mae: 3.6496\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.2007 - mae: 1.0474 - val_loss: 243.4489 - val_mae: 3.6609\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.0982 - mae: 1.0494 - val_loss: 232.5215 - val_mae: 3.6318\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.0053 - mae: 1.1459 - val_loss: 192.0401 - val_mae: 3.3750\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.0861 - mae: 1.0204 - val_loss: 147.5220 - val_mae: 2.9341\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0900 - mae: 1.1120 - val_loss: 195.9773 - val_mae: 3.3990\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0339 - mae: 1.1302 - val_loss: 194.1155 - val_mae: 3.4558\n",
      ">9, MAE: 1.893\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 3s 3ms/step - loss: 334.7841 - mae: 4.7071 - val_loss: 210.8595 - val_mae: 4.0407\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 366.1603 - mae: 4.1242 - val_loss: 326.9265 - val_mae: 5.1954\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 271.6141 - mae: 3.5045 - val_loss: 179.6418 - val_mae: 3.8966\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 99.7698 - mae: 2.8948 - val_loss: 113.7316 - val_mae: 2.8660\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 226.3033 - mae: 3.3378 - val_loss: 140.8262 - val_mae: 3.3067\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 162.5278 - mae: 2.9290 - val_loss: 102.5940 - val_mae: 2.6251\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 113.8444 - mae: 2.5573 - val_loss: 290.3563 - val_mae: 4.1928\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 108.1459 - mae: 2.5983 - val_loss: 375.2679 - val_mae: 4.3882\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 90.3690 - mae: 2.4696 - val_loss: 144.7202 - val_mae: 3.0123\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 61.0336 - mae: 2.1577 - val_loss: 277.6079 - val_mae: 3.7850\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 99.2337 - mae: 2.4348 - val_loss: 185.1081 - val_mae: 3.3381\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 162.1095 - mae: 2.7816 - val_loss: 332.5146 - val_mae: 3.9020\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 74.4115 - mae: 2.2890 - val_loss: 250.0565 - val_mae: 3.5834\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 88.1519 - mae: 2.3758 - val_loss: 349.6446 - val_mae: 3.9300\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.7744 - mae: 1.8893 - val_loss: 558.3978 - val_mae: 4.8108\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 57.5145 - mae: 2.0444 - val_loss: 369.0359 - val_mae: 4.0047\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.8256 - mae: 1.8475 - val_loss: 399.6088 - val_mae: 4.2085\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.5095 - mae: 1.9972 - val_loss: 305.1664 - val_mae: 3.7295\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 62.7639 - mae: 2.0083 - val_loss: 393.4242 - val_mae: 4.0418\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.0993 - mae: 1.9708 - val_loss: 772.8927 - val_mae: 5.4430\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.9564 - mae: 2.1126 - val_loss: 329.4914 - val_mae: 3.8212\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.2858 - mae: 1.7466 - val_loss: 372.1724 - val_mae: 3.9355\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.1027 - mae: 1.9784 - val_loss: 377.2336 - val_mae: 3.8606\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 67.4530 - mae: 2.1293 - val_loss: 293.4431 - val_mae: 3.6737\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.5046 - mae: 1.9015 - val_loss: 478.9446 - val_mae: 4.4783\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 69.0600 - mae: 2.0237 - val_loss: 610.2766 - val_mae: 4.8009\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 61.1428 - mae: 1.9717 - val_loss: 479.9424 - val_mae: 4.2815\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.8715 - mae: 1.7898 - val_loss: 375.1457 - val_mae: 3.9260\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.9709 - mae: 1.9666 - val_loss: 278.1259 - val_mae: 3.5948\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.3424 - mae: 1.9177 - val_loss: 571.2056 - val_mae: 4.8185\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 52.8877 - mae: 1.9327 - val_loss: 289.9384 - val_mae: 3.6188\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.4123 - mae: 1.7129 - val_loss: 347.3293 - val_mae: 3.8761\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.2043 - mae: 1.7292 - val_loss: 319.4651 - val_mae: 3.7025\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.7785 - mae: 1.8498 - val_loss: 461.8810 - val_mae: 4.4059\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 80.1106 - mae: 2.0501 - val_loss: 315.4444 - val_mae: 3.8575\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.9709 - mae: 1.8041 - val_loss: 382.0938 - val_mae: 4.1742\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.4313 - mae: 1.7684 - val_loss: 375.1158 - val_mae: 4.0730\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.3689 - mae: 1.9061 - val_loss: 300.5342 - val_mae: 3.6421\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.5072 - mae: 1.6260 - val_loss: 395.9187 - val_mae: 4.0586\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.1683 - mae: 1.8622 - val_loss: 326.3139 - val_mae: 3.7010\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.7204 - mae: 1.8686 - val_loss: 427.8083 - val_mae: 4.2292\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.4980 - mae: 1.7378 - val_loss: 348.8864 - val_mae: 3.8688\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.0253 - mae: 1.7558 - val_loss: 338.1925 - val_mae: 3.7870\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 68.7178 - mae: 1.8912 - val_loss: 265.9500 - val_mae: 3.4185\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.8994 - mae: 1.7315 - val_loss: 262.6584 - val_mae: 3.4360\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1316 - mae: 1.6407 - val_loss: 303.1778 - val_mae: 3.6518\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.8941 - mae: 1.6293 - val_loss: 264.4418 - val_mae: 3.4405\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.3770 - mae: 1.7063 - val_loss: 250.1329 - val_mae: 3.4354\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.1459 - mae: 1.6478 - val_loss: 326.9457 - val_mae: 3.7509\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 57.7801 - mae: 1.9684 - val_loss: 296.9819 - val_mae: 3.5729\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.3502 - mae: 1.6489 - val_loss: 253.3339 - val_mae: 3.3466\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.6295 - mae: 1.7386 - val_loss: 298.4211 - val_mae: 3.6271\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.3117 - mae: 1.6295 - val_loss: 487.0011 - val_mae: 4.5136\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 49.9600 - mae: 1.7565 - val_loss: 418.5268 - val_mae: 4.1637\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.0675 - mae: 1.5493 - val_loss: 273.8288 - val_mae: 3.5253\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.0283 - mae: 1.7426 - val_loss: 359.8195 - val_mae: 3.9761\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.7846 - mae: 1.8312 - val_loss: 291.2695 - val_mae: 3.6302\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.4355 - mae: 1.5373 - val_loss: 412.9748 - val_mae: 4.2339\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3902 - mae: 1.5077 - val_loss: 303.5497 - val_mae: 3.7226\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.5939 - mae: 1.6468 - val_loss: 340.4946 - val_mae: 3.8318\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.9730 - mae: 1.6554 - val_loss: 319.6572 - val_mae: 3.7258\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.5136 - mae: 1.4996 - val_loss: 339.7160 - val_mae: 3.7826\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.8400 - mae: 1.6457 - val_loss: 407.6912 - val_mae: 4.1182\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.4637 - mae: 1.4583 - val_loss: 276.0982 - val_mae: 3.5512\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.4842 - mae: 1.5384 - val_loss: 249.0755 - val_mae: 3.4520\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.0386 - mae: 1.5711 - val_loss: 190.7419 - val_mae: 3.1312\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.4561 - mae: 1.4012 - val_loss: 224.0397 - val_mae: 3.2384\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6114 - mae: 1.3680 - val_loss: 238.5783 - val_mae: 3.2939\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.4848 - mae: 1.4634 - val_loss: 386.6852 - val_mae: 4.0582\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.9173 - mae: 1.7505 - val_loss: 329.1476 - val_mae: 3.7921\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.4662 - mae: 1.6390 - val_loss: 300.0622 - val_mae: 3.5557\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.5583 - mae: 1.5883 - val_loss: 207.0409 - val_mae: 3.1300\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8148 - mae: 1.4460 - val_loss: 250.5873 - val_mae: 3.3779\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9737 - mae: 1.4280 - val_loss: 271.0453 - val_mae: 3.5037\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.4929 - mae: 1.2506 - val_loss: 328.6544 - val_mae: 3.7158\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.5966 - mae: 1.4583 - val_loss: 286.8621 - val_mae: 3.5548\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2190 - mae: 1.4201 - val_loss: 294.8528 - val_mae: 3.5348\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.9171 - mae: 1.4803 - val_loss: 248.9369 - val_mae: 3.3557\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.2337 - mae: 1.5189 - val_loss: 275.8737 - val_mae: 3.4990\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.7960 - mae: 1.5124 - val_loss: 213.9457 - val_mae: 3.2960\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.3770 - mae: 1.3882 - val_loss: 233.6706 - val_mae: 3.3014\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4086 - mae: 1.4377 - val_loss: 208.6685 - val_mae: 3.1159\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.7152 - mae: 1.5667 - val_loss: 322.3061 - val_mae: 3.7199\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.5931 - mae: 1.3733 - val_loss: 159.9433 - val_mae: 2.7949\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.6264 - mae: 1.4669 - val_loss: 306.0301 - val_mae: 3.6398\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1517 - mae: 1.4805 - val_loss: 246.1889 - val_mae: 3.3275\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.2088 - mae: 1.2350 - val_loss: 208.1615 - val_mae: 3.0999\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.2252 - mae: 1.5669 - val_loss: 231.0912 - val_mae: 3.2313\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1206 - mae: 1.4334 - val_loss: 266.5912 - val_mae: 3.4122\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.0190 - mae: 1.5340 - val_loss: 241.7700 - val_mae: 3.3047\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.7132 - mae: 1.5213 - val_loss: 193.5279 - val_mae: 3.0588\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4896 - mae: 1.3506 - val_loss: 209.9371 - val_mae: 3.1425\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.8899 - mae: 1.4285 - val_loss: 187.2408 - val_mae: 3.0371\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7286 - mae: 1.3427 - val_loss: 238.5023 - val_mae: 3.2968\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4638 - mae: 1.2475 - val_loss: 238.8466 - val_mae: 3.3061\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.6374 - mae: 1.3091 - val_loss: 154.0395 - val_mae: 2.7972\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.2933 - mae: 1.5411 - val_loss: 193.8316 - val_mae: 3.0009\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.3508 - mae: 1.6570 - val_loss: 350.4233 - val_mae: 3.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.0644 - mae: 1.4453 - val_loss: 209.1321 - val_mae: 3.1459\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.0411 - mae: 1.4250 - val_loss: 184.5187 - val_mae: 2.9906\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.7940 - mae: 1.4021 - val_loss: 176.3168 - val_mae: 2.9450\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.6788 - mae: 1.5168 - val_loss: 293.9474 - val_mae: 3.5849\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.9529 - mae: 1.1593 - val_loss: 195.7032 - val_mae: 3.0392\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.6305 - mae: 1.4641 - val_loss: 225.2014 - val_mae: 3.2693\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.0529 - mae: 1.3622 - val_loss: 144.3547 - val_mae: 2.7627\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.1140 - mae: 1.4045 - val_loss: 237.4123 - val_mae: 3.3700\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1078 - mae: 1.4143 - val_loss: 214.9174 - val_mae: 3.2065\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2289 - mae: 1.2772 - val_loss: 239.8128 - val_mae: 3.3270\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8244 - mae: 1.3060 - val_loss: 214.1290 - val_mae: 3.1810\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3191 - mae: 1.2788 - val_loss: 270.1168 - val_mae: 3.4804\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4099 - mae: 1.3209 - val_loss: 199.0873 - val_mae: 3.0841\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9699 - mae: 1.2814 - val_loss: 244.1084 - val_mae: 3.3651\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.7532 - mae: 1.2929 - val_loss: 165.2791 - val_mae: 2.8789\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.7096 - mae: 1.4253 - val_loss: 175.4524 - val_mae: 2.9293\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.9219 - mae: 1.3767 - val_loss: 230.8229 - val_mae: 3.2792\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7261 - mae: 1.2744 - val_loss: 212.8301 - val_mae: 3.2097\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.4705 - mae: 1.2099 - val_loss: 207.1087 - val_mae: 3.1430\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.8274 - mae: 1.4363 - val_loss: 137.6879 - val_mae: 2.6581\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.9467 - mae: 1.2426 - val_loss: 196.2128 - val_mae: 3.0518\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.1419 - mae: 1.4635 - val_loss: 170.0722 - val_mae: 2.8980\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7791 - mae: 1.2053 - val_loss: 165.8974 - val_mae: 2.8328\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6231 - mae: 1.3331 - val_loss: 175.3793 - val_mae: 2.9029\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9953 - mae: 1.3343 - val_loss: 188.7405 - val_mae: 3.0298\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6065 - mae: 1.0922 - val_loss: 186.2354 - val_mae: 3.0055\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.6515 - mae: 1.3257 - val_loss: 165.0186 - val_mae: 2.8095\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.4364 - mae: 1.3883 - val_loss: 299.7382 - val_mae: 3.6595\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1573 - mae: 1.1657 - val_loss: 199.7037 - val_mae: 3.0503\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7473 - mae: 1.2644 - val_loss: 270.7525 - val_mae: 3.5257\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.8689 - mae: 1.2780 - val_loss: 208.3702 - val_mae: 3.1061\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.6243 - mae: 1.4203 - val_loss: 171.1539 - val_mae: 2.8644\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3404 - mae: 1.3380 - val_loss: 208.8477 - val_mae: 3.1173\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0718 - mae: 1.2707 - val_loss: 167.7349 - val_mae: 2.8916\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8529 - mae: 1.1970 - val_loss: 219.3538 - val_mae: 3.1852\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7194 - mae: 1.1182 - val_loss: 215.7017 - val_mae: 3.1410\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.2505 - mae: 1.5407 - val_loss: 175.5839 - val_mae: 2.9350\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6277 - mae: 1.1753 - val_loss: 186.8002 - val_mae: 2.9955\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4060 - mae: 1.2141 - val_loss: 216.6580 - val_mae: 3.1729\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 29.9041 - mae: 1.35 - 1s 1ms/step - loss: 29.0006 - mae: 1.3417 - val_loss: 244.7360 - val_mae: 3.4216\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7903 - mae: 1.3847 - val_loss: 173.8806 - val_mae: 2.9922\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0049 - mae: 1.2174 - val_loss: 197.8748 - val_mae: 3.1093\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3346 - mae: 1.2427 - val_loss: 212.7317 - val_mae: 3.1780\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9207 - mae: 1.1648 - val_loss: 181.2486 - val_mae: 3.0288\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7790 - mae: 1.2723 - val_loss: 232.3521 - val_mae: 3.3013\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.2991 - mae: 1.1411 - val_loss: 194.0006 - val_mae: 3.0727\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.4801 - mae: 1.3537 - val_loss: 205.6647 - val_mae: 3.0987\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9122 - mae: 1.1756 - val_loss: 190.2968 - val_mae: 3.0265\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.6295 - mae: 1.3779 - val_loss: 185.2107 - val_mae: 3.0034\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1110 - mae: 1.2131 - val_loss: 201.5058 - val_mae: 3.1152\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3189 - mae: 1.3267 - val_loss: 178.6774 - val_mae: 2.9608\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0317 - mae: 1.2773 - val_loss: 167.8465 - val_mae: 2.9040\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9815 - mae: 1.3118 - val_loss: 296.3723 - val_mae: 3.7969\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7225 - mae: 1.3195 - val_loss: 219.1741 - val_mae: 3.2247\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2930 - mae: 1.2141 - val_loss: 260.0106 - val_mae: 3.4943\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1594 - mae: 1.1518 - val_loss: 191.6930 - val_mae: 3.0311\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6809 - mae: 1.0674 - val_loss: 179.5341 - val_mae: 2.9593\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4278 - mae: 1.2524 - val_loss: 195.1872 - val_mae: 3.0213\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3204 - mae: 1.2588 - val_loss: 219.1006 - val_mae: 3.2079\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6135 - mae: 1.1659 - val_loss: 188.0005 - val_mae: 2.9891\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.4635 - mae: 1.0787 - val_loss: 181.8964 - val_mae: 2.9715\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0918 - mae: 1.0825 - val_loss: 166.8507 - val_mae: 2.8635\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1627 - mae: 1.1881 - val_loss: 149.8620 - val_mae: 2.7290\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1301 - mae: 1.1864 - val_loss: 189.4033 - val_mae: 3.0422\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2962 - mae: 1.2510 - val_loss: 183.1612 - val_mae: 2.9703\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9834 - mae: 1.1063 - val_loss: 144.1126 - val_mae: 2.6797\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.5824 - mae: 1.3681 - val_loss: 123.1567 - val_mae: 2.4768\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3444 - mae: 1.2054 - val_loss: 124.8082 - val_mae: 2.4946\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.8673 - mae: 1.3665 - val_loss: 216.3617 - val_mae: 3.2566\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0413 - mae: 1.2330 - val_loss: 191.7820 - val_mae: 3.0916\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.7850 - mae: 1.0157 - val_loss: 188.4424 - val_mae: 3.0166\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5993 - mae: 1.1081 - val_loss: 202.5558 - val_mae: 3.1288\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0985 - mae: 1.1274 - val_loss: 218.0853 - val_mae: 3.2072\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1379 - mae: 1.1222 - val_loss: 192.6057 - val_mae: 3.0766\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.7830 - mae: 0.9894 - val_loss: 168.0547 - val_mae: 2.8800\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4419 - mae: 1.1242 - val_loss: 193.2374 - val_mae: 3.0622\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7818 - mae: 1.2451 - val_loss: 243.9814 - val_mae: 3.3404\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.1209 - mae: 1.0736 - val_loss: 209.7075 - val_mae: 3.1358\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7941 - mae: 1.2962 - val_loss: 181.7990 - val_mae: 3.0223\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4460 - mae: 1.2350 - val_loss: 156.9324 - val_mae: 2.8277\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8128 - mae: 1.2214 - val_loss: 163.0965 - val_mae: 2.8622\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9446 - mae: 1.1278 - val_loss: 193.8587 - val_mae: 3.1315\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8396 - mae: 1.1195 - val_loss: 150.5986 - val_mae: 2.7636\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7729 - mae: 1.0633 - val_loss: 159.3552 - val_mae: 2.8580\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2793 - mae: 1.1664 - val_loss: 222.7510 - val_mae: 3.2601\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.1953 - mae: 0.9740 - val_loss: 211.0360 - val_mae: 3.2036\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5602 - mae: 1.2930 - val_loss: 159.7711 - val_mae: 2.8562\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8504 - mae: 1.1559 - val_loss: 213.8602 - val_mae: 3.2801\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0709 - mae: 1.1761 - val_loss: 153.3394 - val_mae: 2.7995\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0133 - mae: 1.2920 - val_loss: 126.4258 - val_mae: 2.5624\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7362 - mae: 1.1942 - val_loss: 172.6712 - val_mae: 2.9377\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7804 - mae: 1.2595 - val_loss: 232.4822 - val_mae: 3.4167\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4292 - mae: 1.1826 - val_loss: 149.5300 - val_mae: 2.8128\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6209 - mae: 1.1379 - val_loss: 174.7752 - val_mae: 3.0774\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0249 - mae: 1.0732 - val_loss: 164.9906 - val_mae: 3.0255\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0089 - mae: 1.1531 - val_loss: 138.3361 - val_mae: 2.7534\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0239 - mae: 1.2214 - val_loss: 155.3693 - val_mae: 2.9329\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8546 - mae: 1.0847 - val_loss: 214.1053 - val_mae: 3.3974\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2547 - mae: 1.1495 - val_loss: 190.3995 - val_mae: 3.1302\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.4711 - mae: 1.0019 - val_loss: 173.8602 - val_mae: 3.0347\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0611 - mae: 1.2217 - val_loss: 128.1182 - val_mae: 2.5861\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2820 - mae: 1.3415 - val_loss: 205.1850 - val_mae: 3.3008\n",
      ">10, MAE: 2.060\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 432.8130 - mae: 4.8020 - val_loss: 926.7348 - val_mae: 7.7322\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 358.0232 - mae: 4.0271 - val_loss: 863.1185 - val_mae: 7.1342\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 151.8574 - mae: 2.9064 - val_loss: 337.9267 - val_mae: 4.7720\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 156.1242 - mae: 2.9210 - val_loss: 189.1195 - val_mae: 3.4271\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 134.7012 - mae: 2.7377 - val_loss: 210.2807 - val_mae: 3.3402\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 78.2919 - mae: 2.3744 - val_loss: 460.0365 - val_mae: 4.5080\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 104.0830 - mae: 2.6303 - val_loss: 1009.5999 - val_mae: 6.4438\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 82.9651 - mae: 2.4114 - val_loss: 573.3440 - val_mae: 4.6400\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 81.5241 - mae: 2.3631 - val_loss: 339.6637 - val_mae: 3.8991\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 63.2411 - mae: 2.1608 - val_loss: 346.7094 - val_mae: 3.8555\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.2313 - mae: 1.9259 - val_loss: 254.9472 - val_mae: 3.6543\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 79.0160 - mae: 2.1996 - val_loss: 189.2645 - val_mae: 3.2676\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.4851 - mae: 1.8979 - val_loss: 449.4046 - val_mae: 4.3751\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.5373 - mae: 1.9402 - val_loss: 224.0046 - val_mae: 3.4288\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 67.6113 - mae: 2.2162 - val_loss: 267.2181 - val_mae: 3.5495\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.5638 - mae: 2.0176 - val_loss: 394.4746 - val_mae: 3.9860\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.2457 - mae: 1.8606 - val_loss: 469.9182 - val_mae: 4.2212\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.8124 - mae: 1.7707 - val_loss: 371.9368 - val_mae: 3.8713\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.9747 - mae: 1.8780 - val_loss: 338.3925 - val_mae: 3.8283\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.3707 - mae: 1.7168 - val_loss: 414.1986 - val_mae: 3.9980\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.7657 - mae: 1.9649 - val_loss: 317.7265 - val_mae: 3.7407\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.8401 - mae: 1.8286 - val_loss: 557.6871 - val_mae: 4.6425\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.9886 - mae: 1.8114 - val_loss: 242.4801 - val_mae: 3.4888\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.2844 - mae: 1.7010 - val_loss: 157.8305 - val_mae: 3.1000\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.9784 - mae: 1.7975 - val_loss: 421.1939 - val_mae: 4.2123\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.8639 - mae: 1.6783 - val_loss: 346.5210 - val_mae: 3.8198\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 24.3328 - mae: 1.4771 - val_loss: 413.2971 - val_mae: 4.1102\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.4921 - mae: 1.7941 - val_loss: 306.5947 - val_mae: 3.7724\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.8685 - mae: 1.5872 - val_loss: 283.1140 - val_mae: 3.9266\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 43.9423 - mae: 1.7699 - val_loss: 678.1846 - val_mae: 5.1655\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.9810 - mae: 1.8048 - val_loss: 541.9256 - val_mae: 4.7404\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 48.9377 - mae: 1.8665 - val_loss: 409.8100 - val_mae: 4.2033\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8247 - mae: 1.5423 - val_loss: 269.7037 - val_mae: 3.7480\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9744 - mae: 1.6152 - val_loss: 388.5787 - val_mae: 4.2347\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 34.8365 - mae: 1.5664 - val_loss: 258.8493 - val_mae: 3.6694\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.6877 - mae: 1.5787 - val_loss: 368.0385 - val_mae: 4.1148\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2291 - mae: 1.6011 - val_loss: 203.6237 - val_mae: 3.4658\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.3861 - mae: 1.5681 - val_loss: 169.3663 - val_mae: 3.2574\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.0119 - mae: 1.8422 - val_loss: 204.5873 - val_mae: 3.4989\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.6005 - mae: 1.6836 - val_loss: 261.5956 - val_mae: 3.7935\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.3954 - mae: 1.7566 - val_loss: 225.3686 - val_mae: 3.6530\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.0327 - mae: 1.5484 - val_loss: 164.0254 - val_mae: 3.2846\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.4287 - mae: 1.7243 - val_loss: 166.8281 - val_mae: 3.2436\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.4861 - mae: 1.5093 - val_loss: 252.9080 - val_mae: 3.6747\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.6442 - mae: 1.7101 - val_loss: 116.5283 - val_mae: 2.8294\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.6225 - mae: 1.7741 - val_loss: 219.6934 - val_mae: 3.6127\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.0649 - mae: 1.5268 - val_loss: 329.9412 - val_mae: 4.0687\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.0822 - mae: 1.6122 - val_loss: 184.2982 - val_mae: 3.3670\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.4689 - mae: 1.4979 - val_loss: 212.7676 - val_mae: 3.4589\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.1488 - mae: 1.6552 - val_loss: 254.2993 - val_mae: 3.6705\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.1560 - mae: 1.6188 - val_loss: 245.9778 - val_mae: 3.6570\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.2159 - mae: 1.7247 - val_loss: 237.1936 - val_mae: 3.7058\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.6800 - mae: 1.5763 - val_loss: 134.3961 - val_mae: 2.9846\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.6463 - mae: 1.5329 - val_loss: 175.7435 - val_mae: 3.3322\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.2113 - mae: 1.5642 - val_loss: 209.5460 - val_mae: 3.4899\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.6106 - mae: 1.5501 - val_loss: 246.2134 - val_mae: 3.6474\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.6045 - mae: 1.6214 - val_loss: 205.8121 - val_mae: 3.4691\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.6375 - mae: 1.5359 - val_loss: 272.4778 - val_mae: 3.8059\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.0501 - mae: 1.5150 - val_loss: 224.2159 - val_mae: 3.5902\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8954 - mae: 1.3813 - val_loss: 178.7982 - val_mae: 3.3302\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4730 - mae: 1.4530 - val_loss: 218.0485 - val_mae: 3.5314\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1960 - mae: 1.4702 - val_loss: 230.2745 - val_mae: 3.5853\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.9375 - mae: 1.8081 - val_loss: 382.0726 - val_mae: 4.1727\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.0110 - mae: 1.8023 - val_loss: 249.5686 - val_mae: 3.6223\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.8283 - mae: 1.6148 - val_loss: 195.2716 - val_mae: 3.3962\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.5158 - mae: 1.5818 - val_loss: 285.8975 - val_mae: 3.8182\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5753 - mae: 1.3559 - val_loss: 203.1950 - val_mae: 3.3802\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9269 - mae: 1.4395 - val_loss: 179.4616 - val_mae: 3.2840\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.8581 - mae: 1.5604 - val_loss: 184.1093 - val_mae: 3.3395\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.7991 - mae: 1.6821 - val_loss: 363.8643 - val_mae: 4.1259\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.4812 - mae: 1.4425 - val_loss: 192.0035 - val_mae: 3.3966\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2041 - mae: 1.3550 - val_loss: 263.9807 - val_mae: 3.7055\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.9799 - mae: 1.5655 - val_loss: 195.7584 - val_mae: 3.4146\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4240 - mae: 1.4174 - val_loss: 258.4035 - val_mae: 3.7242\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.6676 - mae: 1.4786 - val_loss: 285.5085 - val_mae: 3.8693\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7032 - mae: 1.4791 - val_loss: 195.7597 - val_mae: 3.4060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.6199 - mae: 1.4490 - val_loss: 199.8064 - val_mae: 3.4250\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.9268 - mae: 1.4109 - val_loss: 199.0881 - val_mae: 3.3981\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8279 - mae: 1.3754 - val_loss: 157.6020 - val_mae: 3.1543\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.4826 - mae: 1.3760 - val_loss: 258.7426 - val_mae: 3.7226\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5423 - mae: 1.3291 - val_loss: 183.4734 - val_mae: 3.2924\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4555 - mae: 1.3182 - val_loss: 143.2671 - val_mae: 3.0206\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.0524 - mae: 1.5438 - val_loss: 203.5893 - val_mae: 3.4428\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6714 - mae: 1.1796 - val_loss: 192.0316 - val_mae: 3.3812\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7034 - mae: 1.2555 - val_loss: 304.0368 - val_mae: 3.8921\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.9050 - mae: 1.4246 - val_loss: 212.3914 - val_mae: 3.4763\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.1642 - mae: 1.5187 - val_loss: 186.0117 - val_mae: 3.3440\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4419 - mae: 1.4178 - val_loss: 266.1391 - val_mae: 3.7098\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.2259 - mae: 1.3639 - val_loss: 137.4817 - val_mae: 2.9595\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.5317 - mae: 1.3582 - val_loss: 243.9277 - val_mae: 3.5957\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.9648 - mae: 1.4928 - val_loss: 229.7140 - val_mae: 3.5261\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7585 - mae: 1.4005 - val_loss: 198.2825 - val_mae: 3.4121\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3216 - mae: 1.4337 - val_loss: 231.3310 - val_mae: 3.5371\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.9176 - mae: 1.3265 - val_loss: 256.3909 - val_mae: 3.6577\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.3523 - mae: 1.4264 - val_loss: 143.0687 - val_mae: 2.9956\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.4542 - mae: 1.5036 - val_loss: 132.4039 - val_mae: 2.8597\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.7425 - mae: 1.3030 - val_loss: 150.0064 - val_mae: 3.0144\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6989 - mae: 1.3204 - val_loss: 172.5298 - val_mae: 3.2178\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.9938 - mae: 1.4062 - val_loss: 220.6678 - val_mae: 3.5282\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5746 - mae: 1.4265 - val_loss: 215.2525 - val_mae: 3.4947\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1958 - mae: 1.2219 - val_loss: 218.1365 - val_mae: 3.4901\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3167 - mae: 1.2696 - val_loss: 169.0561 - val_mae: 3.1855\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1279 - mae: 1.2920 - val_loss: 164.2192 - val_mae: 3.1452\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 68.4135 - mae: 1.6249 - val_loss: 179.4736 - val_mae: 3.2895\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5944 - mae: 1.1933 - val_loss: 298.3376 - val_mae: 3.8893\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6655 - mae: 1.4017 - val_loss: 157.9763 - val_mae: 3.1679\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7322 - mae: 1.3584 - val_loss: 177.7306 - val_mae: 3.2707\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.8491 - mae: 1.4772 - val_loss: 261.6574 - val_mae: 3.7810\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 62.8169 - mae: 1.5922 - val_loss: 136.4732 - val_mae: 2.9556\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.4455 - mae: 1.4765 - val_loss: 229.6743 - val_mae: 3.6230\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8111 - mae: 1.3135 - val_loss: 203.7965 - val_mae: 3.4406\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8707 - mae: 1.2750 - val_loss: 294.6279 - val_mae: 3.8825\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6885 - mae: 1.2541 - val_loss: 209.0767 - val_mae: 3.4845\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6201 - mae: 1.3084 - val_loss: 213.4838 - val_mae: 3.4515\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.6470 - mae: 1.3085 - val_loss: 202.5174 - val_mae: 3.3711\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8520 - mae: 1.1961 - val_loss: 174.6750 - val_mae: 3.1886\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.7861 - mae: 1.1365 - val_loss: 206.9179 - val_mae: 3.4369\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.1717 - mae: 1.3066 - val_loss: 230.8844 - val_mae: 3.5392\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.5394 - mae: 1.1995 - val_loss: 186.8000 - val_mae: 3.2827\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 16.2867 - mae: 1.2966 - val_loss: 264.9890 - val_mae: 3.6623\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.0072 - mae: 1.3022 - val_loss: 176.1050 - val_mae: 3.2323\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.5011 - mae: 1.2629 - val_loss: 177.2664 - val_mae: 3.2499\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.5285 - mae: 1.4675 - val_loss: 134.9068 - val_mae: 2.8593\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8285 - mae: 1.2570 - val_loss: 234.5139 - val_mae: 3.6051\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.9633 - mae: 1.3721 - val_loss: 244.8654 - val_mae: 3.6648\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.8787 - mae: 1.0480 - val_loss: 222.1374 - val_mae: 3.5374\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.3375 - mae: 1.2004 - val_loss: 165.2902 - val_mae: 3.1564\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.8031 - mae: 1.3992 - val_loss: 145.8897 - val_mae: 3.0073\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2149 - mae: 1.4166 - val_loss: 183.8426 - val_mae: 3.2824\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1574 - mae: 1.1644 - val_loss: 213.4782 - val_mae: 3.4493\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.1202 - mae: 1.2319 - val_loss: 190.0391 - val_mae: 3.3623\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.9450 - mae: 1.2648 - val_loss: 233.6938 - val_mae: 3.5956\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.9451 - mae: 1.4806 - val_loss: 156.2922 - val_mae: 3.0527\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.4194 - mae: 1.2650 - val_loss: 194.5853 - val_mae: 3.3012\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 36.4427 - mae: 1.4665 - val_loss: 260.0517 - val_mae: 3.6820\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.6982 - mae: 1.3581 - val_loss: 170.0932 - val_mae: 3.1890\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0243 - mae: 1.2594 - val_loss: 201.5029 - val_mae: 3.4112\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.0927 - mae: 1.1833 - val_loss: 198.5513 - val_mae: 3.3461\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6296 - mae: 1.1872 - val_loss: 187.4177 - val_mae: 3.2626\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1974 - mae: 1.2743 - val_loss: 226.1960 - val_mae: 3.5412\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0444 - mae: 1.1981 - val_loss: 184.4737 - val_mae: 3.2487\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4868 - mae: 1.2448 - val_loss: 194.3235 - val_mae: 3.2980\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4072 - mae: 1.2307 - val_loss: 131.6331 - val_mae: 2.8304\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3116 - mae: 1.3448 - val_loss: 154.3660 - val_mae: 2.9881\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7237 - mae: 1.1474 - val_loss: 166.1266 - val_mae: 3.1336\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4473 - mae: 1.1666 - val_loss: 201.9647 - val_mae: 3.3395\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4594 - mae: 1.2899 - val_loss: 192.6873 - val_mae: 3.3230\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.9836 - mae: 1.3441 - val_loss: 242.0426 - val_mae: 3.5797\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8167 - mae: 1.2217 - val_loss: 192.0974 - val_mae: 3.3240\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.4210 - mae: 1.2375 - val_loss: 157.9358 - val_mae: 3.0963\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8655 - mae: 1.3059 - val_loss: 286.0932 - val_mae: 3.8271\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.4103 - mae: 1.2410 - val_loss: 256.2869 - val_mae: 3.6888\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5876 - mae: 1.2040 - val_loss: 173.0443 - val_mae: 3.1959\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4520 - mae: 1.3938 - val_loss: 188.8220 - val_mae: 3.3039\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.2714 - mae: 1.1131 - val_loss: 200.9880 - val_mae: 3.3098\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2252 - mae: 1.1821 - val_loss: 166.4251 - val_mae: 3.1129\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7219 - mae: 1.2529 - val_loss: 213.9773 - val_mae: 3.4522\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2096 - mae: 1.3164 - val_loss: 173.4099 - val_mae: 3.1351\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8350 - mae: 1.2764 - val_loss: 207.5569 - val_mae: 3.4109\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.2252 - mae: 1.1636 - val_loss: 205.2540 - val_mae: 3.3735\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5187 - mae: 1.1871 - val_loss: 185.6570 - val_mae: 3.2561\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.1219 - mae: 1.2708 - val_loss: 274.1833 - val_mae: 3.7442\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 13.9283 - mae: 1.2334 - val_loss: 188.8287 - val_mae: 3.3222\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9605 - mae: 1.1425 - val_loss: 237.2289 - val_mae: 3.6293\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7786 - mae: 1.2893 - val_loss: 198.2489 - val_mae: 3.3795\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.2467 - mae: 1.0723 - val_loss: 182.2168 - val_mae: 3.2045\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6285 - mae: 1.1625 - val_loss: 178.3048 - val_mae: 3.1953\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9994 - mae: 1.0792 - val_loss: 256.2380 - val_mae: 3.6582\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3515 - mae: 1.3215 - val_loss: 185.2375 - val_mae: 3.2607\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.2282 - mae: 1.0464 - val_loss: 154.3471 - val_mae: 3.0010\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.7833 - mae: 1.1914 - val_loss: 240.5498 - val_mae: 3.5978\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.3918 - mae: 1.2636 - val_loss: 168.7265 - val_mae: 3.1168\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7373 - mae: 1.2412 - val_loss: 206.5022 - val_mae: 3.4166\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.5660 - mae: 1.1132 - val_loss: 159.8420 - val_mae: 3.0860\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.5245 - mae: 1.2227 - val_loss: 202.2465 - val_mae: 3.3711\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5378 - mae: 1.3812 - val_loss: 193.2057 - val_mae: 3.2911\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.0369 - mae: 1.1023 - val_loss: 295.8188 - val_mae: 3.9412\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.3792 - mae: 1.2890 - val_loss: 209.8555 - val_mae: 3.4448\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4224 - mae: 1.1501 - val_loss: 262.0628 - val_mae: 3.7637\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8509 - mae: 1.1789 - val_loss: 192.1497 - val_mae: 3.3289\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.6312 - mae: 1.2920 - val_loss: 179.8555 - val_mae: 3.2406\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8121 - mae: 1.2205 - val_loss: 176.3662 - val_mae: 3.1988\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.1997 - mae: 1.1105 - val_loss: 190.8434 - val_mae: 3.2617\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.4317 - mae: 1.0593 - val_loss: 179.1101 - val_mae: 3.2498\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.3599 - mae: 1.1451 - val_loss: 247.7630 - val_mae: 3.6583\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6586 - mae: 1.3130 - val_loss: 219.6278 - val_mae: 3.5024\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9831 - mae: 1.0827 - val_loss: 247.9769 - val_mae: 3.7068\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.9883 - mae: 1.3262 - val_loss: 206.6403 - val_mae: 3.4673\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0210 - mae: 1.1552 - val_loss: 233.3891 - val_mae: 3.6156\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5772 - mae: 1.3224 - val_loss: 225.2227 - val_mae: 3.5871\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.7268 - mae: 1.1239 - val_loss: 250.7833 - val_mae: 3.7125\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.7095 - mae: 1.0864 - val_loss: 185.3257 - val_mae: 3.2618\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8455 - mae: 1.2028 - val_loss: 217.4820 - val_mae: 3.5269\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8575 - mae: 1.1859 - val_loss: 208.9301 - val_mae: 3.4677\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 2s 4ms/step - loss: 17.9368 - mae: 1.1678 - val_loss: 126.6976 - val_mae: 2.7273\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 15.5590 - mae: 1.1861 - val_loss: 150.6912 - val_mae: 2.9859\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 18.8053 - mae: 1.2399 - val_loss: 271.0685 - val_mae: 3.8508\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.3247 - mae: 1.1918 - val_loss: 133.4830 - val_mae: 2.7746\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7060 - mae: 1.2315 - val_loss: 233.4308 - val_mae: 3.5888\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 16.1236 - mae: 1.1596 - val_loss: 187.3588 - val_mae: 3.2546\n",
      ">11, MAE: 1.892\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 412.1910 - mae: 4.8509 - val_loss: 399.2941 - val_mae: 5.1652\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 359.6615 - mae: 4.0623 - val_loss: 120.6836 - val_mae: 2.9282\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 149.5081 - mae: 3.2949 - val_loss: 458.2180 - val_mae: 5.6260\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 187.4331 - mae: 3.3945 - val_loss: 130.2954 - val_mae: 3.3274\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 167.5237 - mae: 3.1422 - val_loss: 478.2899 - val_mae: 5.4166\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 148.2192 - mae: 3.0744 - val_loss: 204.3814 - val_mae: 3.8019\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 115.0046 - mae: 2.7747 - val_loss: 320.7163 - val_mae: 4.2874\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 110.2237 - mae: 2.6809 - val_loss: 437.9268 - val_mae: 4.4621\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 76.2112 - mae: 2.4646 - val_loss: 327.4998 - val_mae: 3.8360\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 75.9721 - mae: 2.3963 - val_loss: 269.0502 - val_mae: 3.5350\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 77.9152 - mae: 2.3406 - val_loss: 389.9847 - val_mae: 3.8851\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.7928 - mae: 2.0811 - val_loss: 615.7816 - val_mae: 4.6743\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 50.6459 - mae: 2.0486 - val_loss: 727.8443 - val_mae: 5.1561\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 69.4389 - mae: 2.3082 - val_loss: 601.8468 - val_mae: 4.7952\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.8735 - mae: 2.2032 - val_loss: 475.7087 - val_mae: 4.1666\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.4357 - mae: 2.0158 - val_loss: 502.0141 - val_mae: 4.2456\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 63.7334 - mae: 2.1712 - val_loss: 326.7462 - val_mae: 3.6352\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 62.8355 - mae: 2.2001 - val_loss: 590.2807 - val_mae: 4.4780\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 59.8625 - mae: 2.1249 - val_loss: 482.5294 - val_mae: 4.0784\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.5863 - mae: 1.9655 - val_loss: 525.5767 - val_mae: 4.2718\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.6862 - mae: 1.8692 - val_loss: 527.2690 - val_mae: 4.2992\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.7424 - mae: 1.8389 - val_loss: 711.0645 - val_mae: 4.9739\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.5053 - mae: 1.9840 - val_loss: 599.1383 - val_mae: 4.5166\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.8611 - mae: 1.9840 - val_loss: 576.1560 - val_mae: 4.4424\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.7151 - mae: 2.0190 - val_loss: 591.3347 - val_mae: 4.5820\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 63.5325 - mae: 2.2222 - val_loss: 533.1198 - val_mae: 4.3571\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.6714 - mae: 1.8400 - val_loss: 519.1108 - val_mae: 4.3753\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.2980 - mae: 1.8536 - val_loss: 426.9974 - val_mae: 4.0075\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.0570 - mae: 1.8561 - val_loss: 486.8288 - val_mae: 4.2233\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.7248 - mae: 1.7133 - val_loss: 397.9913 - val_mae: 3.9374\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.8178 - mae: 1.7757 - val_loss: 347.6546 - val_mae: 3.8400\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 46.8859 - mae: 2.0270 - val_loss: 527.1396 - val_mae: 4.4322\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.9431 - mae: 1.8371 - val_loss: 363.3910 - val_mae: 3.9552\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.0896 - mae: 1.7509 - val_loss: 534.0652 - val_mae: 4.4690\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.6282 - mae: 1.9130 - val_loss: 456.1449 - val_mae: 4.0929\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.5194 - mae: 1.7171 - val_loss: 485.5614 - val_mae: 4.1912\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.7118 - mae: 1.8214 - val_loss: 423.6650 - val_mae: 3.9584\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.1566 - mae: 1.7170 - val_loss: 334.2834 - val_mae: 3.6492\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.3091 - mae: 1.7188 - val_loss: 475.2486 - val_mae: 4.2017\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.2241 - mae: 1.6692 - val_loss: 402.7430 - val_mae: 3.9247\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.3116 - mae: 1.6537 - val_loss: 460.5080 - val_mae: 4.0794\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.6443 - mae: 1.7882 - val_loss: 362.9320 - val_mae: 3.8176\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.5896 - mae: 1.6071 - val_loss: 457.0347 - val_mae: 4.1134\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.4832 - mae: 1.6806 - val_loss: 520.8929 - val_mae: 4.3243\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 59.6223 - mae: 1.6937 - val_loss: 681.2939 - val_mae: 5.0276\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.0472 - mae: 1.6962 - val_loss: 504.3057 - val_mae: 4.2597\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.6359 - mae: 1.7267 - val_loss: 658.6023 - val_mae: 4.8160\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.7350 - mae: 1.7180 - val_loss: 379.1495 - val_mae: 3.8169\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.8575 - mae: 1.6081 - val_loss: 645.1135 - val_mae: 4.7226\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.6353 - mae: 1.8233 - val_loss: 407.4720 - val_mae: 3.9162\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.0473 - mae: 1.5452 - val_loss: 656.8993 - val_mae: 4.7764\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.3801 - mae: 1.8299 - val_loss: 374.0434 - val_mae: 3.7843\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.2906 - mae: 1.7212 - val_loss: 484.7883 - val_mae: 4.1633\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.0201 - mae: 1.6345 - val_loss: 432.5713 - val_mae: 3.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.6951 - mae: 1.5554 - val_loss: 426.0817 - val_mae: 3.9574\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.6071 - mae: 1.7125 - val_loss: 623.4033 - val_mae: 4.6998\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.9906 - mae: 1.5842 - val_loss: 346.5558 - val_mae: 3.7417\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.2908 - mae: 1.7706 - val_loss: 579.2429 - val_mae: 4.5934\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.5371 - mae: 1.5327 - val_loss: 530.7516 - val_mae: 4.3858\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8954 - mae: 1.4161 - val_loss: 458.0918 - val_mae: 4.1144\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.7322 - mae: 1.8644 - val_loss: 431.8614 - val_mae: 3.9610\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4186 - mae: 1.5696 - val_loss: 332.1967 - val_mae: 3.7113\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.5089 - mae: 1.4904 - val_loss: 292.3737 - val_mae: 3.5057\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.6241 - mae: 1.8190 - val_loss: 485.9411 - val_mae: 4.2839\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.4006 - mae: 1.7182 - val_loss: 314.3043 - val_mae: 3.6194\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.7271 - mae: 1.7178 - val_loss: 454.1474 - val_mae: 4.0979\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.7020 - mae: 1.5582 - val_loss: 375.5974 - val_mae: 3.8347\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7868 - mae: 1.5061 - val_loss: 438.1351 - val_mae: 4.0296\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.4054 - mae: 1.6809 - val_loss: 388.1353 - val_mae: 3.7933\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.6281 - mae: 1.4229 - val_loss: 405.0166 - val_mae: 3.8905\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.9836 - mae: 1.5649 - val_loss: 379.1935 - val_mae: 3.8320\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.9380 - mae: 1.6900 - val_loss: 345.4672 - val_mae: 3.7485\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7309 - mae: 1.6276 - val_loss: 534.9534 - val_mae: 4.4606\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.5128 - mae: 1.5470 - val_loss: 406.0879 - val_mae: 4.0632\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.3593 - mae: 1.3915 - val_loss: 428.4481 - val_mae: 4.0925\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.8320 - mae: 1.6753 - val_loss: 545.9225 - val_mae: 4.4391\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.6024 - mae: 1.8031 - val_loss: 414.5074 - val_mae: 4.0920\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.6669 - mae: 1.4413 - val_loss: 368.5972 - val_mae: 3.9775\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.3174 - mae: 1.5328 - val_loss: 550.1179 - val_mae: 4.6749\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.6795 - mae: 1.5732 - val_loss: 307.0542 - val_mae: 3.8087\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.3184 - mae: 1.5062 - val_loss: 494.6656 - val_mae: 4.4296\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.0132 - mae: 1.5181 - val_loss: 377.1190 - val_mae: 3.9703\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5135 - mae: 1.3818 - val_loss: 414.1752 - val_mae: 4.1177\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 37.4405 - mae: 1.5551 - val_loss: 397.7110 - val_mae: 4.0895\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.2744 - mae: 1.4914 - val_loss: 280.5347 - val_mae: 3.6708\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.0513 - mae: 1.5854 - val_loss: 508.3224 - val_mae: 4.4449\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.9565 - mae: 1.4851 - val_loss: 410.1951 - val_mae: 4.0985\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.7416 - mae: 1.4892 - val_loss: 395.7021 - val_mae: 4.0418\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.0007 - mae: 1.4129 - val_loss: 373.5587 - val_mae: 3.9370\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8527 - mae: 1.3901 - val_loss: 583.9658 - val_mae: 4.6797\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.2820 - mae: 1.3700 - val_loss: 458.1298 - val_mae: 4.2309\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.2789 - mae: 1.4108 - val_loss: 403.2649 - val_mae: 4.0052\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.7562 - mae: 1.5121 - val_loss: 399.7612 - val_mae: 3.9951\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4118 - mae: 1.2587 - val_loss: 295.5233 - val_mae: 3.6567\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5196 - mae: 1.3276 - val_loss: 410.3090 - val_mae: 4.0547\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6201 - mae: 1.4118 - val_loss: 414.5300 - val_mae: 4.0015\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.9027 - mae: 1.3063 - val_loss: 390.1695 - val_mae: 3.9398\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8120 - mae: 1.2548 - val_loss: 357.1284 - val_mae: 3.8386\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.5175 - mae: 1.4980 - val_loss: 356.9930 - val_mae: 3.8732\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.8883 - mae: 1.3860 - val_loss: 369.7317 - val_mae: 3.8878\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6165 - mae: 1.2891 - val_loss: 301.1805 - val_mae: 3.6786\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.5444 - mae: 1.3462 - val_loss: 406.1694 - val_mae: 4.0296\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3651 - mae: 1.3144 - val_loss: 482.8278 - val_mae: 4.2891\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.3321 - mae: 1.4288 - val_loss: 336.7541 - val_mae: 3.7988\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.4953 - mae: 1.3390 - val_loss: 298.5503 - val_mae: 3.6818\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.4525 - mae: 1.2622 - val_loss: 268.5551 - val_mae: 3.5563\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3861 - mae: 1.2369 - val_loss: 335.1904 - val_mae: 3.7819\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7726 - mae: 1.4372 - val_loss: 367.1894 - val_mae: 3.9233\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1934 - mae: 1.2264 - val_loss: 438.9294 - val_mae: 4.1362\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4420 - mae: 1.3848 - val_loss: 360.7959 - val_mae: 3.8902\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.8415 - mae: 1.5047 - val_loss: 466.9695 - val_mae: 4.2450\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4888 - mae: 1.3135 - val_loss: 427.2612 - val_mae: 4.0700\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.7484 - mae: 1.5211 - val_loss: 283.9435 - val_mae: 3.5715\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.7316 - mae: 1.3739 - val_loss: 430.3367 - val_mae: 4.1072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.9178 - mae: 1.4777 - val_loss: 371.6209 - val_mae: 3.8696\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.4211 - mae: 1.3605 - val_loss: 363.2378 - val_mae: 3.8079\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.9397 - mae: 1.1671 - val_loss: 416.6339 - val_mae: 4.0128\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.3401 - mae: 1.5180 - val_loss: 397.3322 - val_mae: 3.9374\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0902 - mae: 1.2184 - val_loss: 360.8618 - val_mae: 3.8515\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.2326 - mae: 1.2810 - val_loss: 294.9598 - val_mae: 3.6282\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3508 - mae: 1.3387 - val_loss: 393.8119 - val_mae: 3.9373\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2528 - mae: 1.1808 - val_loss: 335.5356 - val_mae: 3.7196\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6723 - mae: 1.2789 - val_loss: 364.9697 - val_mae: 3.8884\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.8017 - mae: 1.2743 - val_loss: 319.4392 - val_mae: 3.6940\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3129 - mae: 1.2756 - val_loss: 426.7957 - val_mae: 4.0494\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.3172 - mae: 1.4068 - val_loss: 246.8856 - val_mae: 3.4129\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5533 - mae: 1.2818 - val_loss: 291.2358 - val_mae: 3.6351\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.8451 - mae: 1.3725 - val_loss: 423.5948 - val_mae: 4.0649\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9882 - mae: 1.2704 - val_loss: 317.1529 - val_mae: 3.7007\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1636 - mae: 1.2631 - val_loss: 286.5241 - val_mae: 3.5715\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4638 - mae: 1.3001 - val_loss: 216.7670 - val_mae: 3.2470\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8149 - mae: 1.2877 - val_loss: 316.7281 - val_mae: 3.6635\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.3263 - mae: 1.2418 - val_loss: 340.5660 - val_mae: 3.7673\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.6941 - mae: 1.2384 - val_loss: 386.7142 - val_mae: 3.9305\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4469 - mae: 1.2592 - val_loss: 382.0635 - val_mae: 3.9735\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.4772 - mae: 1.2419 - val_loss: 301.4930 - val_mae: 3.6633\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.7671 - mae: 1.2119 - val_loss: 338.4987 - val_mae: 3.8143\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2490 - mae: 1.2375 - val_loss: 396.4886 - val_mae: 4.0758\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4110 - mae: 1.3510 - val_loss: 396.8375 - val_mae: 3.9726\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5989 - mae: 1.1915 - val_loss: 324.7422 - val_mae: 3.7613\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.7544 - mae: 1.3214 - val_loss: 258.4378 - val_mae: 3.4560\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6697 - mae: 1.2750 - val_loss: 325.7760 - val_mae: 3.7941\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.6647 - mae: 1.5758 - val_loss: 292.3796 - val_mae: 3.6739\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6519 - mae: 1.2235 - val_loss: 268.3167 - val_mae: 3.5413\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.2624 - mae: 1.4157 - val_loss: 198.1379 - val_mae: 3.2163\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0426 - mae: 1.2411 - val_loss: 213.1326 - val_mae: 3.3096\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8335 - mae: 1.2726 - val_loss: 329.9399 - val_mae: 3.7816\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.9634 - mae: 1.3381 - val_loss: 266.1584 - val_mae: 3.6024\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5845 - mae: 1.2851 - val_loss: 320.4691 - val_mae: 3.8373\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.9040 - mae: 1.1289 - val_loss: 238.0824 - val_mae: 3.4532\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.5013 - mae: 1.3150 - val_loss: 374.0819 - val_mae: 3.9963\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1013 - mae: 1.0879 - val_loss: 321.6740 - val_mae: 3.8128\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7876 - mae: 1.1934 - val_loss: 356.8956 - val_mae: 3.8922\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.4919 - mae: 1.3384 - val_loss: 233.6625 - val_mae: 3.4146\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0592 - mae: 1.1053 - val_loss: 305.7490 - val_mae: 3.6993\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.3714 - mae: 1.3047 - val_loss: 323.2884 - val_mae: 3.6998\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.9415 - mae: 1.1359 - val_loss: 262.2794 - val_mae: 3.4905\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.8159 - mae: 1.2451 - val_loss: 300.4003 - val_mae: 3.6324\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0388 - mae: 1.1099 - val_loss: 320.6877 - val_mae: 3.7172\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1332 - mae: 1.2215 - val_loss: 314.8823 - val_mae: 3.6442\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.0155 - mae: 1.1732 - val_loss: 342.6217 - val_mae: 3.7642\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.0779 - mae: 1.2935 - val_loss: 356.7888 - val_mae: 3.8281\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.4912 - mae: 1.1551 - val_loss: 234.8371 - val_mae: 3.3771\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.8618 - mae: 1.2125 - val_loss: 354.3970 - val_mae: 3.8230\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.6012 - mae: 1.1127 - val_loss: 336.3391 - val_mae: 3.8491\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.3517 - mae: 1.1870 - val_loss: 248.9523 - val_mae: 3.4623\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.4734 - mae: 1.2220 - val_loss: 324.5027 - val_mae: 3.7742\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.6172 - mae: 1.2377 - val_loss: 374.9181 - val_mae: 3.9538\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0153 - mae: 1.1681 - val_loss: 287.4334 - val_mae: 3.6086\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.1103 - mae: 1.0041 - val_loss: 322.8256 - val_mae: 3.7791\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.8137 - mae: 1.1514 - val_loss: 300.2737 - val_mae: 3.6817\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.8006 - mae: 1.2222 - val_loss: 211.4132 - val_mae: 3.2867\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.9004 - mae: 1.3049 - val_loss: 350.2288 - val_mae: 3.9459\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5313 - mae: 1.3213 - val_loss: 280.4087 - val_mae: 3.6478\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8843 - mae: 1.2559 - val_loss: 252.7888 - val_mae: 3.5701\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.8719 - mae: 1.2005 - val_loss: 295.6588 - val_mae: 3.7094\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 10.9592 - mae: 0.9984 - val_loss: 317.4226 - val_mae: 3.8082\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5689 - mae: 1.2509 - val_loss: 316.7289 - val_mae: 3.8240\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3955 - mae: 1.0812 - val_loss: 263.9542 - val_mae: 3.5775\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.2473 - mae: 1.0998 - val_loss: 255.4629 - val_mae: 3.5261\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.5380 - mae: 1.1190 - val_loss: 320.1331 - val_mae: 3.8071\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2525 - mae: 1.1835 - val_loss: 339.9144 - val_mae: 3.8881\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0204 - mae: 1.0683 - val_loss: 399.8791 - val_mae: 4.0391\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.7556 - mae: 1.2669 - val_loss: 424.7209 - val_mae: 4.0967\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1799 - mae: 1.2573 - val_loss: 198.4080 - val_mae: 3.2456\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5717 - mae: 1.1770 - val_loss: 280.6942 - val_mae: 3.5375\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0293 - mae: 1.1503 - val_loss: 221.4400 - val_mae: 3.2939\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4235 - mae: 1.1872 - val_loss: 332.3660 - val_mae: 3.7919\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8488 - mae: 1.0194 - val_loss: 267.5279 - val_mae: 3.5265\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1515 - mae: 1.1621 - val_loss: 380.8185 - val_mae: 3.9500\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.0292 - mae: 1.0027 - val_loss: 389.6544 - val_mae: 4.0087\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1333 - mae: 1.1789 - val_loss: 256.4051 - val_mae: 3.5510\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3845 - mae: 1.2086 - val_loss: 353.7900 - val_mae: 3.9364\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0131 - mae: 1.1885 - val_loss: 353.1790 - val_mae: 3.9696\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8296 - mae: 1.2400 - val_loss: 279.8279 - val_mae: 3.7405\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.7625 - mae: 1.1433 - val_loss: 390.0583 - val_mae: 4.1376\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5970 - mae: 1.2571 - val_loss: 449.0636 - val_mae: 4.3292\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3008 - mae: 1.1293 - val_loss: 254.4395 - val_mae: 3.6010\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.1649 - mae: 1.0167 - val_loss: 336.1777 - val_mae: 3.8851\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3290 - mae: 1.0693 - val_loss: 278.9791 - val_mae: 3.6276\n",
      ">12, MAE: 2.466\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 368.3365 - mae: 4.4986 - val_loss: 117.5245 - val_mae: 2.9314\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 100.9055 - mae: 2.8087 - val_loss: 401.3951 - val_mae: 4.8917\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 159.8749 - mae: 3.1261 - val_loss: 162.1055 - val_mae: 3.2841\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 113.2737 - mae: 2.5016 - val_loss: 124.6207 - val_mae: 3.0216\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 98.2069 - mae: 2.4920 - val_loss: 127.9161 - val_mae: 3.0291\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 153.7336 - mae: 2.8457 - val_loss: 335.8680 - val_mae: 3.9645\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 103.0253 - mae: 2.4712 - val_loss: 289.2840 - val_mae: 3.5910\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.9784 - mae: 1.8120 - val_loss: 385.4992 - val_mae: 3.8998\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.9096 - mae: 2.0302 - val_loss: 559.9672 - val_mae: 4.5638\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 68.6747 - mae: 2.1556 - val_loss: 525.9074 - val_mae: 4.4052\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.4032 - mae: 2.0414 - val_loss: 545.2856 - val_mae: 4.4571\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 74.2204 - mae: 2.1497 - val_loss: 352.7271 - val_mae: 3.6321\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.8485 - mae: 1.9690 - val_loss: 317.7066 - val_mae: 3.5481\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 61.4557 - mae: 2.1446 - val_loss: 568.3865 - val_mae: 4.3335\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.1790 - mae: 1.9518 - val_loss: 672.0193 - val_mae: 4.6990\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.5438 - mae: 2.0571 - val_loss: 407.1272 - val_mae: 3.7963\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.2077 - mae: 1.8232 - val_loss: 505.6392 - val_mae: 4.1978\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.3257 - mae: 2.0438 - val_loss: 365.0362 - val_mae: 3.7455\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 62.9542 - mae: 2.0260 - val_loss: 489.3265 - val_mae: 4.1505\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.0035 - mae: 1.9158 - val_loss: 461.2013 - val_mae: 4.0712\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.8643 - mae: 1.9651 - val_loss: 597.7571 - val_mae: 4.5527\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.4067 - mae: 1.7822 - val_loss: 483.0253 - val_mae: 4.1541\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.2848 - mae: 1.6159 - val_loss: 342.4065 - val_mae: 3.6109\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.1213 - mae: 1.7607 - val_loss: 501.1641 - val_mae: 4.2400\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1398 - mae: 1.5418 - val_loss: 525.9534 - val_mae: 4.3422\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.6278 - mae: 1.6966 - val_loss: 436.5629 - val_mae: 4.0594\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6468 - mae: 1.5261 - val_loss: 357.2678 - val_mae: 3.8886\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.6442 - mae: 1.5876 - val_loss: 435.2028 - val_mae: 4.0779\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.6807 - mae: 1.8079 - val_loss: 363.7704 - val_mae: 3.7256\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.6011 - mae: 1.7464 - val_loss: 386.1860 - val_mae: 3.9277\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.1351 - mae: 1.7153 - val_loss: 421.8391 - val_mae: 3.8905\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4132 - mae: 1.5018 - val_loss: 308.6156 - val_mae: 3.6958\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 28.4114 - mae: 1.5517 - val_loss: 412.8621 - val_mae: 3.9595\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.3849 - mae: 1.5914 - val_loss: 409.5249 - val_mae: 4.0298\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.5721 - mae: 1.6268 - val_loss: 540.5836 - val_mae: 4.4609\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.4728 - mae: 1.7613 - val_loss: 282.4720 - val_mae: 3.5459\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.9218 - mae: 1.6827 - val_loss: 254.3326 - val_mae: 3.4056\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9788 - mae: 1.4683 - val_loss: 278.4375 - val_mae: 3.4457\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.6538 - mae: 1.5290 - val_loss: 602.5364 - val_mae: 4.6745\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.9423 - mae: 1.7020 - val_loss: 331.3449 - val_mae: 3.7704\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5916 - mae: 1.5047 - val_loss: 272.3820 - val_mae: 3.5762\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.1385 - mae: 1.6393 - val_loss: 338.4131 - val_mae: 3.8021\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.5822 - mae: 1.6065 - val_loss: 248.3026 - val_mae: 3.5034\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.9628 - mae: 1.6551 - val_loss: 305.2279 - val_mae: 3.7511\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.4472 - mae: 1.6904 - val_loss: 391.8366 - val_mae: 4.0030\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.8010 - mae: 1.4966 - val_loss: 401.7115 - val_mae: 3.9477\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.8211 - mae: 1.6795 - val_loss: 363.8654 - val_mae: 3.9078\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3123 - mae: 1.4991 - val_loss: 668.0752 - val_mae: 4.9686\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.8993 - mae: 1.6087 - val_loss: 299.4861 - val_mae: 3.7776\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.3914 - mae: 1.5289 - val_loss: 242.8227 - val_mae: 3.4809\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4021 - mae: 1.4712 - val_loss: 346.9290 - val_mae: 3.9423\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.2413 - mae: 1.4268 - val_loss: 353.2250 - val_mae: 3.9556\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.1231 - mae: 1.5673 - val_loss: 392.6591 - val_mae: 4.0633\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.7515 - mae: 1.5797 - val_loss: 274.3662 - val_mae: 3.6194\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 36.0251 - mae: 1.6145 - val_loss: 210.9558 - val_mae: 3.3683\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.5804 - mae: 1.5449 - val_loss: 367.6570 - val_mae: 3.9576\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.0364 - mae: 1.4683 - val_loss: 220.4032 - val_mae: 3.4134\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.8072 - mae: 1.6195 - val_loss: 508.6924 - val_mae: 4.4427\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.4471 - mae: 1.6819 - val_loss: 161.9124 - val_mae: 3.0975\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 60.4572 - mae: 1.6850 - val_loss: 761.6369 - val_mae: 5.6536\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.1712 - mae: 1.5347 - val_loss: 266.9300 - val_mae: 3.5779\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1852 - mae: 1.4271 - val_loss: 318.1320 - val_mae: 3.8200\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 25.6567 - mae: 1.4706 - val_loss: 147.6671 - val_mae: 2.9606\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 34.2025 - mae: 1.5647 - val_loss: 253.1499 - val_mae: 3.5401\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.0515 - mae: 1.4931 - val_loss: 204.3806 - val_mae: 3.3201\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 42.7262 - mae: 1.5538 - val_loss: 357.3177 - val_mae: 3.8844\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1979 - mae: 1.3211 - val_loss: 221.7973 - val_mae: 3.4029\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.9135 - mae: 1.3598 - val_loss: 293.8568 - val_mae: 3.7378\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5723 - mae: 1.2346 - val_loss: 323.5038 - val_mae: 3.8513\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.2615 - mae: 1.3900 - val_loss: 312.9539 - val_mae: 3.8279\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.1307 - mae: 1.5527 - val_loss: 267.1094 - val_mae: 3.6881\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.2903 - mae: 1.5155 - val_loss: 145.0544 - val_mae: 3.0464\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.6108 - mae: 1.4348 - val_loss: 184.8964 - val_mae: 3.3272\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2634 - mae: 1.3959 - val_loss: 210.2293 - val_mae: 3.4612\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2042 - mae: 1.3587 - val_loss: 206.4181 - val_mae: 3.4400\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8142 - mae: 1.3168 - val_loss: 270.3213 - val_mae: 3.6876\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.0510 - mae: 1.2510 - val_loss: 250.4195 - val_mae: 3.6466\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5041 - mae: 1.2964 - val_loss: 123.5772 - val_mae: 2.8589\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.8876 - mae: 1.6635 - val_loss: 264.4018 - val_mae: 3.6352\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 25.7501 - mae: 1.3645 - val_loss: 194.3844 - val_mae: 3.3544\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 62.7512 - mae: 1.7175 - val_loss: 297.2946 - val_mae: 3.7653\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2998 - mae: 1.2455 - val_loss: 246.2077 - val_mae: 3.5901\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.5321 - mae: 1.4077 - val_loss: 218.3883 - val_mae: 3.4387\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.0031 - mae: 1.3603 - val_loss: 225.7378 - val_mae: 3.4977\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.2388 - mae: 1.3014 - val_loss: 164.1780 - val_mae: 3.1828\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.7931 - mae: 1.3378 - val_loss: 214.8269 - val_mae: 3.4751\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.5991 - mae: 1.3343 - val_loss: 253.7225 - val_mae: 3.6143\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.5230 - mae: 1.1186 - val_loss: 199.8097 - val_mae: 3.3485\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.7736 - mae: 1.5303 - val_loss: 183.8933 - val_mae: 3.2574\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.8571 - mae: 1.3535 - val_loss: 282.6215 - val_mae: 3.8107\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.3189 - mae: 1.5806 - val_loss: 277.3324 - val_mae: 3.7464\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.6421 - mae: 1.4193 - val_loss: 237.5025 - val_mae: 3.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.6239 - mae: 1.3102 - val_loss: 294.3600 - val_mae: 3.8403\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.6754 - mae: 1.3243 - val_loss: 215.8668 - val_mae: 3.4713\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6660 - mae: 1.3368 - val_loss: 252.8796 - val_mae: 3.6489\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5427 - mae: 1.3756 - val_loss: 267.0794 - val_mae: 3.7012\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.9496 - mae: 1.3198 - val_loss: 175.3501 - val_mae: 3.1894\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.2605 - mae: 1.2106 - val_loss: 221.9568 - val_mae: 3.5031\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8968 - mae: 1.1452 - val_loss: 222.3040 - val_mae: 3.4861\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0318 - mae: 1.2607 - val_loss: 237.3395 - val_mae: 3.5476\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.5833 - mae: 1.1150 - val_loss: 253.2919 - val_mae: 3.6252\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.3955 - mae: 1.4139 - val_loss: 169.8728 - val_mae: 3.2122\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.7989 - mae: 1.2546 - val_loss: 268.9482 - val_mae: 3.7255\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.8646 - mae: 1.2509 - val_loss: 284.6105 - val_mae: 3.7628\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.6553 - mae: 1.3059 - val_loss: 279.8869 - val_mae: 3.7617\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.3980 - mae: 1.4359 - val_loss: 146.5889 - val_mae: 3.0463\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6207 - mae: 1.3840 - val_loss: 254.4107 - val_mae: 3.5622\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.1923 - mae: 1.1294 - val_loss: 306.5843 - val_mae: 3.8571\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4833 - mae: 1.2794 - val_loss: 292.4082 - val_mae: 3.7234\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.7469 - mae: 1.4890 - val_loss: 383.5027 - val_mae: 4.0862\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.8702 - mae: 1.3532 - val_loss: 141.0192 - val_mae: 3.0058\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.6430 - mae: 1.2754 - val_loss: 289.6266 - val_mae: 3.8416\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5979 - mae: 1.2002 - val_loss: 264.0353 - val_mae: 3.7231\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8370 - mae: 1.3067 - val_loss: 235.5885 - val_mae: 3.5848\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8017 - mae: 1.1704 - val_loss: 270.4200 - val_mae: 3.7186\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1434 - mae: 1.1161 - val_loss: 236.5280 - val_mae: 3.6293\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3897 - mae: 1.2041 - val_loss: 197.2214 - val_mae: 3.3541\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5325 - mae: 1.2560 - val_loss: 211.9207 - val_mae: 3.5004\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.1295 - mae: 1.2443 - val_loss: 276.1810 - val_mae: 3.7434\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.3983 - mae: 1.4881 - val_loss: 178.5307 - val_mae: 3.2549\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 12.5232 - mae: 1.1527 - val_loss: 210.0266 - val_mae: 3.4362\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.3605 - mae: 1.2588 - val_loss: 228.0317 - val_mae: 3.5350\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5926 - mae: 1.1416 - val_loss: 263.0249 - val_mae: 3.6696\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0209 - mae: 1.2705 - val_loss: 239.3048 - val_mae: 3.5488\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8970 - mae: 1.2327 - val_loss: 163.6799 - val_mae: 3.0789\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8259 - mae: 1.1550 - val_loss: 146.0736 - val_mae: 2.9593\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9171 - mae: 1.4657 - val_loss: 228.7294 - val_mae: 3.5701\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1478 - mae: 1.1805 - val_loss: 295.9719 - val_mae: 3.8051\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3217 - mae: 1.4022 - val_loss: 272.8659 - val_mae: 3.6413\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.3202 - mae: 1.4245 - val_loss: 182.0141 - val_mae: 3.2504\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7877 - mae: 1.1188 - val_loss: 232.1967 - val_mae: 3.5082\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5564 - mae: 1.1750 - val_loss: 225.8310 - val_mae: 3.4454\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7117 - mae: 1.1139 - val_loss: 285.1322 - val_mae: 3.7438\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.8430 - mae: 1.3342 - val_loss: 111.0522 - val_mae: 2.6634\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3288 - mae: 1.1849 - val_loss: 157.1973 - val_mae: 3.0390\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9136 - mae: 1.1270 - val_loss: 203.4474 - val_mae: 3.3824\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2269 - mae: 1.1261 - val_loss: 275.7004 - val_mae: 3.7530\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4524 - mae: 1.1829 - val_loss: 136.9651 - val_mae: 2.9334\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0239 - mae: 1.2280 - val_loss: 184.0726 - val_mae: 3.2557\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.8335 - mae: 1.3461 - val_loss: 254.7518 - val_mae: 3.5960\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9272 - mae: 1.1035 - val_loss: 237.9005 - val_mae: 3.5713\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4973 - mae: 1.2336 - val_loss: 117.2045 - val_mae: 2.6719\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.2527 - mae: 1.2820 - val_loss: 185.0483 - val_mae: 3.3116\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3030 - mae: 1.1816 - val_loss: 194.9420 - val_mae: 3.3900\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8328 - mae: 1.1886 - val_loss: 285.1197 - val_mae: 3.8426\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.9183 - mae: 1.2028 - val_loss: 147.4590 - val_mae: 3.0306\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2495 - mae: 1.1287 - val_loss: 142.4582 - val_mae: 2.9695\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1526 - mae: 1.1496 - val_loss: 196.1318 - val_mae: 3.3589\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.2722 - mae: 1.0108 - val_loss: 187.8737 - val_mae: 3.3122\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.7093 - mae: 1.2888 - val_loss: 272.6945 - val_mae: 3.7080\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.8156 - mae: 1.3885 - val_loss: 142.5607 - val_mae: 2.9721\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3638 - mae: 1.0828 - val_loss: 186.4915 - val_mae: 3.2741\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8522 - mae: 1.1319 - val_loss: 194.5955 - val_mae: 3.3276\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9167 - mae: 1.0359 - val_loss: 175.5050 - val_mae: 3.2538\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6731 - mae: 1.0632 - val_loss: 226.3260 - val_mae: 3.5299\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.6967 - mae: 1.3083 - val_loss: 189.1972 - val_mae: 3.2972\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4255 - mae: 1.1872 - val_loss: 238.3707 - val_mae: 3.5698\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8734 - mae: 1.0913 - val_loss: 244.4159 - val_mae: 3.6262\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7931 - mae: 1.2100 - val_loss: 284.1806 - val_mae: 3.7639\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7243 - mae: 1.1058 - val_loss: 191.1245 - val_mae: 3.3291\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0361 - mae: 1.0573 - val_loss: 234.0626 - val_mae: 3.5570\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.5932 - mae: 1.0792 - val_loss: 184.5105 - val_mae: 3.2423\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4067 - mae: 1.2110 - val_loss: 118.1864 - val_mae: 2.6365\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1114 - mae: 1.2069 - val_loss: 151.9168 - val_mae: 2.9548\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.0447 - mae: 1.2742 - val_loss: 161.9453 - val_mae: 3.0939\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1897 - mae: 1.1060 - val_loss: 181.0197 - val_mae: 3.2710\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0859 - mae: 1.0230 - val_loss: 200.8055 - val_mae: 3.3750\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8043 - mae: 1.0681 - val_loss: 215.7068 - val_mae: 3.4659\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3903 - mae: 1.2158 - val_loss: 144.7795 - val_mae: 2.9619\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.1483 - mae: 1.0260 - val_loss: 181.0005 - val_mae: 3.2106\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1604 - mae: 1.0790 - val_loss: 165.1722 - val_mae: 3.1267\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.1637 - mae: 1.0793 - val_loss: 203.4968 - val_mae: 3.3798\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5182 - mae: 1.1101 - val_loss: 148.3632 - val_mae: 2.9900\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6004 - mae: 1.0982 - val_loss: 228.5233 - val_mae: 3.5261\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0726 - mae: 1.1726 - val_loss: 247.8885 - val_mae: 3.6232\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7464 - mae: 1.2605 - val_loss: 241.3605 - val_mae: 3.6224\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8046 - mae: 1.1596 - val_loss: 183.4027 - val_mae: 3.2683\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.1121 - mae: 1.0449 - val_loss: 199.8934 - val_mae: 3.3841\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5131 - mae: 1.2214 - val_loss: 296.1565 - val_mae: 3.9172\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.3664 - mae: 1.4433 - val_loss: 188.3650 - val_mae: 3.3312\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5494 - mae: 1.1073 - val_loss: 298.9736 - val_mae: 3.9745\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3453 - mae: 1.1297 - val_loss: 150.0533 - val_mae: 3.0159\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6873 - mae: 1.0568 - val_loss: 156.3302 - val_mae: 3.0665\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1601 - mae: 1.3614 - val_loss: 215.4915 - val_mae: 3.4684\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6820 - mae: 1.1565 - val_loss: 164.0732 - val_mae: 3.0940\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9888 - mae: 1.0621 - val_loss: 186.8266 - val_mae: 3.3011\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8892 - mae: 1.1440 - val_loss: 149.3257 - val_mae: 2.9578\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4226 - mae: 1.0955 - val_loss: 169.5343 - val_mae: 3.1296\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2936 - mae: 1.2223 - val_loss: 226.1126 - val_mae: 3.5839\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8008 - mae: 1.1618 - val_loss: 123.2084 - val_mae: 2.7135\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8830 - mae: 1.0101 - val_loss: 183.9355 - val_mae: 3.2624\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9642 - mae: 1.0716 - val_loss: 142.0860 - val_mae: 2.9109\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1215 - mae: 1.1237 - val_loss: 178.4826 - val_mae: 3.2105\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.3321 - mae: 0.9631 - val_loss: 198.5607 - val_mae: 3.3549\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 9.5114 - mae: 1.0324 - 1s 1ms/step - loss: 9.4228 - mae: 1.0280 - val_loss: 206.3566 - val_mae: 3.4397\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3960 - mae: 1.0381 - val_loss: 155.1916 - val_mae: 2.9943\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1602 - mae: 1.0350 - val_loss: 156.1942 - val_mae: 3.0267\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7533 - mae: 1.0805 - val_loss: 143.9390 - val_mae: 2.8459\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - ETA: 0s - loss: 13.9950 - mae: 1.06 - 1s 1ms/step - loss: 13.9470 - mae: 1.0651 - val_loss: 157.0750 - val_mae: 3.0206\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.6454 - mae: 1.0528 - val_loss: 154.4054 - val_mae: 3.0202\n",
      ">13, MAE: 2.047\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3694 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3693 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3696 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3696 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3694 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3689 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3693 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3692 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3690 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3693 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3690 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3696 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3694 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3694 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3688 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3691 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3690 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3695 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3693 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3696 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3695 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3694 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3693 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3693 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3688 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3699 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3698 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3695 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 921.3702 - mae: 6.2722 - val_loss: 846.3331 - val_mae: 7.8029\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 833.8480 - mae: 5.9229 - val_loss: 214.0246 - val_mae: 4.3989\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 395.0815 - mae: 4.2278 - val_loss: 146.7133 - val_mae: 3.1388\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 179.0873 - mae: 3.4037 - val_loss: 145.8811 - val_mae: 3.4680\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 216.0708 - mae: 3.4660 - val_loss: 122.8577 - val_mae: 2.8390\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 197.0580 - mae: 3.3381 - val_loss: 186.2489 - val_mae: 4.0366\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 187.7158 - mae: 3.1893 - val_loss: 131.7695 - val_mae: 3.3107\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 154.9503 - mae: 3.1615 - val_loss: 129.6854 - val_mae: 3.2354\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 143.3087 - mae: 2.8747 - val_loss: 147.7043 - val_mae: 3.4285\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 100.0377 - mae: 2.8121 - val_loss: 214.8273 - val_mae: 3.9461\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 104.6078 - mae: 2.6820 - val_loss: 175.5837 - val_mae: 3.4587\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 110.1246 - mae: 2.6154 - val_loss: 279.3610 - val_mae: 4.0946\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 75.2085 - mae: 2.5878 - val_loss: 277.1457 - val_mae: 3.8845\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.6145 - mae: 2.2202 - val_loss: 259.0608 - val_mae: 3.7286\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 63.3769 - mae: 2.2945 - val_loss: 159.0340 - val_mae: 3.0519\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.3102 - mae: 2.3154 - val_loss: 340.0565 - val_mae: 4.1258\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9987 - mae: 1.9800 - val_loss: 343.9380 - val_mae: 4.0530\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.5093 - mae: 2.2672 - val_loss: 428.8242 - val_mae: 4.4325\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 59.2227 - mae: 2.1321 - val_loss: 386.6768 - val_mae: 4.1946\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.2838 - mae: 2.0510 - val_loss: 196.2991 - val_mae: 3.2765\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.6782 - mae: 2.1668 - val_loss: 375.5337 - val_mae: 4.1932\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 122.0927 - mae: 2.5700 - val_loss: 207.0988 - val_mae: 3.6110\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.9105 - mae: 1.9676 - val_loss: 185.3460 - val_mae: 3.4686\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.2159 - mae: 2.0689 - val_loss: 287.9838 - val_mae: 3.9579\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.3151 - mae: 1.9584 - val_loss: 240.5434 - val_mae: 3.6804\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 61.3817 - mae: 2.2667 - val_loss: 436.7429 - val_mae: 4.6405\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.2268 - mae: 2.0199 - val_loss: 333.8691 - val_mae: 4.0591\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6052 - mae: 1.8656 - val_loss: 230.8798 - val_mae: 3.5208\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.5573 - mae: 1.9607 - val_loss: 374.6852 - val_mae: 4.2285\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.4779 - mae: 1.9816 - val_loss: 278.6356 - val_mae: 3.7429\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.2856 - mae: 2.1713 - val_loss: 173.1574 - val_mae: 3.3214\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.5995 - mae: 1.9253 - val_loss: 462.2000 - val_mae: 4.4976\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.6200 - mae: 1.9976 - val_loss: 295.9443 - val_mae: 3.8314\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.5680 - mae: 1.9106 - val_loss: 283.3061 - val_mae: 3.7085\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.6187 - mae: 1.9018 - val_loss: 321.1342 - val_mae: 3.8412\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.4342 - mae: 1.8279 - val_loss: 325.7197 - val_mae: 3.8178\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.0090 - mae: 1.8338 - val_loss: 300.1950 - val_mae: 3.7456\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 77.0953 - mae: 2.1615 - val_loss: 426.2495 - val_mae: 4.3605\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.7294 - mae: 1.8340 - val_loss: 481.4124 - val_mae: 4.5732\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.4135 - mae: 1.6987 - val_loss: 338.9391 - val_mae: 3.9379\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9627 - mae: 1.8081 - val_loss: 353.1379 - val_mae: 3.9984\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.0755 - mae: 1.9359 - val_loss: 285.9846 - val_mae: 3.6093\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.3652 - mae: 1.7819 - val_loss: 240.3171 - val_mae: 3.3946\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.3768 - mae: 1.9372 - val_loss: 421.2729 - val_mae: 4.2864\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.0598 - mae: 1.7899 - val_loss: 308.3209 - val_mae: 3.8441\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9490 - mae: 1.7751 - val_loss: 302.6867 - val_mae: 3.7916\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.7313 - mae: 1.7327 - val_loss: 322.2176 - val_mae: 3.8359\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.3256 - mae: 1.9591 - val_loss: 321.3105 - val_mae: 3.8810\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2077 - mae: 1.5195 - val_loss: 358.2633 - val_mae: 4.0983\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.1980 - mae: 1.7653 - val_loss: 323.4144 - val_mae: 3.9221\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.5093 - mae: 1.7882 - val_loss: 273.2397 - val_mae: 3.5599\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.5266 - mae: 1.5951 - val_loss: 393.0228 - val_mae: 4.2211\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.2324 - mae: 1.8133 - val_loss: 336.2069 - val_mae: 3.9538\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.1092 - mae: 1.9342 - val_loss: 249.8354 - val_mae: 3.4599\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.8851 - mae: 1.8626 - val_loss: 373.6611 - val_mae: 4.0657\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.3507 - mae: 1.5625 - val_loss: 304.5392 - val_mae: 3.7037\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.5376 - mae: 1.9012 - val_loss: 236.4144 - val_mae: 3.4176\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.1665 - mae: 1.8038 - val_loss: 323.8976 - val_mae: 3.9007\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.9188 - mae: 1.7896 - val_loss: 252.0101 - val_mae: 3.5474\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.8595 - mae: 1.8746 - val_loss: 309.8615 - val_mae: 3.8149\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.1388 - mae: 1.6968 - val_loss: 341.9372 - val_mae: 3.9615\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9682 - mae: 1.8115 - val_loss: 251.4873 - val_mae: 3.5178\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9580 - mae: 1.7010 - val_loss: 261.0517 - val_mae: 3.4832\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.9917 - mae: 1.6677 - val_loss: 255.9385 - val_mae: 3.4265\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.0967 - mae: 1.7118 - val_loss: 363.4716 - val_mae: 3.9890\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.0226 - mae: 1.6540 - val_loss: 289.0158 - val_mae: 3.6049\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1333 - mae: 1.5973 - val_loss: 344.5097 - val_mae: 3.9753\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.9708 - mae: 1.7809 - val_loss: 333.7044 - val_mae: 3.9174\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.1912 - mae: 1.8532 - val_loss: 280.8482 - val_mae: 3.6167\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.5693 - mae: 1.5614 - val_loss: 338.0846 - val_mae: 3.8904\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.9948 - mae: 1.8030 - val_loss: 356.2575 - val_mae: 3.9407\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.9863 - mae: 1.5964 - val_loss: 294.4242 - val_mae: 3.6428\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.7902 - mae: 1.7186 - val_loss: 476.3555 - val_mae: 4.4529\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.9442 - mae: 1.7288 - val_loss: 343.7020 - val_mae: 3.8711\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.0091 - mae: 1.6085 - val_loss: 267.0087 - val_mae: 3.4185\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.8794 - mae: 1.4857 - val_loss: 282.0607 - val_mae: 3.5419\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.5795 - mae: 1.5767 - val_loss: 313.5984 - val_mae: 3.7299\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.2215 - mae: 1.7009 - val_loss: 249.4553 - val_mae: 3.3684\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.5731 - mae: 1.6878 - val_loss: 339.0790 - val_mae: 3.8830\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.7709 - mae: 1.5225 - val_loss: 342.1518 - val_mae: 3.8784\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7992 - mae: 1.5690 - val_loss: 260.3461 - val_mae: 3.4978\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.6412 - mae: 1.7188 - val_loss: 386.0038 - val_mae: 4.0570\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.4552 - mae: 1.7160 - val_loss: 486.1136 - val_mae: 4.4856\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1613 - mae: 1.4815 - val_loss: 387.9008 - val_mae: 4.0443\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.6220 - mae: 1.5252 - val_loss: 266.3547 - val_mae: 3.4391\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 27.9443 - mae: 1.6315 - val_loss: 417.2740 - val_mae: 4.2487\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.9631 - mae: 1.6442 - val_loss: 353.5144 - val_mae: 3.9608\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.7419 - mae: 1.6313 - val_loss: 253.3849 - val_mae: 3.4747\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9921 - mae: 1.7239 - val_loss: 367.5706 - val_mae: 4.0032\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.8395 - mae: 1.7467 - val_loss: 284.8198 - val_mae: 3.5762\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.5459 - mae: 1.7251 - val_loss: 321.9534 - val_mae: 3.7832\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6897 - mae: 1.3598 - val_loss: 354.4115 - val_mae: 3.8982\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.0386 - mae: 1.7491 - val_loss: 294.7158 - val_mae: 3.6566\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2966 - mae: 1.5850 - val_loss: 273.7323 - val_mae: 3.5327\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1960 - mae: 1.5014 - val_loss: 241.5992 - val_mae: 3.3534\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.9761 - mae: 1.5303 - val_loss: 339.2801 - val_mae: 3.9577\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4012 - mae: 1.3531 - val_loss: 344.5598 - val_mae: 3.9419\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.8068 - mae: 1.8971 - val_loss: 427.4907 - val_mae: 4.2501\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.9625 - mae: 1.7450 - val_loss: 411.8351 - val_mae: 4.2121\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.5402 - mae: 1.6858 - val_loss: 307.1626 - val_mae: 3.6889\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4263 - mae: 1.4390 - val_loss: 272.9076 - val_mae: 3.5292\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.0342 - mae: 1.7237 - val_loss: 352.7703 - val_mae: 4.0287\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.4452 - mae: 1.5846 - val_loss: 268.6956 - val_mae: 3.5422\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3875 - mae: 1.5125 - val_loss: 289.7541 - val_mae: 3.6569\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.8631 - mae: 1.6143 - val_loss: 237.6362 - val_mae: 3.3249\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7022 - mae: 1.6065 - val_loss: 289.0382 - val_mae: 3.5982\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.7793 - mae: 1.7087 - val_loss: 383.3232 - val_mae: 4.0666\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2773 - mae: 1.4804 - val_loss: 459.2863 - val_mae: 4.4044\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.7967 - mae: 1.5946 - val_loss: 392.0058 - val_mae: 4.1645\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.0821 - mae: 1.5925 - val_loss: 221.9197 - val_mae: 3.2840\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7458 - mae: 1.5302 - val_loss: 276.9609 - val_mae: 3.6339\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.0048 - mae: 1.5897 - val_loss: 344.1509 - val_mae: 4.0212\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9560 - mae: 1.6639 - val_loss: 290.7429 - val_mae: 3.7106\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.8065 - mae: 1.6777 - val_loss: 312.4292 - val_mae: 3.8563\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.6850 - mae: 1.6449 - val_loss: 329.5183 - val_mae: 3.9273\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.4040 - mae: 1.6864 - val_loss: 335.0276 - val_mae: 3.9330\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.0227 - mae: 1.5143 - val_loss: 386.4532 - val_mae: 4.1589\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.2058 - mae: 1.6271 - val_loss: 321.9520 - val_mae: 3.8365\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.5445 - mae: 1.4965 - val_loss: 316.9583 - val_mae: 3.8044\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0765 - mae: 1.4795 - val_loss: 311.0299 - val_mae: 3.7481\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7981 - mae: 1.5187 - val_loss: 395.1568 - val_mae: 4.0967\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4676 - mae: 1.4939 - val_loss: 317.9867 - val_mae: 3.8139\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5185 - mae: 1.4511 - val_loss: 316.5859 - val_mae: 3.7528\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.8655 - mae: 1.5656 - val_loss: 384.2854 - val_mae: 4.0443\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.9611 - mae: 1.4875 - val_loss: 363.6126 - val_mae: 3.9754\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8482 - mae: 1.4707 - val_loss: 396.8040 - val_mae: 4.0920\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.4470 - mae: 1.5002 - val_loss: 320.1208 - val_mae: 3.7791\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.9358 - mae: 1.7977 - val_loss: 180.6623 - val_mae: 3.0844\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2777 - mae: 1.4142 - val_loss: 313.3957 - val_mae: 3.7989\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5434 - mae: 1.4413 - val_loss: 302.8885 - val_mae: 3.7410\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.5315 - mae: 1.5593 - val_loss: 365.1555 - val_mae: 4.0634\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.4428 - mae: 1.5378 - val_loss: 348.9824 - val_mae: 4.0073\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6981 - mae: 1.3399 - val_loss: 305.7790 - val_mae: 3.7750\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.2376 - mae: 1.6313 - val_loss: 248.3797 - val_mae: 3.4823\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4285 - mae: 1.5815 - val_loss: 254.9877 - val_mae: 3.4764\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3120 - mae: 1.5222 - val_loss: 286.5683 - val_mae: 3.6644\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.3851 - mae: 1.4643 - val_loss: 428.0872 - val_mae: 4.3476\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.7823 - mae: 1.4941 - val_loss: 233.7411 - val_mae: 3.3656\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.3895 - mae: 1.5779 - val_loss: 305.6122 - val_mae: 3.7921\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.5048 - mae: 1.5050 - val_loss: 378.8524 - val_mae: 4.1797\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7854 - mae: 1.5004 - val_loss: 320.0728 - val_mae: 3.8480\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.1175 - mae: 1.5170 - val_loss: 328.3571 - val_mae: 3.8657\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9154 - mae: 1.7629 - val_loss: 256.9268 - val_mae: 3.5133\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9361 - mae: 1.3981 - val_loss: 278.2771 - val_mae: 3.6590\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5969 - mae: 1.4312 - val_loss: 286.0789 - val_mae: 3.7662\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8973 - mae: 1.5155 - val_loss: 311.4095 - val_mae: 3.7359\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.6591 - mae: 1.4860 - val_loss: 217.9895 - val_mae: 3.2875\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4918 - mae: 1.4074 - val_loss: 273.3198 - val_mae: 3.4874\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4980 - mae: 1.4046 - val_loss: 309.5909 - val_mae: 3.7848\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5920 - mae: 1.4956 - val_loss: 256.6678 - val_mae: 3.4835\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.6230 - mae: 1.4146 - val_loss: 270.7414 - val_mae: 3.5358\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4952 - mae: 1.5289 - val_loss: 284.2888 - val_mae: 3.6429\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5068 - mae: 1.3512 - val_loss: 214.5542 - val_mae: 3.2369\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4796 - mae: 1.4147 - val_loss: 213.0925 - val_mae: 3.2461\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.6861 - mae: 1.4771 - val_loss: 309.7232 - val_mae: 3.8120\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8964 - mae: 1.4613 - val_loss: 299.3710 - val_mae: 3.8016\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9393 - mae: 1.5029 - val_loss: 293.8004 - val_mae: 3.6814\n",
      ">14, MAE: 2.391\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 251.2031 - mae: 3.9641 - val_loss: 476.9371 - val_mae: 6.0853\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 398.0170 - mae: 4.0856 - val_loss: 131.1229 - val_mae: 3.2770\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 240.0452 - mae: 3.4769 - val_loss: 119.7886 - val_mae: 3.0784\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 264.0974 - mae: 3.3071 - val_loss: 126.2204 - val_mae: 3.1637\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 162.0247 - mae: 2.9762 - val_loss: 192.9649 - val_mae: 3.7198\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 173.7128 - mae: 2.9369 - val_loss: 216.4208 - val_mae: 3.7447\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 95.5025 - mae: 2.3771 - val_loss: 152.2449 - val_mae: 3.2579\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 89.3572 - mae: 2.4609 - val_loss: 163.1029 - val_mae: 3.3192\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 102.7533 - mae: 2.3823 - val_loss: 309.3146 - val_mae: 4.0898\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 76.7031 - mae: 2.2240 - val_loss: 203.9460 - val_mae: 3.4657\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 61.0318 - mae: 2.1744 - val_loss: 206.5457 - val_mae: 3.4279\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 93.0392 - mae: 2.5262 - val_loss: 277.9429 - val_mae: 3.6648\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.8305 - mae: 2.1010 - val_loss: 389.5334 - val_mae: 4.1997\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.0758 - mae: 1.9525 - val_loss: 203.1628 - val_mae: 3.4463\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 65.5133 - mae: 2.1871 - val_loss: 418.6914 - val_mae: 4.3298\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.7516 - mae: 1.8645 - val_loss: 469.4815 - val_mae: 4.4458\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.3727 - mae: 2.0047 - val_loss: 316.5497 - val_mae: 3.7302\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.7490 - mae: 1.9858 - val_loss: 424.8319 - val_mae: 4.2389\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 74.2738 - mae: 2.1888 - val_loss: 279.3022 - val_mae: 3.7432\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 56.7038 - mae: 2.0210 - val_loss: 273.5727 - val_mae: 3.6756\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.0259 - mae: 1.8885 - val_loss: 282.6381 - val_mae: 3.7804\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.1356 - mae: 1.9040 - val_loss: 237.7128 - val_mae: 3.3582\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.8466 - mae: 2.1803 - val_loss: 192.2064 - val_mae: 3.0998\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 76.7437 - mae: 2.2275 - val_loss: 423.0063 - val_mae: 4.2568\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.5526 - mae: 1.7839 - val_loss: 340.2241 - val_mae: 3.9182\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.6949 - mae: 1.9502 - val_loss: 468.5987 - val_mae: 4.4197\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.7567 - mae: 1.7239 - val_loss: 440.5499 - val_mae: 4.2514\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.0647 - mae: 1.9316 - val_loss: 199.0290 - val_mae: 3.1905\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.1213 - mae: 1.8113 - val_loss: 248.6147 - val_mae: 3.4964\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.5340 - mae: 1.9159 - val_loss: 311.4959 - val_mae: 3.6657\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.9602 - mae: 1.6685 - val_loss: 120.8834 - val_mae: 2.7244\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.7074 - mae: 1.8881 - val_loss: 210.3332 - val_mae: 3.2913\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.8624 - mae: 1.7522 - val_loss: 311.2707 - val_mae: 3.7683\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.6652 - mae: 1.7844 - val_loss: 304.1970 - val_mae: 3.6763\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.8910 - mae: 1.5405 - val_loss: 402.5214 - val_mae: 4.0563\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.7383 - mae: 1.7294 - val_loss: 352.1172 - val_mae: 3.9666\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6298 - mae: 1.6551 - val_loss: 287.4570 - val_mae: 3.6535\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 72.7354 - mae: 2.0449 - val_loss: 166.9785 - val_mae: 3.1106\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.0260 - mae: 1.7040 - val_loss: 232.5432 - val_mae: 3.4548\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.9138 - mae: 1.5357 - val_loss: 234.3243 - val_mae: 3.4217\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.5768 - mae: 1.7352 - val_loss: 240.3297 - val_mae: 3.4902\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.6577 - mae: 1.8341 - val_loss: 297.2903 - val_mae: 3.8207\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3893 - mae: 1.4543 - val_loss: 251.9122 - val_mae: 3.5169\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.0333 - mae: 1.5522 - val_loss: 172.1930 - val_mae: 3.0874\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.7637 - mae: 1.5653 - val_loss: 140.0065 - val_mae: 2.9139\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.7330 - mae: 1.7111 - val_loss: 205.8096 - val_mae: 3.3376\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.1930 - mae: 1.6667 - val_loss: 322.6718 - val_mae: 3.8843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.7465 - mae: 1.6436 - val_loss: 149.2758 - val_mae: 3.0317\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.2938 - mae: 1.5883 - val_loss: 153.1609 - val_mae: 3.0482\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.8294 - mae: 1.5140 - val_loss: 231.7943 - val_mae: 3.4393\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.5738 - mae: 1.5839 - val_loss: 266.0752 - val_mae: 3.5867\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.1835 - mae: 1.5453 - val_loss: 255.3469 - val_mae: 3.6178\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.1583 - mae: 1.4779 - val_loss: 224.9412 - val_mae: 3.5179\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.1818 - mae: 1.3436 - val_loss: 220.9866 - val_mae: 3.4241\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.3059 - mae: 1.4506 - val_loss: 147.6144 - val_mae: 2.9768\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.6582 - mae: 1.7072 - val_loss: 208.1100 - val_mae: 3.3156\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.2687 - mae: 1.5498 - val_loss: 168.7292 - val_mae: 3.0789\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7386 - mae: 1.3385 - val_loss: 207.7354 - val_mae: 3.2689\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.3890 - mae: 1.5939 - val_loss: 176.2422 - val_mae: 3.1243\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.2943 - mae: 1.4975 - val_loss: 218.9450 - val_mae: 3.3681\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.0949 - mae: 1.4893 - val_loss: 150.8009 - val_mae: 3.0310\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.0951 - mae: 1.6190 - val_loss: 131.1544 - val_mae: 2.8267\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 69.7609 - mae: 1.8549 - val_loss: 129.9307 - val_mae: 2.7807\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.1444 - mae: 1.4833 - val_loss: 257.0984 - val_mae: 3.5686\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1025 - mae: 1.4711 - val_loss: 209.2028 - val_mae: 3.2429\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.9256 - mae: 1.4530 - val_loss: 134.9220 - val_mae: 2.8984\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.9093 - mae: 1.3985 - val_loss: 263.5906 - val_mae: 3.5851\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.2453 - mae: 1.5463 - val_loss: 168.2964 - val_mae: 3.1292\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.7281 - mae: 1.6673 - val_loss: 223.1938 - val_mae: 3.4044\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2183 - mae: 1.3132 - val_loss: 216.5644 - val_mae: 3.3688\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0062 - mae: 1.3118 - val_loss: 207.0189 - val_mae: 3.3006\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.4552 - mae: 1.6657 - val_loss: 142.4210 - val_mae: 2.8870\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.5100 - mae: 1.3227 - val_loss: 184.1579 - val_mae: 3.1861\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9651 - mae: 1.3919 - val_loss: 209.1702 - val_mae: 3.3194\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2692 - mae: 1.4215 - val_loss: 256.4851 - val_mae: 3.5337\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.0677 - mae: 1.3969 - val_loss: 229.0407 - val_mae: 3.4335\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1441 - mae: 1.4403 - val_loss: 212.7154 - val_mae: 3.3532\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5098 - mae: 1.2930 - val_loss: 209.0373 - val_mae: 3.3903\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.3711 - mae: 1.3714 - val_loss: 148.6575 - val_mae: 2.9823\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.8340 - mae: 1.5610 - val_loss: 217.5815 - val_mae: 3.3311\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1779 - mae: 1.2562 - val_loss: 236.0377 - val_mae: 3.4776\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4277 - mae: 1.2620 - val_loss: 197.3653 - val_mae: 3.2815\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.1069 - mae: 1.4620 - val_loss: 197.2059 - val_mae: 3.3129\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9982 - mae: 1.3873 - val_loss: 233.7114 - val_mae: 3.5052\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.9619 - mae: 1.4187 - val_loss: 172.8162 - val_mae: 3.1748\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5845 - mae: 1.3090 - val_loss: 163.2660 - val_mae: 3.0788\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0317 - mae: 1.2400 - val_loss: 179.3502 - val_mae: 3.1665\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.0648 - mae: 1.4969 - val_loss: 333.8114 - val_mae: 3.9118\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.8342 - mae: 1.6894 - val_loss: 154.4429 - val_mae: 3.0102\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0832 - mae: 1.3032 - val_loss: 140.4951 - val_mae: 2.9160\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9645 - mae: 1.1697 - val_loss: 160.3228 - val_mae: 3.0227\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2393 - mae: 1.2505 - val_loss: 199.9991 - val_mae: 3.2972\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.0662 - mae: 1.2758 - val_loss: 133.4407 - val_mae: 2.7608\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.9386 - mae: 1.2605 - val_loss: 193.3374 - val_mae: 3.1890\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8227 - mae: 1.2328 - val_loss: 153.2492 - val_mae: 2.9862\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.8641 - mae: 1.3954 - val_loss: 238.9870 - val_mae: 3.4254\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8189 - mae: 1.3524 - val_loss: 275.4328 - val_mae: 3.6063\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3935 - mae: 1.4487 - val_loss: 276.4764 - val_mae: 3.6075\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4581 - mae: 1.2727 - val_loss: 245.4931 - val_mae: 3.5313\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.2159 - mae: 1.5598 - val_loss: 337.3372 - val_mae: 3.9307\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5298 - mae: 1.3562 - val_loss: 176.1882 - val_mae: 3.1796\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2832 - mae: 1.1837 - val_loss: 175.3057 - val_mae: 3.1732\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2019 - mae: 1.1838 - val_loss: 157.8947 - val_mae: 3.0623\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5231 - mae: 1.2895 - val_loss: 182.9470 - val_mae: 3.2021\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8568 - mae: 1.3563 - val_loss: 335.7065 - val_mae: 3.9173\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.2149 - mae: 1.5174 - val_loss: 136.1089 - val_mae: 2.8885\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9021 - mae: 1.2333 - val_loss: 207.3066 - val_mae: 3.3304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4146 - mae: 1.3606 - val_loss: 316.9838 - val_mae: 3.7733\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2932 - mae: 1.3670 - val_loss: 124.5610 - val_mae: 2.8214\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.9267 - mae: 1.3502 - val_loss: 170.8874 - val_mae: 3.1257\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0550 - mae: 1.0944 - val_loss: 106.3171 - val_mae: 2.5989\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2851 - mae: 1.2924 - val_loss: 193.2520 - val_mae: 3.2612\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1606 - mae: 1.2354 - val_loss: 160.6306 - val_mae: 3.0311\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8841 - mae: 1.1306 - val_loss: 195.2977 - val_mae: 3.2677\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7044 - mae: 1.3167 - val_loss: 248.0683 - val_mae: 3.5360\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.0825 - mae: 1.3426 - val_loss: 116.0086 - val_mae: 2.7280\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0083 - mae: 1.2838 - val_loss: 200.9095 - val_mae: 3.3457\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0484 - mae: 1.3727 - val_loss: 300.0954 - val_mae: 3.7381\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9157 - mae: 1.1491 - val_loss: 240.2504 - val_mae: 3.4893\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4421 - mae: 1.1267 - val_loss: 256.8809 - val_mae: 3.5601\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.4091 - mae: 1.3137 - val_loss: 140.2880 - val_mae: 2.8670\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.1440 - mae: 1.3501 - val_loss: 138.1358 - val_mae: 2.9305\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.8963 - mae: 1.3947 - val_loss: 229.5882 - val_mae: 3.4505\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8278 - mae: 1.2079 - val_loss: 196.7889 - val_mae: 3.2379\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6361 - mae: 1.2643 - val_loss: 202.2048 - val_mae: 3.2539\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0036 - mae: 1.1539 - val_loss: 175.0663 - val_mae: 3.1123\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7394 - mae: 1.2123 - val_loss: 159.6198 - val_mae: 3.0028\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3606 - mae: 1.2833 - val_loss: 179.6822 - val_mae: 3.1527\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1868 - mae: 1.2063 - val_loss: 219.6382 - val_mae: 3.3905\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3878 - mae: 1.1692 - val_loss: 213.7645 - val_mae: 3.3878\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5432 - mae: 1.3044 - val_loss: 228.6387 - val_mae: 3.4763\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6817 - mae: 1.1200 - val_loss: 165.4518 - val_mae: 3.1134\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5786 - mae: 1.2126 - val_loss: 193.6466 - val_mae: 3.3202\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.2582 - mae: 1.3480 - val_loss: 241.4918 - val_mae: 3.5376\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3339 - mae: 1.1796 - val_loss: 181.9261 - val_mae: 3.2263\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9004 - mae: 1.1137 - val_loss: 138.0045 - val_mae: 2.8685\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0056 - mae: 1.2433 - val_loss: 208.8463 - val_mae: 3.3346\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1026 - mae: 1.1722 - val_loss: 209.0810 - val_mae: 3.3474\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5427 - mae: 1.1848 - val_loss: 253.6800 - val_mae: 3.5824\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6707 - mae: 1.1228 - val_loss: 160.8591 - val_mae: 3.0521\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6004 - mae: 1.1848 - val_loss: 210.1685 - val_mae: 3.3369\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5037 - mae: 1.2018 - val_loss: 150.9318 - val_mae: 2.9770\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8864 - mae: 1.0871 - val_loss: 177.3386 - val_mae: 3.1339\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5217 - mae: 1.2408 - val_loss: 157.4379 - val_mae: 3.0091\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3513 - mae: 1.1657 - val_loss: 183.2488 - val_mae: 3.1861\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5292 - mae: 1.2055 - val_loss: 163.4418 - val_mae: 3.0325\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.7831 - mae: 1.2469 - val_loss: 205.5078 - val_mae: 3.3050\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4662 - mae: 1.1108 - val_loss: 259.2375 - val_mae: 3.5921\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8477 - mae: 1.0886 - val_loss: 163.5567 - val_mae: 3.0269\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.2382 - mae: 1.2350 - val_loss: 209.1615 - val_mae: 3.3727\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3051 - mae: 1.2143 - val_loss: 227.8934 - val_mae: 3.3963\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.6571 - mae: 1.3234 - val_loss: 268.8170 - val_mae: 3.5931\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3368 - mae: 1.1470 - val_loss: 175.0918 - val_mae: 3.1508\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3693 - mae: 1.1219 - val_loss: 134.8639 - val_mae: 2.8247\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9929 - mae: 1.2215 - val_loss: 135.1810 - val_mae: 2.8200\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4009 - mae: 1.1923 - val_loss: 193.7558 - val_mae: 3.2589\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6689 - mae: 1.1614 - val_loss: 176.4696 - val_mae: 3.1572\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.5961 - mae: 1.2483 - val_loss: 129.3523 - val_mae: 2.7234\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4513 - mae: 1.2323 - val_loss: 166.5722 - val_mae: 3.1227\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8508 - mae: 1.2259 - val_loss: 178.0012 - val_mae: 3.1881\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3741 - mae: 1.1529 - val_loss: 197.2611 - val_mae: 3.2681\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1566 - mae: 1.1644 - val_loss: 220.1090 - val_mae: 3.4206\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.5161 - mae: 1.3388 - val_loss: 140.7437 - val_mae: 2.8894\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3941 - mae: 1.2038 - val_loss: 222.5518 - val_mae: 3.4406\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3966 - mae: 1.3199 - val_loss: 185.9878 - val_mae: 3.2457\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1114 - mae: 1.1775 - val_loss: 160.6939 - val_mae: 3.0564\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.9414 - mae: 1.2061 - val_loss: 177.1007 - val_mae: 3.1611\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.9756 - mae: 1.1279 - val_loss: 223.4772 - val_mae: 3.4344\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.2440 - mae: 1.2560 - val_loss: 136.1597 - val_mae: 2.7755\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.8284 - mae: 1.0391 - val_loss: 144.7758 - val_mae: 2.8834\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.1136 - mae: 1.0869 - val_loss: 143.3195 - val_mae: 2.8527\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2189 - mae: 1.1945 - val_loss: 165.7495 - val_mae: 3.0631\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8774 - mae: 1.0526 - val_loss: 135.1425 - val_mae: 2.7933\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4791 - mae: 1.1645 - val_loss: 154.4654 - val_mae: 2.9354\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6913 - mae: 1.0787 - val_loss: 178.8005 - val_mae: 3.1179\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0204 - mae: 1.1271 - val_loss: 152.1629 - val_mae: 2.9271\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.3983 - mae: 0.9998 - val_loss: 135.7968 - val_mae: 2.7785\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4531 - mae: 1.1151 - val_loss: 167.3079 - val_mae: 3.0768\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.1823 - mae: 1.0453 - val_loss: 150.7094 - val_mae: 2.9456\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.1648 - mae: 1.2394 - val_loss: 166.7348 - val_mae: 3.0410\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5257 - mae: 1.0173 - val_loss: 156.1626 - val_mae: 2.9586\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2217 - mae: 1.1006 - val_loss: 199.1910 - val_mae: 3.3296\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2121 - mae: 1.0878 - val_loss: 258.9558 - val_mae: 3.6475\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2182 - mae: 1.2788 - val_loss: 148.0617 - val_mae: 2.8848\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.2392 - mae: 1.0496 - val_loss: 145.1588 - val_mae: 2.8580\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.3551 - mae: 0.9803 - val_loss: 138.2244 - val_mae: 2.7760\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.7542 - mae: 1.0349 - val_loss: 150.2653 - val_mae: 2.9188\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.1476 - mae: 1.3083 - val_loss: 243.9784 - val_mae: 3.5510\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8826 - mae: 1.1309 - val_loss: 215.7553 - val_mae: 3.3671\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5619 - mae: 1.1342 - val_loss: 147.0076 - val_mae: 2.8936\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.7783 - mae: 1.1037 - val_loss: 152.4092 - val_mae: 2.9563\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.7124 - mae: 1.0804 - val_loss: 153.2919 - val_mae: 3.0050\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0926 - mae: 1.1237 - val_loss: 212.8398 - val_mae: 3.4091\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.6648 - mae: 1.0003 - val_loss: 183.1996 - val_mae: 3.1899\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 18.2844 - mae: 1.2210 - val_loss: 120.0862 - val_mae: 2.5812\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.7482 - mae: 1.2494 - val_loss: 137.8809 - val_mae: 2.8103\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7800 - mae: 1.0418 - val_loss: 161.4028 - val_mae: 3.0577\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3677 - mae: 1.2250 - val_loss: 152.3992 - val_mae: 2.9352\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 6.0950 - mae: 0.8980 - val_loss: 145.5398 - val_mae: 2.8782\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0951 - mae: 1.2304 - val_loss: 169.5791 - val_mae: 3.0743\n",
      ">15, MAE: 2.126\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 386.1413 - mae: 4.5354 - val_loss: 181.9452 - val_mae: 3.3900\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 222.1293 - mae: 3.6803 - val_loss: 302.3372 - val_mae: 4.7948\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 206.2198 - mae: 3.3293 - val_loss: 147.3396 - val_mae: 2.8393\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 139.3833 - mae: 2.9322 - val_loss: 605.6138 - val_mae: 6.1983\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 158.7439 - mae: 3.0193 - val_loss: 268.6892 - val_mae: 4.3911\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 130.4691 - mae: 2.8112 - val_loss: 136.6345 - val_mae: 3.0464\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 164.5797 - mae: 2.8943 - val_loss: 203.3408 - val_mae: 3.6855\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 90.2305 - mae: 2.5295 - val_loss: 371.5275 - val_mae: 4.5830\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 103.9303 - mae: 2.5320 - val_loss: 166.9027 - val_mae: 3.2171\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 76.1622 - mae: 2.3104 - val_loss: 227.3395 - val_mae: 3.4433\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.0170 - mae: 1.9646 - val_loss: 433.6673 - val_mae: 4.3776\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.0780 - mae: 2.0734 - val_loss: 222.9872 - val_mae: 3.2494\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 74.3265 - mae: 2.2249 - val_loss: 251.9364 - val_mae: 3.3539\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 68.1509 - mae: 2.1381 - val_loss: 261.9460 - val_mae: 3.5300\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 119.4335 - mae: 2.5178 - val_loss: 478.6765 - val_mae: 4.2501\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.2234 - mae: 2.1243 - val_loss: 297.5226 - val_mae: 3.6124\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.2760 - mae: 1.9693 - val_loss: 266.5576 - val_mae: 3.5467\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.4616 - mae: 1.7976 - val_loss: 427.5096 - val_mae: 4.0833\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.9305 - mae: 1.9075 - val_loss: 408.2050 - val_mae: 3.9824\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.0938 - mae: 1.7778 - val_loss: 373.5021 - val_mae: 3.8565\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.2823 - mae: 1.9966 - val_loss: 339.7898 - val_mae: 3.8350\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.2569 - mae: 2.0643 - val_loss: 445.0854 - val_mae: 4.1922\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.7513 - mae: 2.2038 - val_loss: 733.8666 - val_mae: 5.1052\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 81.1356 - mae: 2.1909 - val_loss: 247.1984 - val_mae: 3.4781\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.6371 - mae: 1.6557 - val_loss: 402.6821 - val_mae: 3.9974\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 45.7414 - mae: 1.7814 - val_loss: 374.4445 - val_mae: 3.8567\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 57.1506 - mae: 1.9993 - val_loss: 592.6014 - val_mae: 4.5721\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.7869 - mae: 1.7699 - val_loss: 183.4785 - val_mae: 3.1196\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 75.3861 - mae: 2.0992 - val_loss: 493.5066 - val_mae: 4.3185\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.7174 - mae: 1.7625 - val_loss: 233.2383 - val_mae: 3.3546\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.6589 - mae: 1.7982 - val_loss: 499.5869 - val_mae: 4.4577\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.1934 - mae: 1.8223 - val_loss: 244.8500 - val_mae: 3.4505\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.1285 - mae: 1.5890 - val_loss: 270.5119 - val_mae: 3.4539\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.9148 - mae: 1.6221 - val_loss: 234.3645 - val_mae: 3.2926\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.0898 - mae: 1.6942 - val_loss: 305.9597 - val_mae: 3.6238\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.2541 - mae: 1.9044 - val_loss: 244.6071 - val_mae: 3.3691\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.2658 - mae: 1.5728 - val_loss: 379.7587 - val_mae: 4.0199\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9130 - mae: 1.7277 - val_loss: 303.7817 - val_mae: 3.5964\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.4740 - mae: 1.8632 - val_loss: 256.2211 - val_mae: 3.3989\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2791 - mae: 1.4610 - val_loss: 331.9568 - val_mae: 3.7763\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.3127 - mae: 1.5480 - val_loss: 276.5084 - val_mae: 3.4927\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.4310 - mae: 1.7219 - val_loss: 322.3840 - val_mae: 3.7503\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.7995 - mae: 1.6028 - val_loss: 280.4171 - val_mae: 3.6015\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.0503 - mae: 1.7453 - val_loss: 223.2749 - val_mae: 3.4197\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9671 - mae: 1.6255 - val_loss: 257.9162 - val_mae: 3.5690\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.6222 - mae: 1.9182 - val_loss: 380.5689 - val_mae: 4.0063\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.0788 - mae: 1.6995 - val_loss: 337.3144 - val_mae: 3.8852\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.3502 - mae: 1.7266 - val_loss: 221.1331 - val_mae: 3.3513\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.4088 - mae: 1.6749 - val_loss: 385.8407 - val_mae: 4.1074\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.6912 - mae: 1.5851 - val_loss: 250.4798 - val_mae: 3.5239\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.1914 - mae: 1.4802 - val_loss: 315.1336 - val_mae: 3.7088\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.5228 - mae: 1.6370 - val_loss: 225.9788 - val_mae: 3.3777\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.0157 - mae: 1.4217 - val_loss: 298.3070 - val_mae: 3.7569\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4323 - mae: 1.4931 - val_loss: 253.9974 - val_mae: 3.5618\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.1870 - mae: 1.4204 - val_loss: 220.8221 - val_mae: 3.3833\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.3527 - mae: 1.5689 - val_loss: 198.1562 - val_mae: 3.2002\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.8288 - mae: 1.4940 - val_loss: 268.3017 - val_mae: 3.6426\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.6466 - mae: 1.5997 - val_loss: 182.4164 - val_mae: 3.1616\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.1059 - mae: 1.6921 - val_loss: 216.8232 - val_mae: 3.3219\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.9754 - mae: 1.4341 - val_loss: 175.0597 - val_mae: 3.0815\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.7734 - mae: 1.5460 - val_loss: 251.7312 - val_mae: 3.5833\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2490 - mae: 1.4369 - val_loss: 232.7253 - val_mae: 3.4533\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.5354 - mae: 1.4803 - val_loss: 344.5526 - val_mae: 3.8802\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9053 - mae: 1.4290 - val_loss: 245.2121 - val_mae: 3.4998\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8561 - mae: 1.3206 - val_loss: 191.2325 - val_mae: 3.2123\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5682 - mae: 1.3768 - val_loss: 272.6052 - val_mae: 3.6648\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3099 - mae: 1.4478 - val_loss: 256.8914 - val_mae: 3.5044\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4408 - mae: 1.4481 - val_loss: 208.4173 - val_mae: 3.1959\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8493 - mae: 1.2734 - val_loss: 329.8007 - val_mae: 3.7993\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2722 - mae: 1.3465 - val_loss: 327.4470 - val_mae: 3.8593\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.7105 - mae: 1.7149 - val_loss: 399.3693 - val_mae: 4.2185\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.1364 - mae: 1.5259 - val_loss: 136.7146 - val_mae: 2.8583\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.7799 - mae: 1.4827 - val_loss: 292.5732 - val_mae: 3.7467\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2094 - mae: 1.3564 - val_loss: 318.8178 - val_mae: 3.7897\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.0557 - mae: 1.4650 - val_loss: 285.1500 - val_mae: 3.5492\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.4039 - mae: 1.4479 - val_loss: 250.4358 - val_mae: 3.3810\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1127 - mae: 1.3444 - val_loss: 291.7494 - val_mae: 3.5703\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.5599 - mae: 1.4423 - val_loss: 160.7953 - val_mae: 2.8572\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.6200 - mae: 1.5618 - val_loss: 265.1332 - val_mae: 3.6319\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0889 - mae: 1.3366 - val_loss: 197.0024 - val_mae: 3.1690\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.6498 - mae: 1.3880 - val_loss: 255.3227 - val_mae: 3.5534\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5614 - mae: 1.3252 - val_loss: 210.7141 - val_mae: 3.2691\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0345 - mae: 1.2910 - val_loss: 204.3586 - val_mae: 3.2316\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.2182 - mae: 1.1032 - val_loss: 242.7318 - val_mae: 3.4491\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2438 - mae: 1.4624 - val_loss: 291.1245 - val_mae: 3.7783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8549 - mae: 1.2527 - val_loss: 246.0689 - val_mae: 3.4654\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0529 - mae: 1.3307 - val_loss: 260.4084 - val_mae: 3.4844\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.2095 - mae: 1.7035 - val_loss: 113.4493 - val_mae: 2.4722\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.8414 - mae: 1.4906 - val_loss: 252.7666 - val_mae: 3.5019\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.5136 - mae: 1.4283 - val_loss: 236.6755 - val_mae: 3.4168\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.5805 - mae: 1.3929 - val_loss: 209.8310 - val_mae: 3.2931\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7994 - mae: 1.3074 - val_loss: 255.3836 - val_mae: 3.4601\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6365 - mae: 1.1415 - val_loss: 261.7468 - val_mae: 3.5138\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9775 - mae: 1.1292 - val_loss: 276.8507 - val_mae: 3.5957\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.7700 - mae: 1.3813 - val_loss: 305.0594 - val_mae: 3.7166\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1151 - mae: 1.2339 - val_loss: 268.1990 - val_mae: 3.5767\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.5740 - mae: 1.2586 - val_loss: 176.2137 - val_mae: 3.0308\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9706 - mae: 1.2687 - val_loss: 181.8217 - val_mae: 3.0543\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.4276 - mae: 1.2978 - val_loss: 290.8085 - val_mae: 3.6775\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3610 - mae: 1.2341 - val_loss: 347.6643 - val_mae: 3.9476\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1280 - mae: 1.3122 - val_loss: 223.6734 - val_mae: 3.3270\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1383 - mae: 1.2110 - val_loss: 260.5394 - val_mae: 3.5587\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.9286 - mae: 1.3595 - val_loss: 334.5649 - val_mae: 3.9382\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.1791 - mae: 1.3635 - val_loss: 164.5319 - val_mae: 2.9675\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8579 - mae: 1.1689 - val_loss: 248.4405 - val_mae: 3.5009\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1557 - mae: 1.3353 - val_loss: 391.5283 - val_mae: 4.1489\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.6793 - mae: 1.3332 - val_loss: 365.6085 - val_mae: 4.0349\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.3569 - mae: 1.4765 - val_loss: 277.5692 - val_mae: 3.6391\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.1580 - mae: 1.3325 - val_loss: 143.6806 - val_mae: 2.7880\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6190 - mae: 1.2372 - val_loss: 163.0287 - val_mae: 2.9357\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6953 - mae: 1.2596 - val_loss: 180.5697 - val_mae: 3.1064\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4901 - mae: 1.2428 - val_loss: 218.4825 - val_mae: 3.3331\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7051 - mae: 1.2139 - val_loss: 177.3109 - val_mae: 3.0869\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.3282 - mae: 1.3317 - val_loss: 240.0547 - val_mae: 3.4782\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7275 - mae: 1.2482 - val_loss: 180.8298 - val_mae: 3.0708\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.4425 - mae: 1.4029 - val_loss: 307.2716 - val_mae: 3.8089\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7695 - mae: 1.2312 - val_loss: 164.9088 - val_mae: 2.9861\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4764 - mae: 1.1326 - val_loss: 259.8865 - val_mae: 3.5556\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5447 - mae: 1.1689 - val_loss: 284.8824 - val_mae: 3.6970\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8631 - mae: 1.2216 - val_loss: 237.1041 - val_mae: 3.4782\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1558 - mae: 1.2253 - val_loss: 157.3687 - val_mae: 2.9348\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.6761 - mae: 1.2571 - val_loss: 281.6350 - val_mae: 3.7284\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7032 - mae: 1.2332 - val_loss: 284.2940 - val_mae: 3.7751\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7033 - mae: 1.3436 - val_loss: 152.5694 - val_mae: 2.9223\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.2876 - mae: 1.4771 - val_loss: 454.3380 - val_mae: 4.4634\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.0748 - mae: 1.3891 - val_loss: 165.1859 - val_mae: 3.0017\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.7227 - mae: 1.4924 - val_loss: 243.9038 - val_mae: 3.6153\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.3447 - mae: 1.3497 - val_loss: 172.8505 - val_mae: 3.1025\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8110 - mae: 1.1246 - val_loss: 249.8759 - val_mae: 3.5640\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7989 - mae: 1.0988 - val_loss: 197.4035 - val_mae: 3.2304\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 59.9797 - mae: 1.5953 - val_loss: 315.0580 - val_mae: 3.9288\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7479 - mae: 1.1077 - val_loss: 211.1418 - val_mae: 3.3437\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.8135 - mae: 1.2679 - val_loss: 177.4121 - val_mae: 3.1301\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.8636 - mae: 1.3061 - val_loss: 297.7887 - val_mae: 3.8143\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.0624 - mae: 1.2503 - val_loss: 140.6169 - val_mae: 2.7995\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2796 - mae: 1.2505 - val_loss: 225.8345 - val_mae: 3.4531\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5715 - mae: 1.2692 - val_loss: 297.1192 - val_mae: 3.9197\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6572 - mae: 1.2607 - val_loss: 229.8957 - val_mae: 3.5165\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8814 - mae: 1.1029 - val_loss: 229.1555 - val_mae: 3.5023\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5339 - mae: 1.3199 - val_loss: 213.4786 - val_mae: 3.3762\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5632 - mae: 1.3643 - val_loss: 334.1834 - val_mae: 4.0434\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3295 - mae: 1.1706 - val_loss: 226.1570 - val_mae: 3.4851\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.7956 - mae: 1.3842 - val_loss: 324.1766 - val_mae: 4.0171\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7514 - mae: 1.0427 - val_loss: 277.8372 - val_mae: 3.7548\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7352 - mae: 1.3058 - val_loss: 256.7894 - val_mae: 3.6932\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.1655 - mae: 1.3074 - val_loss: 149.0177 - val_mae: 2.9768\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1489 - mae: 1.2333 - val_loss: 232.2319 - val_mae: 3.5158\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3030 - mae: 1.0348 - val_loss: 268.7429 - val_mae: 3.7320\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3570 - mae: 1.1570 - val_loss: 174.7577 - val_mae: 3.1596\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1223 - mae: 1.1105 - val_loss: 179.4537 - val_mae: 3.1923\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4065 - mae: 1.0721 - val_loss: 210.0940 - val_mae: 3.4231\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.5658 - mae: 1.1302 - val_loss: 237.1214 - val_mae: 3.5836\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5443 - mae: 1.0845 - val_loss: 192.6598 - val_mae: 3.3081\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3330 - mae: 1.0388 - val_loss: 254.6172 - val_mae: 3.6842\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5654 - mae: 1.1603 - val_loss: 181.5145 - val_mae: 3.1951\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5789 - mae: 1.1344 - val_loss: 234.7030 - val_mae: 3.5587\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4797 - mae: 1.0847 - val_loss: 214.9830 - val_mae: 3.4531\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.9415 - mae: 1.1854 - val_loss: 182.5430 - val_mae: 3.2277\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.1812 - mae: 1.0948 - val_loss: 185.1926 - val_mae: 3.2456\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0455 - mae: 1.0478 - val_loss: 203.1509 - val_mae: 3.3544\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.5458 - mae: 1.1308 - val_loss: 217.6921 - val_mae: 3.4851\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6323 - mae: 1.2301 - val_loss: 250.5287 - val_mae: 3.7341\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4312 - mae: 1.0821 - val_loss: 193.4668 - val_mae: 3.3200\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.9236 - mae: 1.1997 - val_loss: 159.3380 - val_mae: 3.0143\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7787 - mae: 1.1223 - val_loss: 184.1900 - val_mae: 3.2383\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3497 - mae: 1.0847 - val_loss: 213.3838 - val_mae: 3.4725\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 6.8625 - mae: 0.9172 - val_loss: 193.5725 - val_mae: 3.3381\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9702 - mae: 1.0198 - val_loss: 161.6629 - val_mae: 3.0621\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4058 - mae: 1.0113 - val_loss: 201.4151 - val_mae: 3.3915\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9782 - mae: 1.1442 - val_loss: 160.0611 - val_mae: 3.0190\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5128 - mae: 1.1519 - val_loss: 157.7621 - val_mae: 3.0338\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4321 - mae: 1.1934 - val_loss: 162.2711 - val_mae: 3.0167\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.5801 - mae: 1.2559 - val_loss: 244.2139 - val_mae: 3.6827\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.2851 - mae: 1.1180 - val_loss: 213.3511 - val_mae: 3.5127\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0617 - mae: 1.0875 - val_loss: 275.1437 - val_mae: 3.8840\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4637 - mae: 1.1092 - val_loss: 189.7593 - val_mae: 3.3257\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.1230 - mae: 1.0216 - val_loss: 174.7323 - val_mae: 3.1595\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3005 - mae: 1.2343 - val_loss: 231.5555 - val_mae: 3.5979\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7691 - mae: 1.0295 - val_loss: 177.4853 - val_mae: 3.2369\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 6.1949 - mae: 0.8920 - val_loss: 179.0051 - val_mae: 3.2678\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9977 - mae: 1.0880 - val_loss: 219.6093 - val_mae: 3.5915\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0944 - mae: 1.0896 - val_loss: 211.0061 - val_mae: 3.5091\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.4753 - mae: 1.0497 - val_loss: 262.5322 - val_mae: 3.8713\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.3049 - mae: 0.9396 - val_loss: 206.1447 - val_mae: 3.4837\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0162 - mae: 1.0176 - val_loss: 237.0695 - val_mae: 3.6782\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8627 - mae: 1.0669 - val_loss: 210.7480 - val_mae: 3.4641\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.2387 - mae: 1.0142 - val_loss: 168.8585 - val_mae: 3.1471\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0031 - mae: 1.1193 - val_loss: 156.5971 - val_mae: 3.0854\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8454 - mae: 1.1522 - val_loss: 294.9556 - val_mae: 4.0381\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.0756 - mae: 1.0077 - val_loss: 239.9223 - val_mae: 3.7180\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6592 - mae: 1.2278 - val_loss: 166.7877 - val_mae: 3.1525\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6663 - mae: 1.0104 - val_loss: 186.5221 - val_mae: 3.3265\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1824 - mae: 1.1141 - val_loss: 176.8877 - val_mae: 3.1671\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 6.5989 - mae: 0.9015 - val_loss: 179.4129 - val_mae: 3.1966\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.2997 - mae: 1.1152 - val_loss: 193.7342 - val_mae: 3.3174\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5729 - mae: 1.1211 - val_loss: 246.0375 - val_mae: 3.6977\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6486 - mae: 1.2138 - val_loss: 246.7946 - val_mae: 3.7449\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0802 - mae: 1.1562 - val_loss: 203.2326 - val_mae: 3.4331\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5425 - mae: 1.1538 - val_loss: 208.6577 - val_mae: 3.4800\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4367 - mae: 1.1031 - val_loss: 167.6759 - val_mae: 3.1629\n",
      ">16, MAE: 2.209\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 460.0886 - mae: 4.1543 - val_loss: 209.2057 - val_mae: 3.5363\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 286.6117 - mae: 3.6919 - val_loss: 1089.7208 - val_mae: 7.9104\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 289.8694 - mae: 3.7165 - val_loss: 921.2253 - val_mae: 7.1131\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 220.6059 - mae: 3.2173 - val_loss: 119.3687 - val_mae: 3.0159\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 190.1735 - mae: 2.8967 - val_loss: 131.7954 - val_mae: 3.0457\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 101.1825 - mae: 2.5641 - val_loss: 421.9403 - val_mae: 4.6170\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 86.3821 - mae: 2.5484 - val_loss: 114.3436 - val_mae: 2.6937\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 94.7592 - mae: 2.4038 - val_loss: 234.9963 - val_mae: 3.3032\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 121.0133 - mae: 2.5561 - val_loss: 121.2263 - val_mae: 2.8054\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 121.6082 - mae: 2.3817 - val_loss: 468.6781 - val_mae: 4.2443\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.0701 - mae: 1.7472 - val_loss: 217.0667 - val_mae: 3.1819\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.6863 - mae: 2.0688 - val_loss: 443.5279 - val_mae: 4.1357\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.4260 - mae: 1.7764 - val_loss: 336.7817 - val_mae: 3.5385\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.8367 - mae: 1.9458 - val_loss: 313.4583 - val_mae: 3.5673\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.7901 - mae: 1.8367 - val_loss: 504.8411 - val_mae: 4.3756\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 110.9809 - mae: 2.2522 - val_loss: 395.9083 - val_mae: 3.9651\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.9588 - mae: 1.8060 - val_loss: 336.1906 - val_mae: 3.6561\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.7483 - mae: 2.0018 - val_loss: 337.7339 - val_mae: 3.6525\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.5981 - mae: 1.6710 - val_loss: 452.0342 - val_mae: 4.1515\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.0984 - mae: 1.9569 - val_loss: 351.3802 - val_mae: 3.7622\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.7751 - mae: 1.6478 - val_loss: 321.3671 - val_mae: 3.5808\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.9395 - mae: 1.7455 - val_loss: 315.0796 - val_mae: 3.5809\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.5233 - mae: 1.8299 - val_loss: 250.8177 - val_mae: 3.2397\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 67.0173 - mae: 2.0479 - val_loss: 358.2894 - val_mae: 3.7811\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.9642 - mae: 1.7119 - val_loss: 299.1857 - val_mae: 3.4884\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.0902 - mae: 1.5624 - val_loss: 426.3027 - val_mae: 4.1335\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.9396 - mae: 1.7764 - val_loss: 298.5182 - val_mae: 3.4968\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.1882 - mae: 1.8969 - val_loss: 544.3386 - val_mae: 4.4956\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.3680 - mae: 1.8660 - val_loss: 196.2397 - val_mae: 3.1667\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.1083 - mae: 1.8363 - val_loss: 450.5396 - val_mae: 4.1924\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.4534 - mae: 1.8109 - val_loss: 708.1866 - val_mae: 5.2032\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.9305 - mae: 1.9913 - val_loss: 252.3671 - val_mae: 3.3215\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.3967 - mae: 1.6302 - val_loss: 331.5906 - val_mae: 3.6381\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.5763 - mae: 1.6295 - val_loss: 378.9330 - val_mae: 3.9042\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.4915 - mae: 1.6630 - val_loss: 325.9839 - val_mae: 3.6396\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.9454 - mae: 1.6785 - val_loss: 638.7676 - val_mae: 4.8883\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 44.7597 - mae: 1.8380 - val_loss: 275.3159 - val_mae: 3.4187\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.0710 - mae: 1.8402 - val_loss: 534.5909 - val_mae: 4.4991\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.6510 - mae: 1.8544 - val_loss: 164.8956 - val_mae: 3.0923\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.3217 - mae: 1.7154 - val_loss: 308.5652 - val_mae: 3.5699\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1664 - mae: 1.5676 - val_loss: 365.5337 - val_mae: 3.8515\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 39.8191 - mae: 1.6475 - val_loss: 385.2179 - val_mae: 3.9008\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 32.7861 - mae: 1.5262 - val_loss: 322.2349 - val_mae: 3.7544\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3579 - mae: 1.3434 - val_loss: 345.6271 - val_mae: 3.8428\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.1069 - mae: 1.6021 - val_loss: 393.3841 - val_mae: 3.9946\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.6848 - mae: 1.8598 - val_loss: 293.3055 - val_mae: 3.6353\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.2529 - mae: 1.5880 - val_loss: 404.3015 - val_mae: 4.0469\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.3131 - mae: 1.5325 - val_loss: 347.4091 - val_mae: 3.7934\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.6763 - mae: 1.5123 - val_loss: 430.4595 - val_mae: 4.1999\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.9875 - mae: 1.3103 - val_loss: 313.3720 - val_mae: 3.7020\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.5693 - mae: 1.5774 - val_loss: 228.6615 - val_mae: 3.2951\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8797 - mae: 1.4128 - val_loss: 316.2776 - val_mae: 3.6720\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.9920 - mae: 1.4541 - val_loss: 230.5977 - val_mae: 3.3677\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.9951 - mae: 1.5111 - val_loss: 337.5593 - val_mae: 3.8823\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.4746 - mae: 1.7041 - val_loss: 333.6371 - val_mae: 3.8129\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6850 - mae: 1.3964 - val_loss: 319.2280 - val_mae: 3.6885\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.0827 - mae: 1.5383 - val_loss: 209.4983 - val_mae: 3.2610\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.3873 - mae: 1.4740 - val_loss: 311.9037 - val_mae: 3.6732\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.1499 - mae: 1.6902 - val_loss: 427.6466 - val_mae: 4.1329\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9842 - mae: 1.6174 - val_loss: 468.0033 - val_mae: 4.2389\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.1089 - mae: 1.6470 - val_loss: 348.5797 - val_mae: 3.8708\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7832 - mae: 1.4629 - val_loss: 362.9352 - val_mae: 3.9236\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.6108 - mae: 1.5088 - val_loss: 296.9424 - val_mae: 3.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6981 - mae: 1.4430 - val_loss: 383.6242 - val_mae: 4.0447\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.0169 - mae: 1.3575 - val_loss: 270.4918 - val_mae: 3.4927\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.3065 - mae: 1.5682 - val_loss: 218.6914 - val_mae: 3.2235\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.8245 - mae: 1.5838 - val_loss: 266.5456 - val_mae: 3.4352\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2164 - mae: 1.4220 - val_loss: 348.4542 - val_mae: 3.7616\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5963 - mae: 1.4209 - val_loss: 257.9115 - val_mae: 3.4031\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.7729 - mae: 1.3065 - val_loss: 362.9000 - val_mae: 3.8934\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3481 - mae: 1.2910 - val_loss: 295.2030 - val_mae: 3.5844\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9601 - mae: 1.5176 - val_loss: 279.2854 - val_mae: 3.4663\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7308 - mae: 1.3967 - val_loss: 389.9544 - val_mae: 3.9630\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.2465 - mae: 1.5727 - val_loss: 216.6429 - val_mae: 3.2145\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7317 - mae: 1.5473 - val_loss: 349.4730 - val_mae: 3.8309\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.0431 - mae: 1.5271 - val_loss: 280.6174 - val_mae: 3.5390\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8603 - mae: 1.3843 - val_loss: 218.5380 - val_mae: 3.2034\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3082 - mae: 1.3228 - val_loss: 291.6777 - val_mae: 3.5092\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.0143 - mae: 1.3348 - val_loss: 309.0742 - val_mae: 3.6038\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0545 - mae: 1.2810 - val_loss: 277.6138 - val_mae: 3.4788\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2827 - mae: 1.3173 - val_loss: 315.4189 - val_mae: 3.5970\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.1839 - mae: 1.4015 - val_loss: 241.8943 - val_mae: 3.3605\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8990 - mae: 1.4112 - val_loss: 242.0567 - val_mae: 3.3555\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.7778 - mae: 1.4821 - val_loss: 224.5574 - val_mae: 3.2754\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6603 - mae: 1.2616 - val_loss: 200.4458 - val_mae: 3.1554\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2916 - mae: 1.3155 - val_loss: 211.7722 - val_mae: 3.1986\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 52.8766 - mae: 1.6995 - val_loss: 289.4837 - val_mae: 3.5194\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2773 - mae: 1.3064 - val_loss: 348.3819 - val_mae: 3.8110\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.9515 - mae: 1.3395 - val_loss: 280.0099 - val_mae: 3.5511\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.6730 - mae: 1.3832 - val_loss: 352.5201 - val_mae: 3.8317\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1770 - mae: 1.3206 - val_loss: 250.4823 - val_mae: 3.4536\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3427 - mae: 1.4055 - val_loss: 242.2081 - val_mae: 3.3607\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9488 - mae: 1.3158 - val_loss: 256.8346 - val_mae: 3.5097\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.1305 - mae: 1.3676 - val_loss: 177.0890 - val_mae: 3.1161\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8121 - mae: 1.2552 - val_loss: 265.7065 - val_mae: 3.5078\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3937 - mae: 1.2818 - val_loss: 296.7793 - val_mae: 3.7429\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6526 - mae: 1.2384 - val_loss: 183.7887 - val_mae: 3.2098\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5502 - mae: 1.2761 - val_loss: 247.3173 - val_mae: 3.4252\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6025 - mae: 1.2450 - val_loss: 184.7295 - val_mae: 3.1211\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3206 - mae: 1.1957 - val_loss: 239.6814 - val_mae: 3.3963\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.5985 - mae: 1.5289 - val_loss: 157.5223 - val_mae: 2.9739\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.9696 - mae: 1.2885 - val_loss: 200.6023 - val_mae: 3.1776\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.7933 - mae: 1.1922 - val_loss: 183.0403 - val_mae: 3.0516\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.8352 - mae: 1.2325 - val_loss: 218.1537 - val_mae: 3.2927\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.3987 - mae: 1.3849 - val_loss: 145.9602 - val_mae: 2.8321\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.6964 - mae: 1.4909 - val_loss: 163.1658 - val_mae: 3.1008\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.4961 - mae: 1.2408 - val_loss: 235.9920 - val_mae: 3.4261\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.0409 - mae: 1.2855 - val_loss: 198.0695 - val_mae: 3.2922\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.1066 - mae: 1.2629 - val_loss: 134.7731 - val_mae: 2.9946\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2824 - mae: 1.3598 - val_loss: 197.9581 - val_mae: 3.3212\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3445 - mae: 1.2488 - val_loss: 254.3399 - val_mae: 3.6331\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.1034 - mae: 1.2571 - val_loss: 245.0211 - val_mae: 3.5746\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3960 - mae: 1.2223 - val_loss: 180.7292 - val_mae: 3.2246\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7657 - mae: 1.2667 - val_loss: 160.5160 - val_mae: 3.0661\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0130 - mae: 1.0794 - val_loss: 176.9578 - val_mae: 3.0958\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.7749 - mae: 1.4070 - val_loss: 171.7270 - val_mae: 3.0634\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8039 - mae: 1.1903 - val_loss: 234.0401 - val_mae: 3.4095\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7156 - mae: 1.1648 - val_loss: 201.0149 - val_mae: 3.2762\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2753 - mae: 1.2009 - val_loss: 174.3582 - val_mae: 3.1311\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6506 - mae: 1.1163 - val_loss: 198.3941 - val_mae: 3.2248\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6952 - mae: 1.2464 - val_loss: 142.1530 - val_mae: 2.8745\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1361 - mae: 1.2538 - val_loss: 204.2642 - val_mae: 3.2613\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.9954 - mae: 1.3233 - val_loss: 139.0229 - val_mae: 2.8641\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2879 - mae: 1.1058 - val_loss: 217.9702 - val_mae: 3.3580\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7214 - mae: 1.1330 - val_loss: 148.9657 - val_mae: 2.9050\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3032 - mae: 1.0646 - val_loss: 224.0987 - val_mae: 3.3423\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6724 - mae: 1.1525 - val_loss: 154.7570 - val_mae: 2.9489\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6841 - mae: 1.1440 - val_loss: 193.6511 - val_mae: 3.1994\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3253 - mae: 1.3258 - val_loss: 145.6590 - val_mae: 2.8599\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6012 - mae: 1.0834 - val_loss: 189.1797 - val_mae: 3.2232\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.0359 - mae: 1.0397 - val_loss: 201.9535 - val_mae: 3.2543\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7711 - mae: 1.2281 - val_loss: 160.0909 - val_mae: 2.9561\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2208 - mae: 1.2934 - val_loss: 265.0129 - val_mae: 3.6504\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9261 - mae: 1.2478 - val_loss: 167.8423 - val_mae: 3.0825\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2951 - mae: 1.1488 - val_loss: 137.1077 - val_mae: 2.8095\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7163 - mae: 1.1409 - val_loss: 170.5380 - val_mae: 3.0827\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8114 - mae: 1.1651 - val_loss: 194.2256 - val_mae: 3.2533\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8670 - mae: 1.0938 - val_loss: 140.6106 - val_mae: 2.9140\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2239 - mae: 1.1024 - val_loss: 163.5251 - val_mae: 3.0406\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.0131 - mae: 1.0628 - val_loss: 145.6219 - val_mae: 2.9132\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7412 - mae: 1.1723 - val_loss: 159.0716 - val_mae: 2.9635\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5325 - mae: 1.2197 - val_loss: 202.5633 - val_mae: 3.2844\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1784 - mae: 1.0799 - val_loss: 164.2079 - val_mae: 3.0089\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2111 - mae: 1.2448 - val_loss: 166.1127 - val_mae: 3.0113\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.9598 - mae: 1.1164 - val_loss: 182.5223 - val_mae: 3.1279\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0741 - mae: 1.1908 - val_loss: 129.6451 - val_mae: 2.7303\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5415 - mae: 1.1786 - val_loss: 173.3711 - val_mae: 3.0934\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.3882 - mae: 1.2602 - val_loss: 149.5394 - val_mae: 2.9732\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.8054 - mae: 1.0449 - val_loss: 185.0296 - val_mae: 3.1202\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0026 - mae: 1.1657 - val_loss: 187.9265 - val_mae: 3.1465\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9587 - mae: 1.0394 - val_loss: 157.8912 - val_mae: 3.0401\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7283 - mae: 1.1920 - val_loss: 175.2172 - val_mae: 3.1564\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.5598 - mae: 1.3357 - val_loss: 154.2416 - val_mae: 2.9941\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.8401 - mae: 1.3431 - val_loss: 111.8409 - val_mae: 2.5876\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4636 - mae: 1.2379 - val_loss: 210.8536 - val_mae: 3.3051\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4895 - mae: 1.1386 - val_loss: 219.4479 - val_mae: 3.3711\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.4668 - mae: 1.1129 - val_loss: 198.5987 - val_mae: 3.2270\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.5526 - mae: 1.0033 - val_loss: 204.6729 - val_mae: 3.2941\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7497 - mae: 1.0850 - val_loss: 126.9467 - val_mae: 2.7569\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5045 - mae: 1.2125 - val_loss: 162.9687 - val_mae: 2.9874\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3457 - mae: 1.0546 - val_loss: 174.0493 - val_mae: 3.0586\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2902 - mae: 1.1425 - val_loss: 241.0983 - val_mae: 3.5085\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.2308 - mae: 1.0956 - val_loss: 146.2241 - val_mae: 2.8621\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7764 - mae: 1.1463 - val_loss: 136.3719 - val_mae: 2.7594\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.9582 - mae: 0.9732 - val_loss: 133.5072 - val_mae: 2.7316\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8202 - mae: 1.0722 - val_loss: 183.1780 - val_mae: 3.1135\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6343 - mae: 1.1037 - val_loss: 140.0553 - val_mae: 2.8602\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8935 - mae: 1.0080 - val_loss: 202.0730 - val_mae: 3.2581\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.0641 - mae: 1.1575 - val_loss: 129.2800 - val_mae: 2.7235\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.4469 - mae: 1.1478 - val_loss: 180.2739 - val_mae: 3.0917\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9139 - mae: 1.0314 - val_loss: 154.5252 - val_mae: 2.9394\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5998 - mae: 1.1338 - val_loss: 182.4825 - val_mae: 3.1338\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3546 - mae: 1.0809 - val_loss: 135.6695 - val_mae: 2.7700\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7595 - mae: 1.0324 - val_loss: 130.7115 - val_mae: 2.7099\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.3172 - mae: 1.0396 - val_loss: 177.8828 - val_mae: 3.0530\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8338 - mae: 1.0957 - val_loss: 142.2680 - val_mae: 2.8041\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.9948 - mae: 1.2639 - val_loss: 189.1497 - val_mae: 3.1699\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.4049 - mae: 1.0957 - val_loss: 169.8938 - val_mae: 3.0327\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1225 - mae: 1.1681 - val_loss: 108.0586 - val_mae: 2.2634\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.0613 - mae: 1.2000 - val_loss: 186.4180 - val_mae: 3.1714\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2287 - mae: 1.1893 - val_loss: 140.2288 - val_mae: 2.7779\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 12.3747 - mae: 1.1046 - val_loss: 203.8312 - val_mae: 3.2775\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7922 - mae: 1.0994 - val_loss: 120.4217 - val_mae: 2.5624\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.9928 - mae: 1.1924 - val_loss: 179.3336 - val_mae: 3.1291\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9090 - mae: 0.9520 - val_loss: 199.1624 - val_mae: 3.2727\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8853 - mae: 1.2491 - val_loss: 170.2105 - val_mae: 3.0574\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.4899 - mae: 1.0179 - val_loss: 151.2969 - val_mae: 2.9358\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0252 - mae: 1.0810 - val_loss: 125.5636 - val_mae: 2.6683\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3266 - mae: 1.1119 - val_loss: 139.3442 - val_mae: 2.8501\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7578 - mae: 1.0688 - val_loss: 137.1203 - val_mae: 2.7466\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1559 - mae: 1.2601 - val_loss: 115.7496 - val_mae: 2.4298\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4821 - mae: 1.1636 - val_loss: 176.4977 - val_mae: 3.1169\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5748 - mae: 1.1969 - val_loss: 118.8701 - val_mae: 2.4678\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4155 - mae: 1.1099 - val_loss: 143.8122 - val_mae: 2.8446\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.6366 - mae: 1.3319 - val_loss: 191.0201 - val_mae: 3.2233\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.6305 - mae: 1.3734 - val_loss: 123.1878 - val_mae: 2.4545\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4283 - mae: 1.0393 - val_loss: 150.4392 - val_mae: 2.8348\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.9994 - mae: 1.2582 - val_loss: 195.1883 - val_mae: 3.1738\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.1439 - mae: 1.0454 - val_loss: 180.5163 - val_mae: 3.0593\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5877 - mae: 1.2136 - val_loss: 171.9387 - val_mae: 2.9828\n",
      ">17, MAE: 2.149\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 2s 2ms/step - loss: 263.1794 - mae: 4.1248 - val_loss: 178.2285 - val_mae: 3.4809\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 308.4216 - mae: 3.5759 - val_loss: 163.5145 - val_mae: 3.1265\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 324.2000 - mae: 3.4450 - val_loss: 123.9020 - val_mae: 2.9993\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 195.4092 - mae: 3.1715 - val_loss: 104.5443 - val_mae: 2.6664\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 114.9394 - mae: 2.6322 - val_loss: 555.5870 - val_mae: 5.7612\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 92.9944 - mae: 2.4485 - val_loss: 96.1701 - val_mae: 2.5570\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 187.8140 - mae: 2.9885 - val_loss: 167.9222 - val_mae: 3.2745\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 74.8957 - mae: 2.3329 - val_loss: 184.5559 - val_mae: 3.3362\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.7558 - mae: 2.2256 - val_loss: 363.3837 - val_mae: 4.4054\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 96.5594 - mae: 2.2341 - val_loss: 386.1103 - val_mae: 4.1942\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 136.2596 - mae: 2.7000 - val_loss: 408.4224 - val_mae: 4.2738\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.6419 - mae: 1.9541 - val_loss: 305.9902 - val_mae: 3.5196\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 70.6234 - mae: 2.1664 - val_loss: 240.2528 - val_mae: 3.2501\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 82.2027 - mae: 2.3796 - val_loss: 246.4136 - val_mae: 3.2511\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 56.5580 - mae: 2.0238 - val_loss: 302.1561 - val_mae: 3.5985\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.4563 - mae: 2.2288 - val_loss: 266.8285 - val_mae: 3.4432\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 87.4960 - mae: 2.2370 - val_loss: 614.8871 - val_mae: 5.0540\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.7905 - mae: 1.7585 - val_loss: 307.6321 - val_mae: 3.5502\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.2076 - mae: 2.1142 - val_loss: 378.9230 - val_mae: 3.9419\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 53.1759 - mae: 1.8094 - val_loss: 392.5931 - val_mae: 3.9329\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 51.6288 - mae: 1.9223 - val_loss: 317.3932 - val_mae: 3.5660\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.1650 - mae: 1.8201 - val_loss: 393.4758 - val_mae: 3.9378\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 32.4371 - mae: 1.6734 - val_loss: 441.5384 - val_mae: 4.1178\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.4520 - mae: 1.9309 - val_loss: 331.7427 - val_mae: 3.7534\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 41.3981 - mae: 1.8230 - val_loss: 303.3038 - val_mae: 3.5745\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 34.5163 - mae: 1.6710 - val_loss: 343.1325 - val_mae: 3.6419\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 35.1700 - mae: 1.6734 - val_loss: 197.8977 - val_mae: 3.0599\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 55.2360 - mae: 2.0001 - val_loss: 365.1061 - val_mae: 3.7632\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 22.2062 - mae: 1.4988 - val_loss: 310.2837 - val_mae: 3.4533\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.1404 - mae: 1.7392 - val_loss: 231.7269 - val_mae: 3.0826\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 38.6584 - mae: 1.5226 - val_loss: 351.5820 - val_mae: 3.7173\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 33.5164 - mae: 1.6694 - val_loss: 415.9919 - val_mae: 3.9599\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 43.4621 - mae: 1.7517 - val_loss: 253.9302 - val_mae: 3.2575\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.6585 - mae: 1.5970 - val_loss: 263.6300 - val_mae: 3.4203\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.1606 - mae: 1.6701 - val_loss: 371.5370 - val_mae: 3.8197\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.4190 - mae: 1.6748 - val_loss: 427.7768 - val_mae: 4.0211\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.7307 - mae: 1.7802 - val_loss: 232.3796 - val_mae: 3.2937\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 49.5973 - mae: 1.7757 - val_loss: 325.7690 - val_mae: 3.6004\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 3ms/step - loss: 34.0391 - mae: 1.6680 - val_loss: 210.0771 - val_mae: 3.0706\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.9786 - mae: 1.6983 - val_loss: 281.4383 - val_mae: 3.4871\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7263 - mae: 1.4920 - val_loss: 250.9597 - val_mae: 3.3141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 33.1489 - mae: 1.7202 - val_loss: 344.1644 - val_mae: 3.7515\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 24.7054 - mae: 1.4953 - val_loss: 253.7766 - val_mae: 3.3193\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 55.3384 - mae: 1.5814 - val_loss: 348.2086 - val_mae: 3.7457\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.5161 - mae: 1.5267 - val_loss: 306.0938 - val_mae: 3.6097\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3540 - mae: 1.4508 - val_loss: 331.6117 - val_mae: 3.6946\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 30.8255 - mae: 1.6686 - val_loss: 273.7722 - val_mae: 3.3818\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 24.6676 - mae: 1.4632 - val_loss: 221.1721 - val_mae: 3.1651\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.8886 - mae: 1.7016 - val_loss: 445.1320 - val_mae: 4.2578\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 35.6614 - mae: 1.6751 - val_loss: 321.3760 - val_mae: 3.6916\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 31.5651 - mae: 1.6143 - val_loss: 276.6207 - val_mae: 3.4985\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.8707 - mae: 1.4138 - val_loss: 340.2035 - val_mae: 3.7908\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 33.9148 - mae: 1.5494 - val_loss: 252.2969 - val_mae: 3.3562\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.5137 - mae: 1.3589 - val_loss: 228.1967 - val_mae: 3.3532\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.3928 - mae: 1.4572 - val_loss: 306.1538 - val_mae: 3.6504\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.6857 - mae: 1.3493 - val_loss: 287.3629 - val_mae: 3.4603\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 36.7127 - mae: 1.5373 - val_loss: 209.0065 - val_mae: 3.0917\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4212 - mae: 1.5594 - val_loss: 297.3103 - val_mae: 3.5196\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.2591 - mae: 1.5684 - val_loss: 275.9697 - val_mae: 3.3617\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9917 - mae: 1.4336 - val_loss: 266.4295 - val_mae: 3.3570\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.9218 - mae: 1.4776 - val_loss: 254.7922 - val_mae: 3.3529\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.1914 - mae: 1.2578 - val_loss: 291.1956 - val_mae: 3.5032\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3239 - mae: 1.4296 - val_loss: 218.3935 - val_mae: 3.1173\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.4368 - mae: 1.4714 - val_loss: 287.6773 - val_mae: 3.4852\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.1707 - mae: 1.5129 - val_loss: 348.1893 - val_mae: 3.7466\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.1741 - mae: 1.5623 - val_loss: 383.1029 - val_mae: 3.7562\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4067 - mae: 1.3715 - val_loss: 447.2318 - val_mae: 4.1156\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.7487 - mae: 1.4046 - val_loss: 283.2935 - val_mae: 3.4255\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6176 - mae: 1.3391 - val_loss: 351.0641 - val_mae: 3.6663\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.1211 - mae: 1.6201 - val_loss: 316.3474 - val_mae: 3.6623\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.8536 - mae: 1.4935 - val_loss: 193.8066 - val_mae: 3.0420\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.5618 - mae: 1.5831 - val_loss: 130.9493 - val_mae: 2.6642\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 35.9629 - mae: 1.5188 - val_loss: 202.7447 - val_mae: 3.1626\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4952 - mae: 1.3495 - val_loss: 229.7636 - val_mae: 3.2352\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0623 - mae: 1.3111 - val_loss: 259.1553 - val_mae: 3.3629\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.0951 - mae: 1.5345 - val_loss: 260.2766 - val_mae: 3.3669\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.6726 - mae: 1.3697 - val_loss: 255.7263 - val_mae: 3.2476\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5259 - mae: 1.3765 - val_loss: 205.8697 - val_mae: 3.1307\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 28.4974 - mae: 1.4883 - val_loss: 136.0062 - val_mae: 2.7357\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.2872 - mae: 1.2015 - val_loss: 164.1266 - val_mae: 2.8315\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 29.6355 - mae: 1.5106 - val_loss: 339.4532 - val_mae: 3.7224\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.4821 - mae: 1.4775 - val_loss: 204.9881 - val_mae: 3.0998\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3164 - mae: 1.1829 - val_loss: 340.8969 - val_mae: 3.7142\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.3201 - mae: 1.4571 - val_loss: 328.1630 - val_mae: 3.6853\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.6835 - mae: 1.3232 - val_loss: 237.2491 - val_mae: 3.2880\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4190 - mae: 1.3448 - val_loss: 199.9551 - val_mae: 3.0670\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5467 - mae: 1.2743 - val_loss: 234.6821 - val_mae: 3.2158\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.3052 - mae: 1.3829 - val_loss: 180.4602 - val_mae: 2.9793\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.1903 - mae: 1.4028 - val_loss: 217.8847 - val_mae: 3.2505\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6809 - mae: 1.3037 - val_loss: 196.9803 - val_mae: 3.1206\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.5096 - mae: 1.4932 - val_loss: 486.5789 - val_mae: 4.5203\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6329 - mae: 1.4737 - val_loss: 202.9422 - val_mae: 3.0981\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.7896 - mae: 1.1342 - val_loss: 205.4811 - val_mae: 3.0850\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7614 - mae: 1.2615 - val_loss: 194.1555 - val_mae: 3.0388\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5775 - mae: 1.2360 - val_loss: 225.8309 - val_mae: 3.2042\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.1973 - mae: 1.3674 - val_loss: 251.8190 - val_mae: 3.3056\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.7888 - mae: 1.3422 - val_loss: 255.6889 - val_mae: 3.3308\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0259 - mae: 1.2780 - val_loss: 219.8158 - val_mae: 3.1475\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.8589 - mae: 1.5178 - val_loss: 179.7082 - val_mae: 2.9932\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5629 - mae: 1.3700 - val_loss: 190.5550 - val_mae: 3.0773\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.8884 - mae: 1.2811 - val_loss: 181.1404 - val_mae: 2.9396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0285 - mae: 1.1866 - val_loss: 198.6012 - val_mae: 3.0618\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.4925 - mae: 1.1989 - val_loss: 271.0188 - val_mae: 3.6285\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 23.3882 - mae: 1.4553 - val_loss: 226.9912 - val_mae: 3.2486\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 26.5457 - mae: 1.4366 - val_loss: 164.3017 - val_mae: 2.9354\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.1834 - mae: 1.5242 - val_loss: 240.9854 - val_mae: 3.3229\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6927 - mae: 1.1693 - val_loss: 152.5806 - val_mae: 2.8000\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4642 - mae: 1.3137 - val_loss: 190.9286 - val_mae: 3.0169\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.4357 - mae: 1.2060 - val_loss: 212.0936 - val_mae: 3.1620\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.5386 - mae: 1.3060 - val_loss: 187.0006 - val_mae: 2.9769\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 14.9246 - mae: 1.2557 - val_loss: 217.5269 - val_mae: 3.1731\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 17.8286 - mae: 1.2295 - val_loss: 149.0528 - val_mae: 2.8107\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5920 - mae: 1.3473 - val_loss: 214.9126 - val_mae: 3.1735\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.2908 - mae: 1.2526 - val_loss: 358.0344 - val_mae: 3.9508\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8138 - mae: 1.1706 - val_loss: 199.3697 - val_mae: 3.0263\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.9311 - mae: 1.2263 - val_loss: 188.8678 - val_mae: 2.9716\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5303 - mae: 1.1712 - val_loss: 252.7080 - val_mae: 3.3903\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.7743 - mae: 1.2054 - val_loss: 227.6335 - val_mae: 3.2514\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2981 - mae: 1.2369 - val_loss: 213.9681 - val_mae: 3.1055\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.8472 - mae: 1.1412 - val_loss: 210.1154 - val_mae: 3.1130\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4389 - mae: 1.2019 - val_loss: 169.8606 - val_mae: 2.8423\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.4440 - mae: 1.0385 - val_loss: 179.1910 - val_mae: 2.9341\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.6225 - mae: 1.0851 - val_loss: 211.6957 - val_mae: 3.0976\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5720 - mae: 1.1331 - val_loss: 212.4457 - val_mae: 3.0790\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6874 - mae: 1.2371 - val_loss: 176.6585 - val_mae: 2.9004\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4819 - mae: 1.1854 - val_loss: 201.4371 - val_mae: 3.0085\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.5991 - mae: 1.3734 - val_loss: 221.8392 - val_mae: 3.1626\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.2317 - mae: 1.2605 - val_loss: 193.5659 - val_mae: 2.9976\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.3272 - mae: 1.3416 - val_loss: 248.4104 - val_mae: 3.3825\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8659 - mae: 1.2573 - val_loss: 147.9697 - val_mae: 2.7176\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1686 - mae: 1.1599 - val_loss: 165.6325 - val_mae: 2.8522\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0616 - mae: 1.2015 - val_loss: 191.1880 - val_mae: 2.9858\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.5403 - mae: 1.0008 - val_loss: 169.4938 - val_mae: 2.8154\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5335 - mae: 1.1822 - val_loss: 218.7502 - val_mae: 3.0952\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3042 - mae: 1.3297 - val_loss: 228.2268 - val_mae: 3.1436\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.0765 - mae: 1.6034 - val_loss: 75.2097 - val_mae: 2.4190\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.4699 - mae: 1.4195 - val_loss: 196.4332 - val_mae: 3.0130\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.2192 - mae: 1.1589 - val_loss: 129.1149 - val_mae: 2.5726\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3116 - mae: 1.1686 - val_loss: 133.6523 - val_mae: 2.5623\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7120 - mae: 1.2300 - val_loss: 210.0595 - val_mae: 3.0524\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7903 - mae: 1.2764 - val_loss: 134.0292 - val_mae: 2.6005\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5360 - mae: 1.2745 - val_loss: 131.6440 - val_mae: 2.5479\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5012 - mae: 1.1803 - val_loss: 162.5598 - val_mae: 2.8297\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.9005 - mae: 1.1344 - val_loss: 177.0775 - val_mae: 2.8774\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.6086 - mae: 1.3677 - val_loss: 164.9955 - val_mae: 2.8345\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.7816 - mae: 1.2127 - val_loss: 202.9594 - val_mae: 3.0197\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.2850 - mae: 1.2041 - val_loss: 209.2274 - val_mae: 3.0839\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.3999 - mae: 1.2273 - val_loss: 149.1746 - val_mae: 2.6777\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1133 - mae: 1.2360 - val_loss: 204.8274 - val_mae: 3.0548\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4475 - mae: 1.3067 - val_loss: 212.8493 - val_mae: 3.1652\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0751 - mae: 1.1762 - val_loss: 140.3670 - val_mae: 2.6863\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1400 - mae: 1.1817 - val_loss: 171.7979 - val_mae: 2.8610\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9000 - mae: 1.1645 - val_loss: 174.9466 - val_mae: 2.8623\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8235 - mae: 1.2210 - val_loss: 119.7196 - val_mae: 2.4442\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9731 - mae: 1.1862 - val_loss: 192.6524 - val_mae: 2.9530\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4117 - mae: 1.1417 - val_loss: 163.6343 - val_mae: 2.7380\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.6465 - mae: 1.0703 - val_loss: 147.5822 - val_mae: 2.6594\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.9624 - mae: 1.1749 - val_loss: 350.3117 - val_mae: 4.0320\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.5732 - mae: 1.1779 - val_loss: 212.7205 - val_mae: 3.0410\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4703 - mae: 1.1705 - val_loss: 207.0005 - val_mae: 3.0464\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6277 - mae: 1.1341 - val_loss: 201.0710 - val_mae: 3.0134\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3249 - mae: 1.1457 - val_loss: 132.7792 - val_mae: 2.5985\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1440 - mae: 1.1731 - val_loss: 164.4149 - val_mae: 2.8264\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4257 - mae: 1.1088 - val_loss: 204.8404 - val_mae: 3.0571\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5788 - mae: 1.1376 - val_loss: 131.7549 - val_mae: 2.5897\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.1747 - mae: 1.1602 - val_loss: 175.8597 - val_mae: 2.8967\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.7729 - mae: 1.0570 - val_loss: 170.3722 - val_mae: 2.8662\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 12.4242 - mae: 1.1345 - val_loss: 216.7858 - val_mae: 3.2054\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.8871 - mae: 1.0603 - val_loss: 190.4633 - val_mae: 3.0101\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.6837 - mae: 1.0424 - val_loss: 139.5772 - val_mae: 2.6579\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.2783 - mae: 1.1000 - val_loss: 151.6036 - val_mae: 2.7179\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.2888 - mae: 1.1344 - val_loss: 145.6428 - val_mae: 2.7044\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.4224 - mae: 1.2734 - val_loss: 117.2022 - val_mae: 2.4848\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.9510 - mae: 1.0839 - val_loss: 184.7749 - val_mae: 2.9423\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7709 - mae: 1.0705 - val_loss: 174.5469 - val_mae: 2.8995\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 15.7256 - mae: 1.1682 - val_loss: 151.2505 - val_mae: 2.6608\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 13.6261 - mae: 1.1246 - val_loss: 154.1738 - val_mae: 2.7574\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.4053 - mae: 1.1961 - val_loss: 142.0631 - val_mae: 2.6502\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6832 - mae: 1.1170 - val_loss: 178.2675 - val_mae: 2.9579\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.5833 - mae: 1.0928 - val_loss: 140.8705 - val_mae: 2.6784\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5538 - mae: 1.1108 - val_loss: 158.3599 - val_mae: 2.8026\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.2409 - mae: 1.0100 - val_loss: 145.9818 - val_mae: 2.6699\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6459 - mae: 1.1701 - val_loss: 165.8320 - val_mae: 2.8137\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0948 - mae: 1.0644 - val_loss: 127.0155 - val_mae: 2.5120\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5852 - mae: 1.3296 - val_loss: 100.9119 - val_mae: 2.2941\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.4053 - mae: 1.0954 - val_loss: 120.6898 - val_mae: 2.4942\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5576 - mae: 1.1373 - val_loss: 155.6541 - val_mae: 2.7349\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.0455 - mae: 0.9719 - val_loss: 116.1304 - val_mae: 2.4532\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 8.4418 - mae: 0.9889 - val_loss: 131.8985 - val_mae: 2.5812\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.9659 - mae: 1.0685 - val_loss: 105.9902 - val_mae: 2.3679\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6308 - mae: 1.0903 - val_loss: 116.2997 - val_mae: 2.4917\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8920 - mae: 1.0951 - val_loss: 192.8721 - val_mae: 3.0481\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9094 - mae: 1.0151 - val_loss: 141.3422 - val_mae: 2.6937\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 9.2860 - mae: 0.9962 - val_loss: 156.2357 - val_mae: 2.7738\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 19.4484 - mae: 1.1294 - val_loss: 152.5870 - val_mae: 2.8008\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.5027 - mae: 1.1335 - val_loss: 216.2878 - val_mae: 3.2525\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.6546 - mae: 1.0359 - val_loss: 135.3106 - val_mae: 2.6371\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2023 - mae: 1.1555 - val_loss: 133.9240 - val_mae: 2.6361\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.1025 - mae: 0.9921 - val_loss: 147.3806 - val_mae: 2.7538\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.8334 - mae: 1.1184 - val_loss: 180.1169 - val_mae: 3.0200\n",
      ">18, MAE: 1.828\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 518.4969 - mae: 4.9095 - val_loss: 187.2410 - val_mae: 3.3414\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 215.0215 - mae: 3.3567 - val_loss: 160.1966 - val_mae: 3.0111\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 267.9652 - mae: 3.4469 - val_loss: 146.4302 - val_mae: 3.2943\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 180.1512 - mae: 2.9212 - val_loss: 122.2813 - val_mae: 2.9546\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 145.2922 - mae: 2.7508 - val_loss: 178.7023 - val_mae: 3.3398\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 78.4540 - mae: 2.2825 - val_loss: 151.4116 - val_mae: 2.9853\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 96.4163 - mae: 2.4327 - val_loss: 238.5498 - val_mae: 3.4408\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 71.9032 - mae: 2.1164 - val_loss: 165.8420 - val_mae: 2.9536\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 115.7101 - mae: 2.3372 - val_loss: 259.2680 - val_mae: 3.3015\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 60.8370 - mae: 2.0279 - val_loss: 550.8799 - val_mae: 4.5824\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.2811 - mae: 1.9402 - val_loss: 349.0384 - val_mae: 3.7130\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 90.2404 - mae: 2.0835 - val_loss: 538.0961 - val_mae: 4.5031\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 71.0937 - mae: 2.0100 - val_loss: 647.5485 - val_mae: 4.8643\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 57.0051 - mae: 1.9283 - val_loss: 236.1099 - val_mae: 3.3880\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 74.4384 - mae: 2.1495 - val_loss: 282.4835 - val_mae: 3.4297\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 57.8984 - mae: 1.9832 - val_loss: 343.4445 - val_mae: 3.8012\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 71.1095 - mae: 2.1089 - val_loss: 598.6339 - val_mae: 4.7031\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 64.7906 - mae: 2.0343 - val_loss: 580.5693 - val_mae: 4.6332\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 101.9689 - mae: 2.3114 - val_loss: 425.4630 - val_mae: 3.9807\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 73.1138 - mae: 2.0108 - val_loss: 228.4799 - val_mae: 3.3817\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.9650 - mae: 1.8771 - val_loss: 227.8514 - val_mae: 3.4501\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.3488 - mae: 1.7350 - val_loss: 361.7791 - val_mae: 4.0015\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6117 - mae: 1.6791 - val_loss: 372.8164 - val_mae: 4.0023\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.6221 - mae: 1.6856 - val_loss: 315.6783 - val_mae: 3.7190\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.7856 - mae: 1.6768 - val_loss: 326.6390 - val_mae: 3.8662\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.1258 - mae: 1.7518 - val_loss: 386.9377 - val_mae: 4.1610\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.8054 - mae: 1.8133 - val_loss: 342.2691 - val_mae: 3.9770\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.8726 - mae: 1.8184 - val_loss: 313.1279 - val_mae: 3.8138\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.5939 - mae: 1.5728 - val_loss: 291.6991 - val_mae: 3.7523\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 52.1735 - mae: 1.8605 - val_loss: 212.1915 - val_mae: 3.3734\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.1980 - mae: 1.7258 - val_loss: 255.4338 - val_mae: 3.6194\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.4127 - mae: 1.6899 - val_loss: 343.3488 - val_mae: 3.8894\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.7402 - mae: 1.6147 - val_loss: 386.4338 - val_mae: 4.0882\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 47.7538 - mae: 1.8311 - val_loss: 395.6110 - val_mae: 4.1333\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 45.0724 - mae: 1.4983 - val_loss: 435.1067 - val_mae: 4.3373\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.8275 - mae: 1.8171 - val_loss: 231.6658 - val_mae: 3.5185\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.3917 - mae: 1.5415 - val_loss: 197.7947 - val_mae: 3.2996\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.7334 - mae: 1.6581 - val_loss: 283.7206 - val_mae: 3.7378\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.7992 - mae: 1.6301 - val_loss: 374.6147 - val_mae: 4.0674\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 52.9344 - mae: 1.7621 - val_loss: 183.9171 - val_mae: 3.1933\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.4009 - mae: 1.5682 - val_loss: 209.8734 - val_mae: 3.5270\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.0343 - mae: 1.5666 - val_loss: 203.8086 - val_mae: 3.3421\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.2641 - mae: 1.6584 - val_loss: 403.1322 - val_mae: 4.2200\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6526 - mae: 1.6411 - val_loss: 246.1441 - val_mae: 3.5610\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 58.3151 - mae: 1.7272 - val_loss: 393.4834 - val_mae: 4.2768\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.9831 - mae: 1.5644 - val_loss: 291.5756 - val_mae: 3.7919\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.2470 - mae: 1.5929 - val_loss: 162.7824 - val_mae: 3.0930\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.1802 - mae: 1.4645 - val_loss: 279.2557 - val_mae: 3.7440\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 44.4520 - mae: 1.6568 - val_loss: 424.8328 - val_mae: 4.3216\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.7786 - mae: 1.4945 - val_loss: 292.6285 - val_mae: 3.7992\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6900 - mae: 1.6763 - val_loss: 178.9223 - val_mae: 3.2064\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.8813 - mae: 1.4152 - val_loss: 175.3279 - val_mae: 3.1902\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7278 - mae: 1.4047 - val_loss: 274.5212 - val_mae: 3.6965\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.4518 - mae: 1.6717 - val_loss: 139.5898 - val_mae: 2.9474\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 36.1669 - mae: 1.6814 - val_loss: 168.8550 - val_mae: 3.1478\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.7259 - mae: 1.5380 - val_loss: 243.6393 - val_mae: 3.6010\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0111 - mae: 1.4178 - val_loss: 191.3186 - val_mae: 3.2841\n",
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0590 - mae: 1.3760 - val_loss: 217.7655 - val_mae: 3.4235\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 27.3668 - mae: 1.3972 - val_loss: 269.9238 - val_mae: 3.6167\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 2s 3ms/step - loss: 34.1589 - mae: 1.5454 - val_loss: 381.6167 - val_mae: 4.1562\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 40.7512 - mae: 1.6346 - val_loss: 224.9707 - val_mae: 3.4589\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 16.1008 - mae: 1.2690 - val_loss: 285.6318 - val_mae: 3.7140\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.2936 - mae: 1.4654 - val_loss: 223.4223 - val_mae: 3.3916\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.5814 - mae: 1.5985 - val_loss: 224.7942 - val_mae: 3.4113\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6574 - mae: 1.2530 - val_loss: 281.2530 - val_mae: 3.6864\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.4053 - mae: 1.4646 - val_loss: 197.6410 - val_mae: 3.2715\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7804 - mae: 1.5394 - val_loss: 146.7192 - val_mae: 2.9824\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.2006 - mae: 1.6408 - val_loss: 193.4010 - val_mae: 3.3131\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.9647 - mae: 1.5017 - val_loss: 203.0493 - val_mae: 3.3954\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.7715 - mae: 1.4198 - val_loss: 209.3373 - val_mae: 3.4561\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.9043 - mae: 1.5982 - val_loss: 152.5043 - val_mae: 3.0846\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6319 - mae: 1.5437 - val_loss: 185.3761 - val_mae: 3.2356\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.2326 - mae: 1.5002 - val_loss: 270.4908 - val_mae: 3.6738\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2333 - mae: 1.4599 - val_loss: 173.4674 - val_mae: 3.1895\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.2994 - mae: 1.5247 - val_loss: 222.0793 - val_mae: 3.4864\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.3417 - mae: 1.5743 - val_loss: 192.2014 - val_mae: 3.4757\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0172 - mae: 1.3472 - val_loss: 229.4637 - val_mae: 3.6525\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9113 - mae: 1.3264 - val_loss: 190.9903 - val_mae: 3.4304\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.5067 - mae: 1.6675 - val_loss: 100.2357 - val_mae: 2.6077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.4096 - mae: 1.7807 - val_loss: 132.8593 - val_mae: 2.9967\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2000 - mae: 1.3574 - val_loss: 206.2092 - val_mae: 3.4732\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.0091 - mae: 1.6728 - val_loss: 196.4430 - val_mae: 3.3881\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5539 - mae: 1.2531 - val_loss: 187.4744 - val_mae: 3.3417\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.4196 - mae: 1.3635 - val_loss: 189.8052 - val_mae: 3.3595\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.1663 - mae: 1.3203 - val_loss: 138.8454 - val_mae: 3.0141\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8362 - mae: 1.3758 - val_loss: 200.2014 - val_mae: 3.4644\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.7528 - mae: 1.4667 - val_loss: 167.7109 - val_mae: 3.2791\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 21.9929 - mae: 1.3820 - val_loss: 142.8009 - val_mae: 3.0460\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9899 - mae: 1.6511 - val_loss: 201.5308 - val_mae: 3.4262\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.1161 - mae: 1.3043 - val_loss: 260.6747 - val_mae: 3.7464\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2754 - mae: 1.2244 - val_loss: 200.3022 - val_mae: 3.4246\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.6067 - mae: 1.4912 - val_loss: 137.8835 - val_mae: 2.9896\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.4204 - mae: 1.5695 - val_loss: 189.8710 - val_mae: 3.3363\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.2300 - mae: 1.3993 - val_loss: 193.5389 - val_mae: 3.3771\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.4113 - mae: 1.3330 - val_loss: 224.8381 - val_mae: 3.5244\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8557 - mae: 1.2505 - val_loss: 149.3273 - val_mae: 3.0565\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4171 - mae: 1.2945 - val_loss: 164.7719 - val_mae: 3.1706\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.2401 - mae: 1.3517 - val_loss: 256.5830 - val_mae: 3.7143\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.2325 - mae: 1.5412 - val_loss: 156.9062 - val_mae: 3.1197\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5149 - mae: 1.2747 - val_loss: 140.1729 - val_mae: 3.0592\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3756 - mae: 1.2352 - val_loss: 175.9151 - val_mae: 3.2506\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7828 - mae: 1.3727 - val_loss: 163.2172 - val_mae: 3.1607\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3841 - mae: 1.1905 - val_loss: 170.9169 - val_mae: 3.2252\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3323 - mae: 1.2878 - val_loss: 226.2228 - val_mae: 3.5774\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7876 - mae: 1.2423 - val_loss: 186.6638 - val_mae: 3.3106\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.5765 - mae: 1.2492 - val_loss: 163.6361 - val_mae: 3.1664\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.8314 - mae: 1.2881 - val_loss: 124.7424 - val_mae: 2.7989\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6489 - mae: 1.2336 - val_loss: 159.2567 - val_mae: 3.1180\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0413 - mae: 1.2715 - val_loss: 133.4213 - val_mae: 2.8896\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.3028 - mae: 1.1812 - val_loss: 160.1086 - val_mae: 3.1246\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9122 - mae: 1.2277 - val_loss: 149.5371 - val_mae: 3.0190\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.7372 - mae: 1.1945 - val_loss: 114.8204 - val_mae: 2.7301\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6913 - mae: 1.2641 - val_loss: 112.2749 - val_mae: 2.6792\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8005 - mae: 1.3039 - val_loss: 171.3540 - val_mae: 3.2240\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8566 - mae: 1.1975 - val_loss: 143.2338 - val_mae: 2.9892\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6554 - mae: 1.1506 - val_loss: 146.0134 - val_mae: 3.0332\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.8253 - mae: 1.1796 - val_loss: 139.8048 - val_mae: 2.9662\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.2108 - mae: 1.2438 - val_loss: 150.3507 - val_mae: 3.0404\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.7447 - mae: 1.0903 - val_loss: 141.1558 - val_mae: 2.9712\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1761 - mae: 1.2132 - val_loss: 174.0882 - val_mae: 3.2274\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6744 - mae: 1.3022 - val_loss: 113.2080 - val_mae: 2.7007\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.9833 - mae: 1.3077 - val_loss: 150.7914 - val_mae: 3.0379\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.9764 - mae: 1.3759 - val_loss: 199.1354 - val_mae: 3.4198\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0916 - mae: 1.2518 - val_loss: 127.1703 - val_mae: 2.7970\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.8154 - mae: 1.3588 - val_loss: 234.0567 - val_mae: 3.6728\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.2388 - mae: 1.4153 - val_loss: 154.4773 - val_mae: 3.0910\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0743 - mae: 1.2311 - val_loss: 141.2078 - val_mae: 2.9957\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2163 - mae: 1.1227 - val_loss: 145.9725 - val_mae: 3.0349\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0313 - mae: 1.2915 - val_loss: 123.3565 - val_mae: 2.7975\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4684 - mae: 1.2560 - val_loss: 152.5247 - val_mae: 3.0322\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.5448 - mae: 1.2786 - val_loss: 177.4571 - val_mae: 3.2389\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.6137 - mae: 1.2996 - val_loss: 231.0726 - val_mae: 3.6235\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.3550 - mae: 1.5338 - val_loss: 153.7422 - val_mae: 3.0823\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.9696 - mae: 1.1809 - val_loss: 144.4654 - val_mae: 3.0193\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5292 - mae: 1.2178 - val_loss: 173.8783 - val_mae: 3.2408\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.2446 - mae: 1.1497 - val_loss: 121.4733 - val_mae: 2.8072\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7151 - mae: 1.2269 - val_loss: 147.5725 - val_mae: 2.9860\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7124 - mae: 1.1109 - val_loss: 133.3219 - val_mae: 2.8605\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.4244 - mae: 1.0836 - val_loss: 155.8373 - val_mae: 3.0850\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.1928 - mae: 1.4121 - val_loss: 179.4945 - val_mae: 3.2412\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0383 - mae: 1.2055 - val_loss: 194.7357 - val_mae: 3.3463\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.7283 - mae: 1.2844 - val_loss: 113.3697 - val_mae: 2.6501\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.5165 - mae: 1.0089 - val_loss: 117.5306 - val_mae: 2.7061\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2978 - mae: 1.2301 - val_loss: 181.3688 - val_mae: 3.2275\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6285 - mae: 1.3350 - val_loss: 151.1364 - val_mae: 3.0077\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3891 - mae: 1.1286 - val_loss: 118.8602 - val_mae: 2.7228\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.7665 - mae: 1.3176 - val_loss: 173.2254 - val_mae: 3.2262\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0604 - mae: 1.3319 - val_loss: 156.9699 - val_mae: 3.0409\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.2646 - mae: 1.2193 - val_loss: 173.9919 - val_mae: 3.1592\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6326 - mae: 1.1552 - val_loss: 166.1754 - val_mae: 3.0965\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.1277 - mae: 1.2849 - val_loss: 200.6927 - val_mae: 3.3414\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.9918 - mae: 1.3523 - val_loss: 120.5291 - val_mae: 2.6663\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.4966 - mae: 1.2572 - val_loss: 127.3336 - val_mae: 2.7228\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.3967 - mae: 1.0679 - val_loss: 138.4642 - val_mae: 2.8377\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.9218 - mae: 1.0202 - val_loss: 139.3162 - val_mae: 2.8448\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3576 - mae: 1.2983 - val_loss: 134.9812 - val_mae: 2.8202\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.9086 - mae: 1.0603 - val_loss: 136.5679 - val_mae: 2.8250\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.7612 - mae: 1.3362 - val_loss: 157.1794 - val_mae: 3.0237\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6320 - mae: 1.1672 - val_loss: 116.0366 - val_mae: 2.5865\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.7231 - mae: 1.2096 - val_loss: 109.2436 - val_mae: 2.4548\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.6064 - mae: 1.1597 - val_loss: 132.4353 - val_mae: 2.7582\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6468 - mae: 1.1916 - val_loss: 121.9422 - val_mae: 2.6054\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.5037 - mae: 1.0296 - val_loss: 123.2565 - val_mae: 2.5963\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3610 - mae: 1.1863 - val_loss: 196.3515 - val_mae: 3.3247\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.6730 - mae: 1.1885 - val_loss: 160.4046 - val_mae: 2.9994\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1335 - mae: 1.1889 - val_loss: 176.2896 - val_mae: 3.1838\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7271 - mae: 1.1447 - val_loss: 125.8716 - val_mae: 2.6869\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.0000 - mae: 1.1966 - val_loss: 134.0985 - val_mae: 2.7360\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9631 - mae: 1.2304 - val_loss: 146.9474 - val_mae: 2.9859\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8447 - mae: 1.1132 - val_loss: 113.2574 - val_mae: 2.5466\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8488 - mae: 1.2094 - val_loss: 144.7739 - val_mae: 2.8412\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.2329 - mae: 1.1164 - val_loss: 151.0422 - val_mae: 2.9524\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4320 - mae: 1.1849 - val_loss: 144.5271 - val_mae: 2.8558\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.6568 - mae: 1.2054 - val_loss: 149.5294 - val_mae: 2.9501\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0130 - mae: 1.1455 - val_loss: 130.1089 - val_mae: 2.7606\n",
      "Epoch 176/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.0743 - mae: 1.2889 - val_loss: 149.4707 - val_mae: 2.9544\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.2071 - mae: 1.1122 - val_loss: 139.6900 - val_mae: 2.8180\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1119 - mae: 1.1889 - val_loss: 169.1669 - val_mae: 3.1322\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2873 - mae: 1.1665 - val_loss: 120.1879 - val_mae: 2.5896\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.0311 - mae: 1.0838 - val_loss: 119.8082 - val_mae: 2.5801\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.1262 - mae: 1.1368 - val_loss: 136.7295 - val_mae: 2.7545\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8001 - mae: 1.0794 - val_loss: 140.6472 - val_mae: 2.8049\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.5281 - mae: 1.0365 - val_loss: 117.3985 - val_mae: 2.4440\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.8641 - mae: 1.0348 - val_loss: 117.4330 - val_mae: 2.4622\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.1469 - mae: 1.0306 - val_loss: 138.7800 - val_mae: 2.7842\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5906 - mae: 1.2367 - val_loss: 120.2445 - val_mae: 2.4765\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 20.1862 - mae: 1.2261 - val_loss: 136.0346 - val_mae: 2.6988\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 11.3831 - mae: 1.0823 - val_loss: 123.3582 - val_mae: 2.4525\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.0067 - mae: 1.2866 - val_loss: 122.9139 - val_mae: 2.4396\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6774 - mae: 1.1485 - val_loss: 130.5796 - val_mae: 2.5810\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4220 - mae: 1.1471 - val_loss: 161.5178 - val_mae: 3.0118\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.1937 - mae: 1.2641 - val_loss: 141.6595 - val_mae: 2.8051\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 6.5004 - mae: 0.9079 - val_loss: 159.9550 - val_mae: 3.0340\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3951 - mae: 1.2392 - val_loss: 129.4274 - val_mae: 2.6601\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0804 - mae: 1.2406 - val_loss: 130.9458 - val_mae: 2.6442\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8452 - mae: 1.1911 - val_loss: 129.1192 - val_mae: 2.5680\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.9199 - mae: 1.0741 - val_loss: 123.8682 - val_mae: 2.4798\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 11.6999 - mae: 1.0739 - val_loss: 138.0784 - val_mae: 2.7118\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 7.2434 - mae: 0.9475 - val_loss: 139.4235 - val_mae: 2.7249\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7862 - mae: 1.0619 - val_loss: 136.6662 - val_mae: 2.7146\n",
      ">19, MAE: 1.907\n",
      "Epoch 1/200\n",
      "582/582 [==============================] - 1s 2ms/step - loss: 278.2858 - mae: 3.9388 - val_loss: 640.4919 - val_mae: 6.8543\n",
      "Epoch 2/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 159.4335 - mae: 3.3935 - val_loss: 142.0896 - val_mae: 3.0245\n",
      "Epoch 3/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 222.4271 - mae: 3.6823 - val_loss: 163.3802 - val_mae: 3.6605\n",
      "Epoch 4/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 180.6829 - mae: 3.2252 - val_loss: 519.7883 - val_mae: 6.1475\n",
      "Epoch 5/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 250.7032 - mae: 3.3989 - val_loss: 296.9881 - val_mae: 4.5819\n",
      "Epoch 6/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 187.9274 - mae: 3.0434 - val_loss: 133.0322 - val_mae: 3.2432\n",
      "Epoch 7/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 121.0213 - mae: 2.6988 - val_loss: 181.2214 - val_mae: 3.6947\n",
      "Epoch 8/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.4476 - mae: 2.2048 - val_loss: 98.1421 - val_mae: 2.6671\n",
      "Epoch 9/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 212.6703 - mae: 2.9056 - val_loss: 116.7901 - val_mae: 2.8526\n",
      "Epoch 10/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 104.0140 - mae: 2.3495 - val_loss: 146.4492 - val_mae: 3.1359\n",
      "Epoch 11/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 54.0065 - mae: 2.1745 - val_loss: 253.7673 - val_mae: 3.8990\n",
      "Epoch 12/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 63.7406 - mae: 2.2074 - val_loss: 220.6010 - val_mae: 3.5229\n",
      "Epoch 13/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 81.5554 - mae: 2.3261 - val_loss: 307.0649 - val_mae: 3.9407\n",
      "Epoch 14/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 51.0329 - mae: 1.9573 - val_loss: 246.4139 - val_mae: 3.5133\n",
      "Epoch 15/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.9148 - mae: 1.8596 - val_loss: 149.2758 - val_mae: 3.0500\n",
      "Epoch 16/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 64.7330 - mae: 2.1225 - val_loss: 304.8136 - val_mae: 3.7912\n",
      "Epoch 17/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 65.4628 - mae: 2.2048 - val_loss: 181.1650 - val_mae: 3.1343\n",
      "Epoch 18/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 70.0267 - mae: 2.0490 - val_loss: 147.6012 - val_mae: 3.0583\n",
      "Epoch 19/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.7906 - mae: 1.9713 - val_loss: 195.3865 - val_mae: 3.1870\n",
      "Epoch 20/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.9164 - mae: 1.9342 - val_loss: 310.7258 - val_mae: 3.9319\n",
      "Epoch 21/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 42.3328 - mae: 1.9671 - val_loss: 290.0159 - val_mae: 3.7289\n",
      "Epoch 22/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.2279 - mae: 1.6564 - val_loss: 280.3748 - val_mae: 3.6891\n",
      "Epoch 23/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.8039 - mae: 1.9246 - val_loss: 287.3857 - val_mae: 3.6975\n",
      "Epoch 24/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.6373 - mae: 1.8155 - val_loss: 199.8028 - val_mae: 3.3213\n",
      "Epoch 25/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.0609 - mae: 1.7354 - val_loss: 189.3171 - val_mae: 3.3840\n",
      "Epoch 26/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.5841 - mae: 1.9790 - val_loss: 296.1686 - val_mae: 3.7458\n",
      "Epoch 27/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.7546 - mae: 1.8667 - val_loss: 230.1531 - val_mae: 3.4291\n",
      "Epoch 28/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 48.5555 - mae: 1.8195 - val_loss: 342.6714 - val_mae: 3.8526\n",
      "Epoch 29/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.7204 - mae: 1.8958 - val_loss: 569.9972 - val_mae: 4.8214\n",
      "Epoch 30/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.2113 - mae: 1.7816 - val_loss: 264.8342 - val_mae: 3.5117\n",
      "Epoch 31/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.0217 - mae: 1.8123 - val_loss: 236.0363 - val_mae: 3.4000\n",
      "Epoch 32/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 53.2788 - mae: 1.9316 - val_loss: 301.3336 - val_mae: 3.7000\n",
      "Epoch 33/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.4510 - mae: 1.7253 - val_loss: 228.6677 - val_mae: 3.4075\n",
      "Epoch 34/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.3258 - mae: 1.8632 - val_loss: 194.6126 - val_mae: 3.2167\n",
      "Epoch 35/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.8835 - mae: 1.8085 - val_loss: 246.9738 - val_mae: 3.5453\n",
      "Epoch 36/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.3712 - mae: 1.6012 - val_loss: 192.0497 - val_mae: 3.2673\n",
      "Epoch 37/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.2525 - mae: 1.6077 - val_loss: 170.1238 - val_mae: 3.1197\n",
      "Epoch 38/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.6527 - mae: 1.6436 - val_loss: 184.2596 - val_mae: 3.1892\n",
      "Epoch 39/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.0489 - mae: 1.6442 - val_loss: 190.5039 - val_mae: 3.2311\n",
      "Epoch 40/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 50.3853 - mae: 1.6943 - val_loss: 224.1125 - val_mae: 3.4334\n",
      "Epoch 41/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 38.4986 - mae: 1.7075 - val_loss: 229.9942 - val_mae: 3.4250\n",
      "Epoch 42/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.6402 - mae: 1.8156 - val_loss: 310.4641 - val_mae: 3.7792\n",
      "Epoch 43/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.5858 - mae: 1.6327 - val_loss: 239.1146 - val_mae: 3.5015\n",
      "Epoch 44/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.9663 - mae: 1.4545 - val_loss: 154.9820 - val_mae: 2.9859\n",
      "Epoch 45/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.7125 - mae: 1.7186 - val_loss: 326.1379 - val_mae: 3.9368\n",
      "Epoch 46/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7006 - mae: 1.4254 - val_loss: 276.6898 - val_mae: 3.6613\n",
      "Epoch 47/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.8707 - mae: 1.6587 - val_loss: 275.1563 - val_mae: 3.5762\n",
      "Epoch 48/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.0338 - mae: 1.6630 - val_loss: 186.6051 - val_mae: 3.0880\n",
      "Epoch 49/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.6668 - mae: 1.5765 - val_loss: 225.9342 - val_mae: 3.4009\n",
      "Epoch 50/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.5550 - mae: 1.6677 - val_loss: 173.0493 - val_mae: 3.0795\n",
      "Epoch 51/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.1932 - mae: 1.6638 - val_loss: 374.8475 - val_mae: 4.1336\n",
      "Epoch 52/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.7298 - mae: 1.4754 - val_loss: 217.4636 - val_mae: 3.4048\n",
      "Epoch 53/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 43.3841 - mae: 1.6434 - val_loss: 226.1130 - val_mae: 3.4727\n",
      "Epoch 54/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.2400 - mae: 1.6707 - val_loss: 249.8313 - val_mae: 3.5486\n",
      "Epoch 55/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 112.5262 - mae: 2.1096 - val_loss: 224.0837 - val_mae: 3.4542\n",
      "Epoch 56/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.4939 - mae: 1.4586 - val_loss: 281.7035 - val_mae: 3.7240\n",
      "Epoch 57/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.7334 - mae: 1.5720 - val_loss: 216.6751 - val_mae: 3.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.6689 - mae: 1.4618 - val_loss: 247.4480 - val_mae: 3.5135\n",
      "Epoch 59/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2274 - mae: 1.5760 - val_loss: 253.9524 - val_mae: 3.5553\n",
      "Epoch 60/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.3526 - mae: 1.4652 - val_loss: 256.3398 - val_mae: 3.5249\n",
      "Epoch 61/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1347 - mae: 1.2147 - val_loss: 198.8274 - val_mae: 3.2190\n",
      "Epoch 62/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 47.0273 - mae: 1.6203 - val_loss: 386.3175 - val_mae: 4.0794\n",
      "Epoch 63/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 49.2419 - mae: 1.8298 - val_loss: 135.6368 - val_mae: 2.8011\n",
      "Epoch 64/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.1416 - mae: 1.5709 - val_loss: 292.6475 - val_mae: 3.7516\n",
      "Epoch 65/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2094 - mae: 1.4504 - val_loss: 192.4174 - val_mae: 3.2013\n",
      "Epoch 66/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8363 - mae: 1.3840 - val_loss: 155.9754 - val_mae: 3.0055\n",
      "Epoch 67/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.2463 - mae: 1.5847 - val_loss: 216.7945 - val_mae: 3.3080\n",
      "Epoch 68/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.8229 - mae: 1.5591 - val_loss: 259.6276 - val_mae: 3.6046\n",
      "Epoch 69/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.8794 - mae: 1.6091 - val_loss: 177.7058 - val_mae: 3.0650\n",
      "Epoch 70/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.6971 - mae: 1.3356 - val_loss: 211.6805 - val_mae: 3.3652\n",
      "Epoch 71/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.9816 - mae: 1.6011 - val_loss: 224.2911 - val_mae: 3.3643\n",
      "Epoch 72/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.5939 - mae: 1.4700 - val_loss: 161.5889 - val_mae: 2.9766\n",
      "Epoch 73/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.2179 - mae: 1.5028 - val_loss: 146.6571 - val_mae: 2.9144\n",
      "Epoch 74/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 39.9651 - mae: 1.6209 - val_loss: 218.1704 - val_mae: 3.3590\n",
      "Epoch 75/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9482 - mae: 1.2707 - val_loss: 153.8787 - val_mae: 2.9756\n",
      "Epoch 76/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 46.1639 - mae: 1.6341 - val_loss: 164.3130 - val_mae: 3.0715\n",
      "Epoch 77/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 37.1635 - mae: 1.5689 - val_loss: 320.6263 - val_mae: 3.8408\n",
      "Epoch 78/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.3610 - mae: 1.6058 - val_loss: 175.3963 - val_mae: 3.1080\n",
      "Epoch 79/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8794 - mae: 1.3926 - val_loss: 135.5043 - val_mae: 2.7722\n",
      "Epoch 80/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.7207 - mae: 1.3076 - val_loss: 207.6142 - val_mae: 3.2553\n",
      "Epoch 81/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 29.0106 - mae: 1.5879 - val_loss: 224.8957 - val_mae: 3.4262\n",
      "Epoch 82/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.5965 - mae: 1.5259 - val_loss: 270.2156 - val_mae: 3.6717\n",
      "Epoch 83/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 45.8591 - mae: 1.6815 - val_loss: 146.9839 - val_mae: 2.9821\n",
      "Epoch 84/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8350 - mae: 1.2953 - val_loss: 216.0990 - val_mae: 3.3189\n",
      "Epoch 85/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.7004 - mae: 1.4135 - val_loss: 230.7284 - val_mae: 3.4029\n",
      "Epoch 86/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.9153 - mae: 1.2016 - val_loss: 197.2371 - val_mae: 3.2763\n",
      "Epoch 87/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9242 - mae: 1.3130 - val_loss: 215.4320 - val_mae: 3.4092\n",
      "Epoch 88/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 41.4697 - mae: 1.5671 - val_loss: 276.4979 - val_mae: 3.7129\n",
      "Epoch 89/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.2651 - mae: 1.4612 - val_loss: 224.4480 - val_mae: 3.3644\n",
      "Epoch 90/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.7999 - mae: 1.5574 - val_loss: 382.6889 - val_mae: 4.1546\n",
      "Epoch 91/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.2384 - mae: 1.3912 - val_loss: 193.3434 - val_mae: 3.2493\n",
      "Epoch 92/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.4298 - mae: 1.2092 - val_loss: 227.7874 - val_mae: 3.4407\n",
      "Epoch 93/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.2540 - mae: 1.3586 - val_loss: 260.3163 - val_mae: 3.5871\n",
      "Epoch 94/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 34.0368 - mae: 1.4354 - val_loss: 162.3471 - val_mae: 2.9186\n",
      "Epoch 95/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.5041 - mae: 1.2719 - val_loss: 183.7043 - val_mae: 3.0814\n",
      "Epoch 96/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.1600 - mae: 1.3659 - val_loss: 187.9566 - val_mae: 3.1302\n",
      "Epoch 97/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3010 - mae: 1.3708 - val_loss: 160.8149 - val_mae: 2.9902\n",
      "Epoch 98/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4232 - mae: 1.4002 - val_loss: 251.2432 - val_mae: 3.5190\n",
      "Epoch 99/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1054 - mae: 1.2000 - val_loss: 284.8170 - val_mae: 3.6938\n",
      "Epoch 100/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8272 - mae: 1.2089 - val_loss: 275.1794 - val_mae: 3.6327\n",
      "Epoch 101/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 40.8050 - mae: 1.4287 - val_loss: 157.9697 - val_mae: 2.9504\n",
      "Epoch 102/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.3146 - mae: 1.2050 - val_loss: 166.8985 - val_mae: 3.0515\n",
      "Epoch 103/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.0336 - mae: 1.3778 - val_loss: 236.2783 - val_mae: 3.4622\n",
      "Epoch 104/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.0841 - mae: 1.2322 - val_loss: 249.2962 - val_mae: 3.6272\n",
      "Epoch 105/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1176 - mae: 1.2146 - val_loss: 178.5310 - val_mae: 3.1281\n",
      "Epoch 106/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.3341 - mae: 1.2539 - val_loss: 217.9957 - val_mae: 3.4053\n",
      "Epoch 107/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3065 - mae: 1.2286 - val_loss: 168.6036 - val_mae: 3.0936\n",
      "Epoch 108/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 35.3125 - mae: 1.3978 - val_loss: 245.6685 - val_mae: 3.5718\n",
      "Epoch 109/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.6917 - mae: 1.2958 - val_loss: 163.6072 - val_mae: 3.0832\n",
      "Epoch 110/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.5478 - mae: 1.1936 - val_loss: 174.2054 - val_mae: 3.1524\n",
      "Epoch 111/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.1662 - mae: 1.1904 - val_loss: 244.3164 - val_mae: 3.5808\n",
      "Epoch 112/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.1460 - mae: 1.3184 - val_loss: 191.8551 - val_mae: 3.2607\n",
      "Epoch 113/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.9031 - mae: 1.2513 - val_loss: 294.0784 - val_mae: 3.7807\n",
      "Epoch 114/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.4201 - mae: 1.3194 - val_loss: 190.1372 - val_mae: 3.2501\n",
      "Epoch 115/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.6737 - mae: 1.3494 - val_loss: 204.5480 - val_mae: 3.3710\n",
      "Epoch 116/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.7156 - mae: 1.1365 - val_loss: 140.9460 - val_mae: 2.8522\n",
      "Epoch 117/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.8798 - mae: 1.3787 - val_loss: 199.7636 - val_mae: 3.3303\n",
      "Epoch 118/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.1967 - mae: 1.1497 - val_loss: 181.9207 - val_mae: 3.2058\n",
      "Epoch 119/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.6766 - mae: 1.1726 - val_loss: 217.7560 - val_mae: 3.4645\n",
      "Epoch 120/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 26.4108 - mae: 1.2699 - val_loss: 186.5146 - val_mae: 3.2370\n",
      "Epoch 121/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.8318 - mae: 1.3145 - val_loss: 150.5725 - val_mae: 3.0194\n",
      "Epoch 122/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 25.3517 - mae: 1.3576 - val_loss: 241.3479 - val_mae: 3.5746\n",
      "Epoch 123/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.5654 - mae: 1.4395 - val_loss: 307.0873 - val_mae: 3.8602\n",
      "Epoch 124/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7536 - mae: 1.2673 - val_loss: 309.7969 - val_mae: 3.8482\n",
      "Epoch 125/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.4902 - mae: 1.2158 - val_loss: 243.6496 - val_mae: 3.5581\n",
      "Epoch 126/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.2055 - mae: 1.1302 - val_loss: 226.2669 - val_mae: 3.4571\n",
      "Epoch 127/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 23.5771 - mae: 1.3086 - val_loss: 289.5610 - val_mae: 3.7474\n",
      "Epoch 128/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 28.6734 - mae: 1.4282 - val_loss: 177.0054 - val_mae: 3.1142\n",
      "Epoch 129/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0664 - mae: 1.1623 - val_loss: 252.2981 - val_mae: 3.6072\n",
      "Epoch 130/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2646 - mae: 1.2676 - val_loss: 272.9530 - val_mae: 3.6329\n",
      "Epoch 131/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.8797 - mae: 1.2925 - val_loss: 304.2041 - val_mae: 3.8129\n",
      "Epoch 132/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.6859 - mae: 1.1993 - val_loss: 231.8991 - val_mae: 3.5167\n",
      "Epoch 133/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.3069 - mae: 1.2339 - val_loss: 272.9469 - val_mae: 3.7275\n",
      "Epoch 134/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.3406 - mae: 1.2917 - val_loss: 137.5258 - val_mae: 2.8261\n",
      "Epoch 135/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.0637 - mae: 1.2064 - val_loss: 245.4786 - val_mae: 3.5219\n",
      "Epoch 136/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.7108 - mae: 1.0552 - val_loss: 275.5157 - val_mae: 3.6434\n",
      "Epoch 137/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.2535 - mae: 1.2436 - val_loss: 321.6744 - val_mae: 3.8655\n",
      "Epoch 138/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.8129 - mae: 1.1986 - val_loss: 206.5549 - val_mae: 3.3988\n",
      "Epoch 139/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.7070 - mae: 1.2976 - val_loss: 226.4768 - val_mae: 3.6323\n",
      "Epoch 140/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.7526 - mae: 1.1754 - val_loss: 226.5128 - val_mae: 3.4998\n",
      "Epoch 141/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.7850 - mae: 1.1419 - val_loss: 211.9038 - val_mae: 3.4316\n",
      "Epoch 142/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.8545 - mae: 1.2858 - val_loss: 231.5222 - val_mae: 3.5612\n",
      "Epoch 143/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.0099 - mae: 1.2850 - val_loss: 311.3674 - val_mae: 3.9378\n",
      "Epoch 144/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.2105 - mae: 1.2044 - val_loss: 286.4214 - val_mae: 3.8572\n",
      "Epoch 145/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 33.0128 - mae: 1.3364 - val_loss: 166.9159 - val_mae: 3.2014\n",
      "Epoch 146/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.3222 - mae: 1.1679 - val_loss: 274.5621 - val_mae: 3.8348\n",
      "Epoch 147/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 32.1986 - mae: 1.4631 - val_loss: 168.0096 - val_mae: 3.1359\n",
      "Epoch 148/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.3236 - mae: 1.2683 - val_loss: 228.0314 - val_mae: 3.5792\n",
      "Epoch 149/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 30.3544 - mae: 1.2891 - val_loss: 263.9096 - val_mae: 3.7661\n",
      "Epoch 150/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.5252 - mae: 1.1399 - val_loss: 165.5455 - val_mae: 3.1370\n",
      "Epoch 151/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.7512 - mae: 1.2017 - val_loss: 341.8024 - val_mae: 4.0888\n",
      "Epoch 152/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.0087 - mae: 1.2243 - val_loss: 164.4012 - val_mae: 3.1266\n",
      "Epoch 153/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 24.2574 - mae: 1.2331 - val_loss: 236.6915 - val_mae: 3.6078\n",
      "Epoch 154/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.0886 - mae: 1.1116 - val_loss: 216.5126 - val_mae: 3.4935\n",
      "Epoch 155/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.5128 - mae: 1.0199 - val_loss: 215.3952 - val_mae: 3.5070\n",
      "Epoch 156/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.4303 - mae: 1.1543 - val_loss: 211.8965 - val_mae: 3.4905\n",
      "Epoch 157/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.1925 - mae: 1.2632 - val_loss: 195.0655 - val_mae: 3.4080\n",
      "Epoch 158/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.4693 - mae: 1.0564 - val_loss: 210.3635 - val_mae: 3.5573\n",
      "Epoch 159/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 8.0904 - mae: 1.0407 - val_loss: 203.8372 - val_mae: 3.4753\n",
      "Epoch 160/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 31.4500 - mae: 1.3172 - val_loss: 283.3219 - val_mae: 3.9138\n",
      "Epoch 161/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.5214 - mae: 1.2117 - val_loss: 168.9869 - val_mae: 3.2572\n",
      "Epoch 162/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5242 - mae: 1.0473 - val_loss: 189.0233 - val_mae: 3.3640\n",
      "Epoch 163/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 13.8040 - mae: 1.1813 - val_loss: 182.2528 - val_mae: 3.3316\n",
      "Epoch 164/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.3823 - mae: 1.1431 - val_loss: 211.6358 - val_mae: 3.5203\n",
      "Epoch 165/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.6670 - mae: 1.1418 - val_loss: 178.7623 - val_mae: 3.2750\n",
      "Epoch 166/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 17.0752 - mae: 1.2528 - val_loss: 150.7713 - val_mae: 3.0513\n",
      "Epoch 167/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.3855 - mae: 1.2519 - val_loss: 200.5207 - val_mae: 3.4879\n",
      "Epoch 168/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.4836 - mae: 0.9726 - val_loss: 154.2571 - val_mae: 3.1406\n",
      "Epoch 169/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 15.0404 - mae: 1.1604 - val_loss: 231.5118 - val_mae: 3.6389\n",
      "Epoch 170/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.6233 - mae: 1.2546 - val_loss: 234.9462 - val_mae: 3.6516\n",
      "Epoch 171/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.7579 - mae: 1.3037 - val_loss: 231.0748 - val_mae: 3.6336\n",
      "Epoch 172/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.1733 - mae: 1.0961 - val_loss: 257.0149 - val_mae: 3.7851\n",
      "Epoch 173/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 19.9633 - mae: 1.1717 - val_loss: 209.9837 - val_mae: 3.5854\n",
      "Epoch 174/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 22.5779 - mae: 1.2813 - val_loss: 171.5252 - val_mae: 3.2507\n",
      "Epoch 175/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 18.2256 - mae: 1.2512 - val_loss: 277.2176 - val_mae: 3.8792\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 29.6592 - mae: 1.2581 - val_loss: 166.1000 - val_mae: 3.2166\n",
      "Epoch 177/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.7758 - mae: 1.0878 - val_loss: 249.3099 - val_mae: 3.7378\n",
      "Epoch 178/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.8190 - mae: 1.3389 - val_loss: 264.9035 - val_mae: 3.7874\n",
      "Epoch 179/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 27.8473 - mae: 1.3455 - val_loss: 165.7808 - val_mae: 3.1705\n",
      "Epoch 180/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.4118 - mae: 0.9934 - val_loss: 245.9569 - val_mae: 3.6852\n",
      "Epoch 181/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.4210 - mae: 1.0807 - val_loss: 219.4748 - val_mae: 3.5670\n",
      "Epoch 182/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.4461 - mae: 1.0762 - val_loss: 215.8933 - val_mae: 3.5314\n",
      "Epoch 183/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.3522 - mae: 1.1602 - val_loss: 245.3062 - val_mae: 3.7431\n",
      "Epoch 184/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5279 - mae: 1.1034 - val_loss: 180.7804 - val_mae: 3.2937\n",
      "Epoch 185/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 21.6376 - mae: 1.2205 - val_loss: 152.3975 - val_mae: 3.0800\n",
      "Epoch 186/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 55.4486 - mae: 1.6483 - val_loss: 256.3613 - val_mae: 3.9089\n",
      "Epoch 187/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 12.8798 - mae: 1.2706 - val_loss: 218.9755 - val_mae: 3.6253\n",
      "Epoch 188/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.7274 - mae: 1.1166 - val_loss: 222.8208 - val_mae: 3.6466\n",
      "Epoch 189/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5352 - mae: 1.1438 - val_loss: 204.8056 - val_mae: 3.5475\n",
      "Epoch 190/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.5149 - mae: 1.1214 - val_loss: 238.4488 - val_mae: 3.7495\n",
      "Epoch 191/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.3739 - mae: 1.1322 - val_loss: 268.9657 - val_mae: 3.9201\n",
      "Epoch 192/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.7170 - mae: 1.1758 - val_loss: 206.9606 - val_mae: 3.5844\n",
      "Epoch 193/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.9698 - mae: 1.1302 - val_loss: 280.8310 - val_mae: 3.9954\n",
      "Epoch 194/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 20.1814 - mae: 1.1940 - val_loss: 219.6956 - val_mae: 3.6344\n",
      "Epoch 195/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 10.6559 - mae: 1.0603 - val_loss: 202.3400 - val_mae: 3.5353\n",
      "Epoch 196/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 9.1151 - mae: 1.0132 - val_loss: 201.4754 - val_mae: 3.5241\n",
      "Epoch 197/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.1058 - mae: 1.1738 - val_loss: 159.1267 - val_mae: 3.2163\n",
      "Epoch 198/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 16.9953 - mae: 1.0870 - val_loss: 251.9741 - val_mae: 3.8278\n",
      "Epoch 199/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 14.0567 - mae: 1.1488 - val_loss: 275.4251 - val_mae: 3.9511\n",
      "Epoch 200/200\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 11.0246 - mae: 1.0585 - val_loss: 243.6623 - val_mae: 3.7741\n",
      ">20, MAE: 2.425\n"
     ]
    }
   ],
   "source": [
    "# fit ensemble\n",
    "n_members = 20\n",
    "ensemble = fit_ensemble(n_members, X_train, X_test, y_train, y_test, optimizer, dropout_rate, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 5\n",
    "make predictions with prediction interval\n",
    "\"\"\"\n",
    "\n",
    "p_turkey = turkey[['symbol', 'shortName', 'marketCap']]\n",
    "point_prediction = []\n",
    "lower_bound = []\n",
    "upper_bound = []\n",
    "\n",
    "for i in range(0, len(X_scaled_tur)):\n",
    "    newX = asarray([X_scaled_tur.loc[i, :]])\n",
    "    lower, mean, upper = predict_with_pi(ensemble, newX)\n",
    "    point_prediction.append(mean)\n",
    "    lower_bound.append(lower)\n",
    "    upper_bound.append(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-3e02045ebf1c>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_turkey['point_prediction'] = point_prediction\n",
      "<ipython-input-106-3e02045ebf1c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_turkey['lower_bound'] = lower_bound\n",
      "<ipython-input-106-3e02045ebf1c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_turkey['upper_bound'] = upper_bound\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>shortName</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>point_prediction</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GARAN.IS</td>\n",
       "      <td>GARANTI BANKASI</td>\n",
       "      <td>4.585135</td>\n",
       "      <td>9.839768</td>\n",
       "      <td>7.636162</td>\n",
       "      <td>12.043374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKBNK.IS</td>\n",
       "      <td>AKBANK</td>\n",
       "      <td>3.355317</td>\n",
       "      <td>8.856296</td>\n",
       "      <td>7.538009</td>\n",
       "      <td>10.174582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISCTR.IS</td>\n",
       "      <td>IS BANKASI (C)</td>\n",
       "      <td>2.761096</td>\n",
       "      <td>8.548029</td>\n",
       "      <td>5.645167</td>\n",
       "      <td>11.450891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YKBNK.IS</td>\n",
       "      <td>YAPI VE KREDI BANK.</td>\n",
       "      <td>2.406071</td>\n",
       "      <td>7.097673</td>\n",
       "      <td>5.773831</td>\n",
       "      <td>8.421515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAHOL.IS</td>\n",
       "      <td>SABANCI HOLDING</td>\n",
       "      <td>2.291788</td>\n",
       "      <td>7.013840</td>\n",
       "      <td>4.849965</td>\n",
       "      <td>9.177715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAKBN.IS</td>\n",
       "      <td>VAKIFLAR BANKASI</td>\n",
       "      <td>1.562017</td>\n",
       "      <td>5.386577</td>\n",
       "      <td>4.030570</td>\n",
       "      <td>6.742583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HALKB.IS</td>\n",
       "      <td>T. HALK BANKASI</td>\n",
       "      <td>1.343121</td>\n",
       "      <td>4.381282</td>\n",
       "      <td>2.309190</td>\n",
       "      <td>6.453375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TSKB.IS</td>\n",
       "      <td>T.S.K.B.</td>\n",
       "      <td>0.406916</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>0.537522</td>\n",
       "      <td>1.662511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALBRK.IS</td>\n",
       "      <td>ALBARAKA TURK</td>\n",
       "      <td>0.238569</td>\n",
       "      <td>0.118892</td>\n",
       "      <td>-0.082575</td>\n",
       "      <td>0.320360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SKBNK.IS</td>\n",
       "      <td>SEKERBANK</td>\n",
       "      <td>0.218410</td>\n",
       "      <td>0.024867</td>\n",
       "      <td>-0.142633</td>\n",
       "      <td>0.192368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol            shortName  marketCap  point_prediction  lower_bound  \\\n",
       "0  GARAN.IS      GARANTI BANKASI   4.585135          9.839768     7.636162   \n",
       "1  AKBNK.IS               AKBANK   3.355317          8.856296     7.538009   \n",
       "2  ISCTR.IS       IS BANKASI (C)   2.761096          8.548029     5.645167   \n",
       "3  YKBNK.IS  YAPI VE KREDI BANK.   2.406071          7.097673     5.773831   \n",
       "4  SAHOL.IS      SABANCI HOLDING   2.291788          7.013840     4.849965   \n",
       "5  VAKBN.IS     VAKIFLAR BANKASI   1.562017          5.386577     4.030570   \n",
       "6  HALKB.IS      T. HALK BANKASI   1.343121          4.381282     2.309190   \n",
       "7   TSKB.IS             T.S.K.B.   0.406916          1.100016     0.537522   \n",
       "8  ALBRK.IS        ALBARAKA TURK   0.238569          0.118892    -0.082575   \n",
       "9  SKBNK.IS            SEKERBANK   0.218410          0.024867    -0.142633   \n",
       "\n",
       "   upper_bound  \n",
       "0    12.043374  \n",
       "1    10.174582  \n",
       "2    11.450891  \n",
       "3     8.421515  \n",
       "4     9.177715  \n",
       "5     6.742583  \n",
       "6     6.453375  \n",
       "7     1.662511  \n",
       "8     0.320360  \n",
       "9     0.192368  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_turkey['point_prediction'] = point_prediction\n",
    "p_turkey['lower_bound'] = lower_bound\n",
    "p_turkey['upper_bound'] = upper_bound\n",
    "p_turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_turkey.to_csv('turkey_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Developing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resource 5\n",
    "make predictions with prediction interval\n",
    "\"\"\"\n",
    "p_developing = developing[['symbol', 'shortName', 'marketCap']]\n",
    "point_prediction_developing = []\n",
    "lower_bound_developing = []\n",
    "upper_bound_developing = []\n",
    "\n",
    "for i in range(0, len(X_scaled_developing)):\n",
    "    newX_developing = asarray([X_scaled_developing.loc[i, :]])\n",
    "    lower_developing, mean_developing, upper_developing = predict_with_pi(ensemble, newX_developing)\n",
    "    point_prediction_developing.append(mean_developing)\n",
    "    lower_bound_developing.append(lower_developing)\n",
    "    upper_bound_developing.append(upper_developing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-123-1e01f149b8c0>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_developing['point_prediction_developing'] = point_prediction_developing\n",
      "<ipython-input-123-1e01f149b8c0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_developing['lower_bound_developing'] = lower_bound_developing\n",
      "<ipython-input-123-1e01f149b8c0>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_developing['upper_bound_developing'] = upper_bound_developing\n",
      "<ipython-input-123-1e01f149b8c0>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_developing['country'] = developing['country']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>shortName</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>point_prediction_developing</th>\n",
       "      <th>lower_bound_developing</th>\n",
       "      <th>upper_bound_developing</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDFCBANK.NS</td>\n",
       "      <td>HDFC BANK</td>\n",
       "      <td>119.246483</td>\n",
       "      <td>82.549179</td>\n",
       "      <td>74.300049</td>\n",
       "      <td>90.798309</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICICIBANK.NS</td>\n",
       "      <td>ICICI BANK</td>\n",
       "      <td>67.968793</td>\n",
       "      <td>48.909954</td>\n",
       "      <td>40.255404</td>\n",
       "      <td>57.564504</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBIN.NS</td>\n",
       "      <td>STATE BK OF INDIA</td>\n",
       "      <td>55.169843</td>\n",
       "      <td>58.287987</td>\n",
       "      <td>45.688508</td>\n",
       "      <td>70.887466</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KOTAKBANK.NS</td>\n",
       "      <td>KOTAK MAHINDRA BAN</td>\n",
       "      <td>54.205208</td>\n",
       "      <td>22.408054</td>\n",
       "      <td>14.680852</td>\n",
       "      <td>30.135257</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXISBANK.NS</td>\n",
       "      <td>AXIS BANK</td>\n",
       "      <td>33.720593</td>\n",
       "      <td>20.288666</td>\n",
       "      <td>15.627705</td>\n",
       "      <td>24.949627</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>VAKBN.IS</td>\n",
       "      <td>VAKIFLAR BANKASI</td>\n",
       "      <td>1.562017</td>\n",
       "      <td>5.386577</td>\n",
       "      <td>4.030570</td>\n",
       "      <td>6.742583</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>HALKB.IS</td>\n",
       "      <td>T. HALK BANKASI</td>\n",
       "      <td>1.343121</td>\n",
       "      <td>4.381282</td>\n",
       "      <td>2.309190</td>\n",
       "      <td>6.453375</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>TSKB.IS</td>\n",
       "      <td>T.S.K.B.</td>\n",
       "      <td>0.406916</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>0.537522</td>\n",
       "      <td>1.662511</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ALBRK.IS</td>\n",
       "      <td>ALBARAKA TURK</td>\n",
       "      <td>0.238569</td>\n",
       "      <td>0.118892</td>\n",
       "      <td>-0.082575</td>\n",
       "      <td>0.320360</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>SKBNK.IS</td>\n",
       "      <td>SEKERBANK</td>\n",
       "      <td>0.218410</td>\n",
       "      <td>0.024867</td>\n",
       "      <td>-0.142633</td>\n",
       "      <td>0.192368</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol           shortName   marketCap  \\\n",
       "0     HDFCBANK.NS           HDFC BANK  119.246483   \n",
       "1    ICICIBANK.NS          ICICI BANK   67.968793   \n",
       "2         SBIN.NS   STATE BK OF INDIA   55.169843   \n",
       "3    KOTAKBANK.NS  KOTAK MAHINDRA BAN   54.205208   \n",
       "4     AXISBANK.NS           AXIS BANK   33.720593   \n",
       "..            ...                 ...         ...   \n",
       "123      VAKBN.IS    VAKIFLAR BANKASI    1.562017   \n",
       "124      HALKB.IS     T. HALK BANKASI    1.343121   \n",
       "125       TSKB.IS            T.S.K.B.    0.406916   \n",
       "126      ALBRK.IS       ALBARAKA TURK    0.238569   \n",
       "127      SKBNK.IS           SEKERBANK    0.218410   \n",
       "\n",
       "     point_prediction_developing  lower_bound_developing  \\\n",
       "0                      82.549179               74.300049   \n",
       "1                      48.909954               40.255404   \n",
       "2                      58.287987               45.688508   \n",
       "3                      22.408054               14.680852   \n",
       "4                      20.288666               15.627705   \n",
       "..                           ...                     ...   \n",
       "123                     5.386577                4.030570   \n",
       "124                     4.381282                2.309190   \n",
       "125                     1.100016                0.537522   \n",
       "126                     0.118892               -0.082575   \n",
       "127                     0.024867               -0.142633   \n",
       "\n",
       "     upper_bound_developing country  \n",
       "0                 90.798309   India  \n",
       "1                 57.564504   India  \n",
       "2                 70.887466   India  \n",
       "3                 30.135257   India  \n",
       "4                 24.949627   India  \n",
       "..                      ...     ...  \n",
       "123                6.742583  Turkey  \n",
       "124                6.453375  Turkey  \n",
       "125                1.662511  Turkey  \n",
       "126                0.320360  Turkey  \n",
       "127                0.192368  Turkey  \n",
       "\n",
       "[128 rows x 7 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_developing['point_prediction_developing'] = point_prediction_developing\n",
    "p_developing['lower_bound_developing'] = lower_bound_developing\n",
    "p_developing['upper_bound_developing'] = upper_bound_developing\n",
    "p_developing['country'] = developing['country']\n",
    "p_developing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_developing.to_csv('developing_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "1. Keras Sequential model: https://keras.io/guides/sequential_model/\n",
    "2. Train model: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "3. Display model training history: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "4. Pandas Fillna: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n",
    "5. Confidence interval: https://machinelearningmastery.com/prediction-intervals-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
